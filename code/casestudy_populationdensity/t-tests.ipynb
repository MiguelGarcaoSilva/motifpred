{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/populationdensity\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/populationdensity\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/populationdensity\n",
      "Dataset path: /home/mgsilva/motifpred/data/populationdensity/hourly_township.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from msig import Motif, NullModel\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Load YAML configuration\n",
    "config_path = \"config.yaml\"  # Ensure this path is correct\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Convert base_dir to absolute\n",
    "BASE_DIR = Path(config[\"base_dir\"]).resolve()\n",
    "\n",
    "# Convert other paths to absolute using BASE_DIR\n",
    "RESULTS_DIR = BASE_DIR / config[\"results_dir\"]\n",
    "RESULTS_MOTIF_DIR = BASE_DIR / config[\"results_motif_dir\"]\n",
    "IMAGES_DIR = BASE_DIR / config[\"images_dir\"]\n",
    "DATA_DIR = BASE_DIR / config[\"data_dir\"]\n",
    "DATASET_PATH = BASE_DIR / config[\"dataset_path\"]\n",
    "\n",
    "# Extract remaining parameters from YAML\n",
    "TOWNSHIP_NAME = config[\"township_name\"]\n",
    "VARIABLES = config[\"variables\"]\n",
    "NORMALIZE_FLAGS = config[\"normalize_flags\"]\n",
    "STUMPY_EXCL_ZONE_DENOM = config[\"stumpy_excl_zone_denom\"]\n",
    "TOP_K_MP = config[\"top_k_mp\"]\n",
    "INCLUDE = config[\"include\"]\n",
    "NORMALIZE = config[\"normalize\"]\n",
    "SUBSEQUENCES_LENGTHS = config[\"subsequences_lengths\"]\n",
    "NTOP_MOTIFS = config[\"ntop_motifs\"]\n",
    "MOTIF_SIZE = config[\"motif_size\"]\n",
    "LOOKBACK_PERIOD = config[\"lookback_period\"]\n",
    "STEP = config[\"step\"]\n",
    "FORECAST_PERIOD = config[\"forecast_period\"]\n",
    "\n",
    "# Print resolved paths for debugging\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "\n",
    "# Handling different environments\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = Path(__file__).parent.resolve()\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = Path(os.getcwd()).resolve()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(str(base_dir / \"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=[\"#Matches\", \"ID\"], ascending=[False, True]).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum_terminals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_time</th>\n",
       "      <th>township_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-15 00:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>260700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 01:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>276675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 02:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>284563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 03:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>279563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 04:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>281460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 19:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>391367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 20:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>352361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 21:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>388246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 22:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>360169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 23:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>349164.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1848 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum_terminals\n",
       "one_time            township_name                \n",
       "2021-09-15 00:00:00 Avenidas Novas       260700.0\n",
       "2021-09-15 01:00:00 Avenidas Novas       276675.0\n",
       "2021-09-15 02:00:00 Avenidas Novas       284563.0\n",
       "2021-09-15 03:00:00 Avenidas Novas       279563.0\n",
       "2021-09-15 04:00:00 Avenidas Novas       281460.0\n",
       "...                                           ...\n",
       "2021-11-30 19:00:00 Avenidas Novas       391367.0\n",
       "2021-11-30 20:00:00 Avenidas Novas       352361.0\n",
       "2021-11-30 21:00:00 Avenidas Novas       388246.0\n",
       "2021-11-30 22:00:00 Avenidas Novas       360169.0\n",
       "2021-11-30 23:00:00 Avenidas Novas       349164.0\n",
       "\n",
       "[1848 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "data_df = pd.read_csv(\n",
    "    DATASET_PATH,\n",
    "    parse_dates=[\"one_time\"],\n",
    "    date_format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "data_df = data_df[data_df[\"township_name\"] == TOWNSHIP_NAME]\n",
    "#set index to one_time and township_name\n",
    "data_df = data_df.set_index([\"one_time\", \"township_name\"]).sort_index()[VARIABLES]\n",
    "data = data_df.to_numpy().T\n",
    "data_univar = data[0]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 27 with size 12 and 58 indexes\n",
      "Model FFNNSeries already exists for motif 27\n",
      "Model FFNNSeries_Masking already exists for motif 27\n",
      "Model FFNNIndexes already exists for motif 27\n",
      "Model LSTMSeries already exists for motif 27\n",
      "Model LSTMSeries_Masking already exists for motif 27\n",
      "Model LSTMIndexes already exists for motif 27\n",
      "Model CNNSeries already exists for motif 27\n",
      "Model CNNSeries_Masking already exists for motif 27\n",
      "Model CNNIndexes already exists for motif 27\n",
      "Model TCNSeries already exists for motif 27\n",
      "Model TCNSeries_Masking already exists for motif 27\n",
      "Model TCNIndexes already exists for motif 27\n",
      "Model TransformerSeries already exists for motif 27\n",
      "Model TransformerSeries_Masking already exists for motif 27\n",
      "Model TransformerIndexes already exists for motif 27\n",
      "Model BaselineAverageIndexes already exists for motif 27\n",
      "Model BaselineLastDifferenceIndexes already exists for motif 27\n",
      "Evaluating motif 6 with size 12 and 47 indexes\n",
      "Model FFNNSeries already exists for motif 6\n",
      "Model FFNNSeries_Masking already exists for motif 6\n",
      "Model FFNNIndexes already exists for motif 6\n",
      "Model LSTMSeries already exists for motif 6\n",
      "Model LSTMSeries_Masking already exists for motif 6\n",
      "Model LSTMIndexes already exists for motif 6\n",
      "Model CNNSeries already exists for motif 6\n",
      "Model CNNSeries_Masking already exists for motif 6\n",
      "Model CNNIndexes already exists for motif 6\n",
      "Model TCNSeries already exists for motif 6\n",
      "Model TCNSeries_Masking already exists for motif 6\n",
      "Model TCNIndexes already exists for motif 6\n",
      "Model TransformerSeries already exists for motif 6\n",
      "Model TransformerSeries_Masking already exists for motif 6\n",
      "Model TransformerIndexes already exists for motif 6\n",
      "Model BaselineAverageIndexes already exists for motif 6\n",
      "Model BaselineLastDifferenceIndexes already exists for motif 6\n",
      "Evaluating motif 24 with size 12 and 46 indexes\n",
      "Model FFNNSeries already exists for motif 24\n",
      "Model FFNNSeries_Masking already exists for motif 24\n",
      "Model FFNNIndexes already exists for motif 24\n",
      "Model LSTMSeries already exists for motif 24\n",
      "Model LSTMSeries_Masking already exists for motif 24\n",
      "Model LSTMIndexes already exists for motif 24\n",
      "Model CNNSeries already exists for motif 24\n",
      "Model CNNSeries_Masking already exists for motif 24\n",
      "Model CNNIndexes already exists for motif 24\n",
      "Model TCNSeries already exists for motif 24\n",
      "Model TCNSeries_Masking already exists for motif 24\n",
      "Model TCNIndexes already exists for motif 24\n",
      "Model TransformerSeries already exists for motif 24\n",
      "Model TransformerSeries_Masking already exists for motif 24\n",
      "Model TransformerIndexes already exists for motif 24\n",
      "Model BaselineAverageIndexes already exists for motif 24\n",
      "Model BaselineLastDifferenceIndexes already exists for motif 24\n",
      "Evaluating motif 12 with size 12 and 44 indexes\n",
      "Model FFNNSeries already exists for motif 12\n",
      "Model FFNNSeries_Masking already exists for motif 12\n",
      "Model FFNNIndexes already exists for motif 12\n",
      "Model LSTMSeries already exists for motif 12\n",
      "Model LSTMSeries_Masking already exists for motif 12\n",
      "Model LSTMIndexes already exists for motif 12\n",
      "Model CNNSeries already exists for motif 12\n",
      "Model CNNSeries_Masking already exists for motif 12\n",
      "Model CNNIndexes already exists for motif 12\n",
      "Model TCNSeries already exists for motif 12\n",
      "Model TCNSeries_Masking already exists for motif 12\n",
      "Model TCNIndexes already exists for motif 12\n",
      "Model TransformerSeries already exists for motif 12\n",
      "Model TransformerSeries_Masking already exists for motif 12\n",
      "Model TransformerIndexes already exists for motif 12\n",
      "Model BaselineAverageIndexes already exists for motif 12\n",
      "Model BaselineLastDifferenceIndexes already exists for motif 12\n",
      "Evaluating motif 7 with size 12 and 38 indexes\n",
      "Model FFNNSeries already exists for motif 7\n",
      "Model FFNNSeries_Masking already exists for motif 7\n",
      "Model FFNNIndexes already exists for motif 7\n",
      "Model LSTMSeries already exists for motif 7\n",
      "Model LSTMSeries_Masking already exists for motif 7\n",
      "Model LSTMIndexes already exists for motif 7\n",
      "Model CNNSeries already exists for motif 7\n",
      "Model CNNSeries_Masking already exists for motif 7\n",
      "Model CNNIndexes already exists for motif 7\n",
      "Model TCNSeries already exists for motif 7\n",
      "Model TCNSeries_Masking already exists for motif 7\n",
      "Model TCNIndexes already exists for motif 7\n",
      "Model TransformerSeries already exists for motif 7\n",
      "Model TransformerSeries_Masking already exists for motif 7\n",
      "Model TransformerIndexes already exists for motif 7\n",
      "Model BaselineAverageIndexes already exists for motif 7\n",
      "Model BaselineLastDifferenceIndexes already exists for motif 7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import ast\n",
    "import pandas as pd\n",
    "from utils.utils import create_dataset, get_best_model_results_traindevtest, plot_best_model_results_traindevtest, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TCN\n",
    "from models.transformer_pytorch import Transformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "\n",
    "models = [ \"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists for motif {motif_id}\")\n",
    "        return\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    _, _, _, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(test_loss, test_losses, atol=0.1):\n",
    "        print(f\"Test loss: {test_loss}\")\n",
    "        print(f\"Retrained test loss: {test_losses}\")\n",
    "        raise Exception(\"Best model test loss does not match the one obtained from the study\")\n",
    "\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists for motif {motif_id}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing model {model_name} for motif {motif_id}\")\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse  = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    _, _, _, retrained_test_losses, retrained_test_mae, retrained_test_rmse, retrained_all_predictions, retrained_all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "    \n",
    "    if not np.allclose(test_loss, retrained_test_losses, atol=0.1):\n",
    "        print(f\"Test loss: {test_loss}\")\n",
    "        print(f\"Retrained test loss: {retrained_test_losses}\")\n",
    "        raise Exception(\"Best model test loss does not match the one obtained from the study\")\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            normalize_flags = NORMALIZE_FLAGS\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "            \n",
    "            if model_type == \"Baseline\":\n",
    "                if input_name != \"Indexes\":\n",
    "                    continue\n",
    "\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "                normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "                for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                    process_baseline_model(model_class, input_name, X, normalize_flags, 1, 1, seed, pipeline, y, i+1)\n",
    "            else:\n",
    "                if input_name == \"Series\":\n",
    "                    X = {\"X_series\": X_series}\n",
    "                elif input_name == \"Series_Masking\":\n",
    "                    X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "                else:\n",
    "                    X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "                model_params_map = {\n",
    "                    \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                    \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                    \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                    \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                    \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "                }\n",
    "\n",
    "                process_non_baseline_model(\n",
    "                    model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y, i+1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing motif 27 with 58 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 6 with 47 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 24 with 46 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 12 with 44 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 7 with 38 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "                     model           input motif        mae       rmse\n",
      "0                     FFNN          Series     1   6.988628   9.561339\n",
      "1                     FFNN  Series_Masking     1   8.065460  10.338732\n",
      "2                     FFNN         Indexes     1   8.091155  11.118716\n",
      "3                     LSTM          Series     1   8.713504  10.978179\n",
      "4                     LSTM  Series_Masking     1   7.484268   9.790107\n",
      "..                     ...             ...   ...        ...        ...\n",
      "80             Transformer          Series     1  14.796771  17.342743\n",
      "81             Transformer  Series_Masking     1  12.275888  16.024958\n",
      "82             Transformer         Indexes     1  11.995288  13.852979\n",
      "83         BaselineAverage         Indexes     1  15.887364  19.022167\n",
      "84  BaselineLastDifference         Indexes     1  30.109589  36.129524\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280170/726525104.py:83: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "models = [ \"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"motif\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    motif_id = i + 1\n",
    "    print(f\"Processing motif {motif_id} with {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            # Handle baseline-specific logic\n",
    "            if model_type == \"Baseline\":\n",
    "                n_trials, num_epochs = (1, 1)\n",
    "                if input_name != \"Indexes\":\n",
    "                    continue\n",
    "                \n",
    "                # Process both BaselineAverage and BaselineLastDifference\n",
    "                baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "                for baseline_type in baseline_variants:\n",
    "                    model_name = f\"{baseline_type}{input_name}\"\n",
    "                    print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                    # Construct the results directory path\n",
    "                    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "                    results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                    # Skip if results file doesn't exist\n",
    "                    if not os.path.exists(results_file):\n",
    "                        print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # Load results from CSV\n",
    "                    results = pd.read_csv(results_file)\n",
    "                    maes = results[\"test_mae\"].values\n",
    "                    rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                    # Add results to the dataframe\n",
    "                    for i in range(len(maes)):  # Assuming results have folds\n",
    "                        results_df = pd.concat([\n",
    "                            results_df,\n",
    "                            pd.DataFrame([{\n",
    "                                \"model\": baseline_type,\n",
    "                                \"input\": input_name,\n",
    "                                \"motif\": i + 1,\n",
    "                                \"mae\": maes[i],\n",
    "                                \"rmse\": rmses[i]\n",
    "                            }])\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                n_trials = 100\n",
    "                num_epochs = 500\n",
    "\n",
    "                model_name = f\"{model_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": model_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"motif\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input motif        mae       rmse\n",
      "0          BaselineAverage         Indexes   1.0  12.951233  15.588457\n",
      "1   BaselineLastDifference         Indexes   1.0  18.528498  29.364649\n",
      "2                      CNN         Indexes   1.0  10.261559  12.555540\n",
      "3                      CNN          Series   1.0   9.594777  11.600351\n",
      "4                      CNN  Series_Masking   1.0  11.497563  13.672227\n",
      "5                     FFNN         Indexes   1.0  11.138082  13.242543\n",
      "6                     FFNN          Series   1.0   9.336295  11.407887\n",
      "7                     FFNN  Series_Masking   1.0   9.164855  11.873960\n",
      "8                     LSTM         Indexes   1.0   9.783668  12.221509\n",
      "9                     LSTM          Series   1.0   9.792237  12.216532\n",
      "10                    LSTM  Series_Masking   1.0   9.555272  11.882629\n",
      "11                     TCN         Indexes   1.0   9.896350  12.022695\n",
      "12                     TCN          Series   1.0   9.065550  11.506223\n",
      "13                     TCN  Series_Masking   1.0   9.447861  11.722694\n",
      "14             Transformer         Indexes   1.0  10.910243  12.919132\n",
      "15             Transformer          Series   1.0  11.465725  14.569164\n",
      "16             Transformer  Series_Masking   1.0   9.978911  12.899248\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_1</th>\n",
       "      <th>InputType_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>InputType_2</th>\n",
       "      <th>Metric</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.041331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.045609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_1 InputType_1          Model_2 InputType_2 Metric   P-Value\n",
       "0     TCN      Series  BaselineAverage     Indexes    mae  0.041331\n",
       "1     TCN      Series  BaselineAverage     Indexes   rmse  0.045609"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "models_1 = [\"TCN\" ]\n",
    "input_types_1 = [\"Series\"]\n",
    "models_2 = [\"BaselineAverage\" ]\n",
    "input_types_2 = [\"Indexes\"]\n",
    "\n",
    "# Filter data for the selected input types\n",
    "\n",
    "results = []\n",
    "for model1 in models_1:\n",
    "    for model2 in models_2:\n",
    "        for input_1 in input_types_1:\n",
    "            for input_2 in input_types_2:\n",
    "                for metric in [\"mae\", \"rmse\"]:\n",
    "\n",
    "                    data1 = results_df[(results_df['model'] == model1) & (results_df['input'] == input_1)].sort_values('motif')[metric]\n",
    "                    data2 = results_df[(results_df['model'] == model2) & (results_df['input'] == input_2)].sort_values('motif')[metric]\n",
    "\n",
    "                    if len(data1) == len(data2):\n",
    "                        t_stat, p_value = ttest_rel(data1, data2, alternative='less')\n",
    "                        results.append({\n",
    "                            \"Model_1\": model1,\n",
    "                            \"InputType_1\": input_1,\n",
    "                            \"Model_2\": model2,\n",
    "                            \"InputType_2\": input_2,\n",
    "                            \"Metric\": metric,\n",
    "                            \"P-Value\": p_value\n",
    "                        })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "pval_results_df = pd.DataFrame(results)\n",
    "pval_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
