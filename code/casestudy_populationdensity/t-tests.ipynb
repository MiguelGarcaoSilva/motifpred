{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/populationdensity\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/populationdensity\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/populationdensity\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, TOWNSHIP_NAME, VARIABLES, NORMALIZE_FLAGS, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS, NTOP_MOTIFS, MOTIF_SIZE\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=\"#Matches\", ascending=False).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum_terminals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_time</th>\n",
       "      <th>township_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-15 00:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>260700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 01:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>276675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 02:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>284563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 03:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>279563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 04:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>281460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 19:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>391367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 20:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>352361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 21:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>388246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 22:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>360169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 23:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>349164.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1848 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum_terminals\n",
       "one_time            township_name                \n",
       "2021-09-15 00:00:00 Avenidas Novas       260700.0\n",
       "2021-09-15 01:00:00 Avenidas Novas       276675.0\n",
       "2021-09-15 02:00:00 Avenidas Novas       284563.0\n",
       "2021-09-15 03:00:00 Avenidas Novas       279563.0\n",
       "2021-09-15 04:00:00 Avenidas Novas       281460.0\n",
       "...                                           ...\n",
       "2021-11-30 19:00:00 Avenidas Novas       391367.0\n",
       "2021-11-30 20:00:00 Avenidas Novas       352361.0\n",
       "2021-11-30 21:00:00 Avenidas Novas       388246.0\n",
       "2021-11-30 22:00:00 Avenidas Novas       360169.0\n",
       "2021-11-30 23:00:00 Avenidas Novas       349164.0\n",
       "\n",
       "[1848 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "data_df = pd.read_csv(\n",
    "    DATASET_PATH,\n",
    "    parse_dates=[\"one_time\"],\n",
    "    date_format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "data_df = data_df[data_df[\"township_name\"] == TOWNSHIP_NAME]\n",
    "#set index to one_time and township_name\n",
    "data_df = data_df.set_index([\"one_time\", \"township_name\"]).sort_index()[VARIABLES]\n",
    "data = data_df.to_numpy().T\n",
    "data_univar = data[0]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3026, 0.8867, 0.8263],\n",
      "        [0.3065, 0.8353, 0.5215],\n",
      "        [0.6699, 0.6728, 0.7548],\n",
      "        [0.2313, 0.5837, 0.6572],\n",
      "        [0.8870, 0.4751, 0.6564]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 27 with size 12 and 58 indexes\n",
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Evaluating motif 6 with size 12 and 47 indexes\n",
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Evaluating motif 24 with size 12 and 46 indexes\n",
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Evaluating motif 12 with size 12 and 44 indexes\n",
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Evaluating motif 7 with size 12 and 38 indexes\n",
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset, get_best_model_results_traindevtest, plot_best_model_results_traindevtest, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import run_optuna_study, get_preds_best_config_train_val_test\n",
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TemporalConvNet\n",
    "from models.transformer_pytorch import TimeSeriesTransformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "\n",
    "models = [\"Baseline\"]\n",
    "inputs = [\"Indexes\"]\n",
    "\n",
    "lookback_period = 24*7*3 #window size\n",
    "step = 1 #step size for the sliding window\n",
    "forecast_period = 24*2 #forward window size\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import ast\n",
    "import pandas as pd\n",
    "from utils.utils import create_dataset, get_best_model_results_traindevtest, plot_best_model_results_traindevtest, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TemporalConvNet\n",
    "from models.transformer_pytorch import TimeSeriesTransformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "\n",
    "models = [\"FFNN\"]\n",
    "inputs = [\"Series\", \"Series_Masking\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "    print(f\"{model_name} - Motif {motif_id}: Best epoch: {best_epoch}, Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "    \n",
    "    _, _, _, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "    \n",
    "    #plot_best_model_results_traindevtest(\n",
    "    #    study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}_best_results.png\")\n",
    "    #)\n",
    "    \n",
    "    #plot_preds_vs_truevalues(\n",
    "    #    np.ravel(all_true_values), np.ravel(all_predictions), fold=0,\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}_fold_{0}_predictions.png\")\n",
    "    #)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse  = get_best_model_results_traindevtest(study)\n",
    "    print(f\"{model_name} - Motif {motif_id}: Best epoch: {best_epoch}, Test Loss: {best_model_test_loss}, Test MAE: {best_model_test_mae}, Test RMSE: {best_model_test_rmse}\")\n",
    "    \n",
    "    _, _, _, retrained_test_losses, retrained_test_mae, retrained_test_rmse, retrained_all_predictions, retrained_all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(test_loss, retrained_test_losses, atol=1):\n",
    "        raise Exception(\"Best model test loss does not match the one obtained from the study\")\n",
    "    \n",
    "    #plot_best_model_results_traindevtest(\n",
    "    #    study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}_best_results.png\")\n",
    "    #)\n",
    "    \n",
    "    #plot_preds_vs_truevalues(\n",
    "    #    np.ravel(all_true_values), np.ravel(all_predictions), fold=0,\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}_fold_{0}_predictions.png\")\n",
    "    #)\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, lookback_period, step, forecast_period, motif_indexes, MOTIF_SIZE)\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            if model_type == \"Baseline\" and input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            X = {\"X_series\": X_series} if input_name == \"Series\" else {\"X_series\": X_series, \"X_mask\": X_mask} if input_name == \"Series_Masking\" else {\"X_indices\": X_indices}\n",
    "            \n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "            \n",
    "            if model_type == \"Baseline\":\n",
    "                for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                    process_baseline_model(model_class, input_name, X, NORMALIZE_FLAGS, num_epochs, seed, pipeline, y, i+1)\n",
    "            else:\n",
    "                process_non_baseline_model(model_type, model_params_map[model_type], input_name, X, NORMALIZE_FLAGS, num_epochs, seed, pipeline, y, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing motif 27 with 58 indexes\n",
      "Results file for FFNNIndexes motif 27 not found. Skipping.\n",
      "Results file for LSTMSeries motif 27 not found. Skipping.\n",
      "Results file for LSTMSeries_Masking motif 27 not found. Skipping.\n",
      "Results file for LSTMIndexes motif 27 not found. Skipping.\n",
      "Results file for CNNSeries motif 27 not found. Skipping.\n",
      "Results file for CNNSeries_Masking motif 27 not found. Skipping.\n",
      "Results file for CNNIndexes motif 27 not found. Skipping.\n",
      "Results file for TCNSeries motif 27 not found. Skipping.\n",
      "Results file for TCNSeries_Masking motif 27 not found. Skipping.\n",
      "Results file for TCNIndexes motif 27 not found. Skipping.\n",
      "Results file for TransformerSeries motif 27 not found. Skipping.\n",
      "Results file for TransformerSeries_Masking motif 27 not found. Skipping.\n",
      "Results file for TransformerIndexes motif 27 not found. Skipping.\n",
      "Results file for BaselineIndexes motif 27 not found. Skipping.\n",
      "Processing motif 6 with 47 indexes\n",
      "Results file for FFNNIndexes motif 6 not found. Skipping.\n",
      "Results file for LSTMSeries motif 6 not found. Skipping.\n",
      "Results file for LSTMSeries_Masking motif 6 not found. Skipping.\n",
      "Results file for LSTMIndexes motif 6 not found. Skipping.\n",
      "Results file for CNNSeries motif 6 not found. Skipping.\n",
      "Results file for CNNSeries_Masking motif 6 not found. Skipping.\n",
      "Results file for CNNIndexes motif 6 not found. Skipping.\n",
      "Results file for TCNSeries motif 6 not found. Skipping.\n",
      "Results file for TCNSeries_Masking motif 6 not found. Skipping.\n",
      "Results file for TCNIndexes motif 6 not found. Skipping.\n",
      "Results file for TransformerSeries motif 6 not found. Skipping.\n",
      "Results file for TransformerSeries_Masking motif 6 not found. Skipping.\n",
      "Results file for TransformerIndexes motif 6 not found. Skipping.\n",
      "Results file for BaselineIndexes motif 6 not found. Skipping.\n",
      "Processing motif 24 with 46 indexes\n",
      "Results file for FFNNIndexes motif 24 not found. Skipping.\n",
      "Results file for LSTMSeries motif 24 not found. Skipping.\n",
      "Results file for LSTMSeries_Masking motif 24 not found. Skipping.\n",
      "Results file for LSTMIndexes motif 24 not found. Skipping.\n",
      "Results file for CNNSeries motif 24 not found. Skipping.\n",
      "Results file for CNNSeries_Masking motif 24 not found. Skipping.\n",
      "Results file for CNNIndexes motif 24 not found. Skipping.\n",
      "Results file for TCNSeries motif 24 not found. Skipping.\n",
      "Results file for TCNSeries_Masking motif 24 not found. Skipping.\n",
      "Results file for TCNIndexes motif 24 not found. Skipping.\n",
      "Results file for TransformerSeries motif 24 not found. Skipping.\n",
      "Results file for TransformerSeries_Masking motif 24 not found. Skipping.\n",
      "Results file for TransformerIndexes motif 24 not found. Skipping.\n",
      "Results file for BaselineIndexes motif 24 not found. Skipping.\n",
      "Processing motif 12 with 44 indexes\n",
      "Results file for FFNNIndexes motif 12 not found. Skipping.\n",
      "Results file for LSTMSeries motif 12 not found. Skipping.\n",
      "Results file for LSTMSeries_Masking motif 12 not found. Skipping.\n",
      "Results file for LSTMIndexes motif 12 not found. Skipping.\n",
      "Results file for CNNSeries motif 12 not found. Skipping.\n",
      "Results file for CNNSeries_Masking motif 12 not found. Skipping.\n",
      "Results file for CNNIndexes motif 12 not found. Skipping.\n",
      "Results file for TCNSeries motif 12 not found. Skipping.\n",
      "Results file for TCNSeries_Masking motif 12 not found. Skipping.\n",
      "Results file for TCNIndexes motif 12 not found. Skipping.\n",
      "Results file for TransformerSeries motif 12 not found. Skipping.\n",
      "Results file for TransformerSeries_Masking motif 12 not found. Skipping.\n",
      "Results file for TransformerIndexes motif 12 not found. Skipping.\n",
      "Results file for BaselineIndexes motif 12 not found. Skipping.\n",
      "Processing motif 7 with 38 indexes\n",
      "Results file for FFNNIndexes motif 7 not found. Skipping.\n",
      "Results file for LSTMSeries motif 7 not found. Skipping.\n",
      "Results file for LSTMSeries_Masking motif 7 not found. Skipping.\n",
      "Results file for LSTMIndexes motif 7 not found. Skipping.\n",
      "Results file for CNNSeries motif 7 not found. Skipping.\n",
      "Results file for CNNSeries_Masking motif 7 not found. Skipping.\n",
      "Results file for CNNIndexes motif 7 not found. Skipping.\n",
      "Results file for TCNSeries motif 7 not found. Skipping.\n",
      "Results file for TCNSeries_Masking motif 7 not found. Skipping.\n",
      "Results file for TCNIndexes motif 7 not found. Skipping.\n",
      "Results file for TransformerSeries motif 7 not found. Skipping.\n",
      "Results file for TransformerSeries_Masking motif 7 not found. Skipping.\n",
      "Results file for TransformerIndexes motif 7 not found. Skipping.\n",
      "Results file for BaselineIndexes motif 7 not found. Skipping.\n",
      "  model           input motif        mae       rmse\n",
      "0  FFNN          Series    27   6.857397   9.644611\n",
      "1  FFNN  Series_Masking    27   8.810878  11.362280\n",
      "2  FFNN          Series     6   6.352315  11.469268\n",
      "3  FFNN  Series_Masking     6  10.451489  11.203886\n",
      "4  FFNN          Series    24  11.243575  13.804465\n",
      "5  FFNN  Series_Masking    24   9.418563  12.882505\n",
      "6  FFNN          Series    12  10.634895  16.875971\n",
      "7  FFNN  Series_Masking    12  10.664497  13.937145\n",
      "8  FFNN          Series     7  12.560537  15.545620\n",
      "9  FFNN  Series_Masking     7  11.001407  16.182066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_171549/4066975937.py:29: FutureWarning:\n",
      "\n",
      "The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"motif\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    motif_id = i + 1\n",
    "    print(f\"Processing motif {motif_id} with {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            if model_type == \"Baseline\" and input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            model_name = f\"{model_type}{input_name}\"\n",
    "            model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "            results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "            \n",
    "            if not os.path.exists(results_file):\n",
    "                print(f\"Results file for {model_name} motif {motif_id} not found. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            results = pd.read_csv(results_file)\n",
    "            test_mae = results[\"test_mae\"].values[0]\n",
    "            test_rmse = results[\"test_rmse\"].values[0]\n",
    "            \n",
    "            results_df = pd.concat([\n",
    "                results_df,\n",
    "                pd.DataFrame([{\n",
    "                    \"model\": model_type,\n",
    "                    \"input\": input_name,\n",
    "                    \"motif\": motif_id,\n",
    "                    \"mae\": test_mae,\n",
    "                    \"rmse\": test_rmse\n",
    "                }])\n",
    "            ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model           input motif        mae       rmse\n",
      "0  FFNN          Series  15.2   9.529744  13.467987\n",
      "1  FFNN  Series_Masking  15.2  10.069367  13.113577\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
