{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 09:57:24,829 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/populationdensity\n",
      "2025-02-05 09:57:24,830 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/populationdensity\n",
      "2025-02-05 09:57:24,830 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/populationdensity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/populationdensity\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/populationdensity\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/populationdensity\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, TOWNSHIP_NAME, VARIABLES, NORMALIZE_FLAGS, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS, NTOP_MOTIFS, MOTIF_SIZE\n",
    "from config import LOOKBACK_PERIOD, STEP, FORECAST_PERIOD\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=[\"#Matches\", \"ID\"], ascending=[False, True]).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum_terminals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one_time</th>\n",
       "      <th>township_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-09-15 00:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>260700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 01:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>276675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 02:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>284563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 03:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>279563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-15 04:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>281460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 19:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>391367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 20:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>352361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 21:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>388246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 22:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>360169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 23:00:00</th>\n",
       "      <th>Avenidas Novas</th>\n",
       "      <td>349164.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1848 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sum_terminals\n",
       "one_time            township_name                \n",
       "2021-09-15 00:00:00 Avenidas Novas       260700.0\n",
       "2021-09-15 01:00:00 Avenidas Novas       276675.0\n",
       "2021-09-15 02:00:00 Avenidas Novas       284563.0\n",
       "2021-09-15 03:00:00 Avenidas Novas       279563.0\n",
       "2021-09-15 04:00:00 Avenidas Novas       281460.0\n",
       "...                                           ...\n",
       "2021-11-30 19:00:00 Avenidas Novas       391367.0\n",
       "2021-11-30 20:00:00 Avenidas Novas       352361.0\n",
       "2021-11-30 21:00:00 Avenidas Novas       388246.0\n",
       "2021-11-30 22:00:00 Avenidas Novas       360169.0\n",
       "2021-11-30 23:00:00 Avenidas Novas       349164.0\n",
       "\n",
       "[1848 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "data_df = pd.read_csv(\n",
    "    DATASET_PATH,\n",
    "    parse_dates=[\"one_time\"],\n",
    "    date_format=\"%Y-%m-%d %H:%M:%S\",\n",
    "    index_col=0,\n",
    ")\n",
    "\n",
    "data_df = data_df[data_df[\"township_name\"] == TOWNSHIP_NAME]\n",
    "#set index to one_time and township_name\n",
    "data_df = data_df.set_index([\"one_time\", \"township_name\"]).sort_index()[VARIABLES]\n",
    "data = data_df.to_numpy().T\n",
    "data_univar = data[0]\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 27 with size 12 and 58  indexes\n",
      "X_series shape: torch.Size([1173, 504, 1])\n",
      "X_indices shape: torch.Size([1173, 18, 1])\n",
      "X_mask shape: torch.Size([1173, 504])\n",
      "y shape: torch.Size([1173, 1])\n",
      "Best epoch: 24\n",
      "Test Loss: 121.37779998779297, Test MAE: 6.261159420013428, Test RMSE: 11.017159461975098\n",
      "Evaluating motif 6 with size 12 and 47  indexes\n",
      "X_series shape: torch.Size([1032, 504, 1])\n",
      "X_indices shape: torch.Size([1032, 16, 1])\n",
      "X_mask shape: torch.Size([1032, 504])\n",
      "y shape: torch.Size([1032, 1])\n",
      "Best epoch: 3\n",
      "Test Loss: 127.28821563720703, Test MAE: 8.923789024353027, Test RMSE: 11.282207489013672\n",
      "Evaluating motif 24 with size 12 and 46  indexes\n",
      "X_series shape: torch.Size([1122, 504, 1])\n",
      "X_indices shape: torch.Size([1122, 16, 1])\n",
      "X_mask shape: torch.Size([1122, 504])\n",
      "y shape: torch.Size([1122, 1])\n",
      "Best epoch: 10\n",
      "Test Loss: 423.5412902832031, Test MAE: 18.11562728881836, Test RMSE: 20.58011817932129\n",
      "Evaluating motif 12 with size 12 and 44  indexes\n",
      "X_series shape: torch.Size([1050, 504, 1])\n",
      "X_indices shape: torch.Size([1050, 15, 1])\n",
      "X_mask shape: torch.Size([1050, 504])\n",
      "y shape: torch.Size([1050, 1])\n",
      "Best epoch: 27\n",
      "Test Loss: 159.35511779785156, Test MAE: 9.231277465820312, Test RMSE: 12.6235933303833\n",
      "Evaluating motif 7 with size 12 and 38  indexes\n",
      "X_series shape: torch.Size([979, 504, 1])\n",
      "X_indices shape: torch.Size([979, 12, 1])\n",
      "X_mask shape: torch.Size([979, 504])\n",
      "y shape: torch.Size([979, 1])\n",
      "Best epoch: 9\n",
      "Test Loss: 300.7707214355469, Test MAE: 14.796771049499512, Test RMSE: 17.342742919921875\n",
      "Aggregated Results Across Top 5 Motifs:\n",
      "Mean Test Loss: 226.4666290283203 Â± 118.10461029842446\n",
      "Mean Test MAE: 11.465724849700928 Â± 4.332638120092395\n",
      "Mean Test RMSE: 14.569164276123047 Â± 3.7690947121204683\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.transformer_pytorch import Transformer\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i} with size {MOTIF_SIZE} and {len(motif_indexes)}  indexes\")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"Transformer\"\n",
    "    model_name = \"TransformerSeries\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"d_model\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[64, 128, 256, 512]]\n",
    "        },\n",
    "        \"n_heads\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[2, 4, 8, 16]]\n",
    "        },\n",
    "        \"e_layers\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[1, 2, 3]]\n",
    "        },\n",
    "        \"dim_feedforward\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[128, 256, 512]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[4, 8, 16, 32]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_series\": X_series}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} Â± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} Â± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} Â± {std_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 27 with size 12 and 58  indexes\n",
      "X_series shape: torch.Size([1173, 504, 1])\n",
      "X_indices shape: torch.Size([1173, 18, 1])\n",
      "X_mask shape: torch.Size([1173, 504])\n",
      "y shape: torch.Size([1173, 1])\n",
      "Best epoch: 71\n",
      "Test Loss: 113.2253189086914, Test MAE: 7.82368803024292, Test RMSE: 10.640738487243652\n",
      "Evaluating motif 6 with size 12 and 47  indexes\n",
      "X_series shape: torch.Size([1032, 504, 1])\n",
      "X_indices shape: torch.Size([1032, 16, 1])\n",
      "X_mask shape: torch.Size([1032, 504])\n",
      "y shape: torch.Size([1032, 1])\n",
      "Best epoch: 18\n",
      "Test Loss: 127.4791488647461, Test MAE: 8.904017448425293, Test RMSE: 11.290666580200195\n",
      "Evaluating motif 24 with size 12 and 46  indexes\n",
      "X_series shape: torch.Size([1122, 504, 1])\n",
      "X_indices shape: torch.Size([1122, 16, 1])\n",
      "X_mask shape: torch.Size([1122, 504])\n",
      "y shape: torch.Size([1122, 1])\n",
      "Best epoch: 8\n",
      "Test Loss: 154.69862365722656, Test MAE: 10.222691535949707, Test RMSE: 12.437789916992188\n",
      "Evaluating motif 12 with size 12 and 44  indexes\n",
      "X_series shape: torch.Size([1050, 504, 1])\n",
      "X_indices shape: torch.Size([1050, 15, 1])\n",
      "X_mask shape: torch.Size([1050, 504])\n",
      "y shape: torch.Size([1050, 1])\n",
      "Best epoch: 39\n",
      "Test Loss: 198.8688507080078, Test MAE: 10.668267250061035, Test RMSE: 14.102087020874023\n",
      "Evaluating motif 7 with size 12 and 38  indexes\n",
      "X_series shape: torch.Size([979, 504, 1])\n",
      "X_indices shape: torch.Size([979, 12, 1])\n",
      "X_mask shape: torch.Size([979, 504])\n",
      "y shape: torch.Size([979, 1])\n",
      "Best epoch: 15\n",
      "Test Loss: 256.79925537109375, Test MAE: 12.275888442993164, Test RMSE: 16.02495765686035\n",
      "Aggregated Results Across Top 5 Motifs:\n",
      "Mean Test Loss: 170.21423950195313 Â± 52.2164937421616\n",
      "Mean Test MAE: 9.978910541534423 Â± 1.5238850717432673\n",
      "Mean Test RMSE: 12.899247932434083 Â± 1.9554143057079503\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.transformer_pytorch import Transformer\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i} with size {MOTIF_SIZE} and {len(motif_indexes)}  indexes\")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"Transformer\"\n",
    "    model_name = \"TransformerSeries_Masking\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"d_model\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[64, 128, 256, 512]]\n",
    "        },\n",
    "        \"n_heads\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[2, 4, 8, 16]]\n",
    "        },\n",
    "        \"e_layers\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[1, 2, 3]]\n",
    "        },\n",
    "        \"dim_feedforward\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[128, 256, 512]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[4, 8, 16, 32]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} Â± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} Â± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} Â± {std_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 27 with size 12 and 58  indexes\n",
      "X_series shape: torch.Size([1173, 504, 1])\n",
      "X_indices shape: torch.Size([1173, 18, 1])\n",
      "X_mask shape: torch.Size([1173, 504])\n",
      "y shape: torch.Size([1173, 1])\n",
      "Best epoch: 101\n",
      "Test Loss: 204.63050842285156, Test MAE: 12.237844467163086, Test RMSE: 14.304911613464355\n",
      "Evaluating motif 6 with size 12 and 47  indexes\n",
      "X_series shape: torch.Size([1032, 504, 1])\n",
      "X_indices shape: torch.Size([1032, 16, 1])\n",
      "X_mask shape: torch.Size([1032, 504])\n",
      "y shape: torch.Size([1032, 1])\n",
      "Best epoch: 4\n",
      "Test Loss: 127.53108215332031, Test MAE: 8.916876792907715, Test RMSE: 11.29296588897705\n",
      "Evaluating motif 24 with size 12 and 46  indexes\n",
      "X_series shape: torch.Size([1122, 504, 1])\n",
      "X_indices shape: torch.Size([1122, 16, 1])\n",
      "X_mask shape: torch.Size([1122, 504])\n",
      "y shape: torch.Size([1122, 1])\n",
      "Best epoch: 5\n",
      "Test Loss: 137.69354248046875, Test MAE: 9.816875457763672, Test RMSE: 11.734289169311523\n",
      "Evaluating motif 12 with size 12 and 44  indexes\n",
      "X_series shape: torch.Size([1050, 504, 1])\n",
      "X_indices shape: torch.Size([1050, 15, 1])\n",
      "X_mask shape: torch.Size([1050, 504])\n",
      "y shape: torch.Size([1050, 1])\n",
      "Best epoch: 7\n",
      "Test Loss: 179.8419189453125, Test MAE: 11.584332466125488, Test RMSE: 13.410514831542969\n",
      "Evaluating motif 7 with size 12 and 38  indexes\n",
      "X_series shape: torch.Size([979, 504, 1])\n",
      "X_indices shape: torch.Size([979, 12, 1])\n",
      "X_mask shape: torch.Size([979, 504])\n",
      "y shape: torch.Size([979, 1])\n",
      "Best epoch: 4\n",
      "Test Loss: 191.90501403808594, Test MAE: 11.995287895202637, Test RMSE: 13.852978706359863\n",
      "Aggregated Results Across Top 5 Motifs:\n",
      "Mean Test Loss: 168.3204132080078 Â± 30.361739883380096\n",
      "Mean Test MAE: 10.91024341583252 Â± 1.3086791896070444\n",
      "Mean Test RMSE: 12.919132041931153 Â± 1.1901412226522652\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.transformer_pytorch import Transformer\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i} with size {MOTIF_SIZE} and {len(motif_indexes)}  indexes\")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"Transformer\"\n",
    "    model_name = \"TransformerIndices\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"d_model\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[64, 128, 256, 512]]\n",
    "        },\n",
    "        \"n_heads\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[2, 4, 8, 16]]\n",
    "        },\n",
    "        \"e_layers\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[1, 2, 3]]\n",
    "        },\n",
    "        \"dim_feedforward\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[128, 256, 512]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[4, 8, 16, 32]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_indices\": X_indices}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} Â± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} Â± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} Â± {std_test_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
