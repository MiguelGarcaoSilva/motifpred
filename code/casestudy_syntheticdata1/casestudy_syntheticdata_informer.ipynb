{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "from config import results_dir, images_dir, data_dir\n",
    "\n",
    "print(f\"Results will be saved in: {results_dir}\")\n",
    "print(f\"Images will be saved in: {images_dir}\")\n",
    "print(f\"Data will be accessed from: {data_dir}\")\n",
    "\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0    10    22 ... 99922 99956 99992]\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "n = 100000 #number of data points\n",
    "k = 3 #number of variables\n",
    "p = 5 # pattern length\n",
    "variable_indexes = np.arange(k)\n",
    "variables_pattern = [0,2]\n",
    "\n",
    "dataset_path = os.path.join(data_dir, \"scenario1_n={}_k={}_p={}_min_step={}_max_step={}_variables={}.csv\".format(n, k, p, 5, 45, variables_pattern))\n",
    "motif_indexes_path = os.path.join(data_dir, \"motif_indexes_scenario1_n={}_k={}_p={}_min_step={}_max_step={}.csv\".format(n, k, p, 5, 45))\n",
    "data = np.genfromtxt(dataset_path, delimiter=\",\").astype(int).reshape((k, n))\n",
    "motif_indexes = np.genfromtxt(motif_indexes_path, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 15997 15998 15999] TEST: [16000 16001 16002 ... 19997 19998 19999]\n",
      "TRAIN: [20000 20001 20002 ... 35997 35998 35999] TEST: [36000 36001 36002 ... 39997 39998 39999]\n",
      "TRAIN: [40000 40001 40002 ... 55997 55998 55999] TEST: [56000 56001 56002 ... 59997 59998 59999]\n",
      "TRAIN: [60000 60001 60002 ... 75997 75998 75999] TEST: [76000 76001 76002 ... 79997 79998 79999]\n",
      "TRAIN: [80000 80001 80002 ... 95997 95998 95999] TEST: [96000 96001 96002 ... 99997 99998 99999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.timeseries_split import BlockingTimeSeriesSplit\n",
    "\n",
    "#create index  \n",
    "indexes = np.arange(len(data[0]))\n",
    "\n",
    "#split data\n",
    "tscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(indexes)):\n",
    "    # Plot train and test indices\n",
    "    ax.plot(train_index, np.zeros_like(train_index) + i, 'o', color='lightblue')\n",
    "    ax.plot(test_index, np.zeros_like(test_index) + i, 'o', color='red')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "\n",
    "ax.set_yticks(np.arange(5), [\"Fold {}\".format(i) for i in range(1, 6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: torch.Size([19979, 100, 3])\n",
      "X2 shape: torch.Size([19979, 6, 1])\n",
      "y shape: torch.Size([19979, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#x1: past window, x2: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X1, X2, y = create_dataset(data, variable_indexes, lookback_period, step, forecast_period, motif_indexes)\n",
    "\n",
    "# X1, X2, and y are now PyTorch tensors\n",
    "print(\"X1 shape:\", X1.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X2 shape:\", X2.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 14:53:15,825] A new study created in memory with name: no-name-198aae6e-9179-4d46-b901-29abc540ecfd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 117, with best epoch being 88\n",
      "Early stopping at epoch 113, with best epoch being 85\n",
      "Early stopping at epoch 115, with best epoch being 104\n",
      "Early stopping at epoch 129, with best epoch being 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 15:17:03,591] Trial 0 finished with value: 108.98028259277343 and parameters: {'learning_rate': 2.6565450821928437e-05, 'd_model': 256, 'n_heads': 3, 'attn': 'prob', 'e_layers': 2, 'd_layers': 2, 'dropout': 0.25599658869775177, 'batch_size': 16}. Best is trial 0 with value: 108.98028259277343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 113, with best epoch being 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-12-20 15:17:30,697] Trial 1 failed with parameters: {'learning_rate': 4.946096107589924e-05, 'd_model': 64, 'n_heads': 7, 'attn': 'prob', 'e_layers': 1, 'd_layers': 2, 'dropout': 0.42903854381849826, 'batch_size': 32} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 89, in objective\n",
      "    trial_val_loss, _, _ = objective_func(trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparameters, model_params_keys)  # Pass hyperparameters\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 422, in run_cross_val\n",
      "    fold_val_loss, model, best_epoch, train_losses, validation_losses = self.train_model(\n",
      "                                                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 295, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-20 15:17:30,698] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_trials_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mrun_optuna_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cross_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuggestion_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m study \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(result_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     55\u001b[0m print_study_results(study)\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:94\u001b[0m, in \u001b[0;36mrun_optuna_study\u001b[0;34m(objective_func, model_class, model_type, suggestion_dict, model_params_keys, seed, X1, X2, y, results_folder, n_trials, num_epochs)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Let Optuna manage trials and pass them to the objective function\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, file_name)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Save and log the study results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:89\u001b[0m, in \u001b[0;36mrun_optuna_study.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     86\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m extract_hyperparameters(trial, suggestion_dict, model_type\u001b[38;5;241m=\u001b[39mmodel_type)\n\u001b[1;32m     88\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()  \u001b[38;5;66;03m# Define the criterion here\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m trial_val_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass hyperparameters\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:422\u001b[0m, in \u001b[0;36mModelTrainingPipeline.run_cross_val\u001b[0;34m(self, trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparams, model_params_keys)\u001b[0m\n\u001b[1;32m    418\u001b[0m             model \u001b[38;5;241m=\u001b[39m model_class(enc_in\u001b[38;5;241m=\u001b[39mX1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], dec_in\u001b[38;5;241m=\u001b[39mX1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], c_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  seq_len\u001b[38;5;241m=\u001b[39mX1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], label_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(X1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m), out_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_hyperparams, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# Train the model using the existing train_model method\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m fold_val_loss, model, best_epoch, train_losses, validation_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdual_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Test evaluation for other models\u001b[39;00m\n\u001b[1;32m    428\u001b[0m fold_test_loss, test_fold_predictions, test_fold_true_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_test_set(\n\u001b[1;32m    429\u001b[0m     model, test_loader, criterion, dual_input\u001b[38;5;241m=\u001b[39m(X2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    430\u001b[0m )\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:295\u001b[0m, in \u001b[0;36mModelTrainingPipeline.train_model\u001b[0;34m(self, model, criterion, optimizer, train_loader, val_loader, num_epochs, dual_input)\u001b[0m\n\u001b[1;32m    293\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(predictions, batch_y)\n\u001b[1;32m    294\u001b[0m     epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 295\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    298\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m epoch_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.informer_pytorch import Informer\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import print_study_results, plot_best_model_results\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "model_type = \"Informer\"\n",
    "model_name = \"InformerSeries\"\n",
    "\n",
    "suggestion_dict = {\n",
    "    \"learning_rate\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [1e-5, 1e-3],\n",
    "        \"kwargs\": {\"log\": True}\n",
    "    },\n",
    "    \"d_model\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[64, 128, 256, 512]]\n",
    "    },\n",
    "    \"n_heads\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2, 4, 8, 16]]\n",
    "    },\n",
    "    \"attn\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[\"prob\", \"full\"]]\n",
    "    },\n",
    "    \"e_layers\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2, 3]]\n",
    "    },\n",
    "    \"d_layers\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2]]\n",
    "    },\n",
    "    \"dropout\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [0.0, 0.5]\n",
    "    },\n",
    "    \"batch_size\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[16, 32, 64, 128]]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_params_keys = [\"n_heads\", \"d_model\", \"attn\", \"e_layers\", \"d_layers\", \"dropout\"]\n",
    "\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "run_optuna_study(pipeline.run_cross_val, Informer, model_type, suggestion_dict, model_params_keys, seed, X1, None, y, result_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "print_study_results(study)\n",
    "plot_best_model_results(\n",
    "    study.trials_dataframe(),\n",
    "    save_path=os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_losses.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-18 19:25:05,996] A new study created in memory with name: no-name-96cb2360-59d4-4609-b5d0-0a3cac7499e8\n",
      "[W 2024-12-18 19:25:14,332] Trial 0 failed with parameters: {'learning_rate': 2.6565450821928437e-05, 'kernel_size': 7, 'num_blocks': 5, 'dropout': 0.12704166510234777, 'batch_size': 16, 'block_channels_0': 16, 'block_channels_1': 32, 'block_channels_2': 32, 'block_channels_3': 16, 'block_channels_4': 16} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 88, in objective\n",
      "    trial_val_loss, _, _ = objective_func(trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparameters, model_params_keys)  # Pass hyperparameters\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 411, in run_cross_val\n",
      "    fold_val_loss, model, best_epoch, train_losses, validation_losses = self.train_model(\n",
      "                                                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 302, in train_model\n",
      "    predictions = model(batch_X1, batch_X2)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/models/tcn_pytorch.py\", line 123, in forward\n",
      "    y1 = self.network(x)\n",
      "         ^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/models/tcn_pytorch.py\", line 93, in forward\n",
      "    out = self.net(x)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 375, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/conv.py\", line 370, in _conv_forward\n",
      "    return F.conv1d(\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-18 19:25:14,335] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m result_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_trials_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(result_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mrun_optuna_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cross_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTemporalConvNet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuggestion_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasking_X1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m study \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(result_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     52\u001b[0m print_study_results(study)\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:93\u001b[0m, in \u001b[0;36mrun_optuna_study\u001b[0;34m(objective_func, model_class, model_type, suggestion_dict, model_params_keys, seed, X1, X2, y, results_folder, n_trials, num_epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Let Optuna manage trials and pass them to the objective function\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, file_name)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Save and log the study results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:88\u001b[0m, in \u001b[0;36mrun_optuna_study.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     85\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m extract_hyperparameters(trial, suggestion_dict, model_type\u001b[38;5;241m=\u001b[39mmodel_type)\n\u001b[1;32m     87\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()  \u001b[38;5;66;03m# Define the criterion here\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m trial_val_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass hyperparameters\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:411\u001b[0m, in \u001b[0;36mModelTrainingPipeline.run_cross_val\u001b[0;34m(self, trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparams, model_params_keys)\u001b[0m\n\u001b[1;32m    406\u001b[0m         model \u001b[38;5;241m=\u001b[39m model_class(input_channels\u001b[38;5;241m=\u001b[39mX1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_hyperparams)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Train the model using the existing train_model method\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m fold_val_loss, model, best_epoch, train_losses, validation_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdual_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;66;03m# Test evaluation for other models\u001b[39;00m\n\u001b[1;32m    417\u001b[0m fold_test_loss, test_fold_predictions, test_fold_true_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_test_set(\n\u001b[1;32m    418\u001b[0m     model, test_loader, criterion, dual_input\u001b[38;5;241m=\u001b[39m(X2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    419\u001b[0m )\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:302\u001b[0m, in \u001b[0;36mModelTrainingPipeline.train_model\u001b[0;34m(self, model, criterion, optimizer, train_loader, val_loader, num_epochs, dual_input)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dual_input:\n\u001b[1;32m    301\u001b[0m     batch_X1, batch_X2, batch_y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 302\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_X1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_X2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     batch_X1, batch_y \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/motifpred/code/models/tcn_pytorch.py:123\u001b[0m, in \u001b[0;36mTemporalConvNet.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    119\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, mask), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    121\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to (batch_size, channels, sequence_length)\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(y1[:, :, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# just take the last time step features\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m o\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/motifpred/code/models/tcn_pytorch.py:93\u001b[0m, in \u001b[0;36mTemporalBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 93\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     res \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out \u001b[38;5;241m+\u001b[39m res)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.informer_pytorch import Informer\n",
    "from utils.utils import print_study_results, plot_best_model_results\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "model_type = \"Informer\"\n",
    "model_name = \"InformerSeries_X2Masking\"\n",
    "\n",
    "suggestion_dict = {\n",
    "    \"learning_rate\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [1e-5, 1e-3],\n",
    "        \"kwargs\": {\"log\": True}\n",
    "    },\n",
    "    \"d_model\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[64, 128, 256, 512]]\n",
    "    },\n",
    "    \"n_heads\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2, 4, 8, 16]]\n",
    "    },\n",
    "    \"attn\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[\"prob\", \"full\"]]\n",
    "    },\n",
    "    \"e_layers\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2, 3]]\n",
    "    },\n",
    "    \"s_layers\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[1, 2, 3]]\n",
    "    },\n",
    "    \"dropout\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [0.0, 0.5]\n",
    "    },\n",
    "    \"batch_size\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[16, 32, 64, 128]]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_params_keys = [\"n_heads\", \"d_model\", \"attn\", \"e_layers\", \"s_layers\", \"dropout\"]\n",
    "\n",
    "#X1 shape is (num_samples, lookback_period)\n",
    "masking_X1 = np.zeros((X1.shape[0], X1.shape[1])) \n",
    "\n",
    "for i, obs_motif_indexes in enumerate(X2):\n",
    "    for j, idx in enumerate(obs_motif_indexes):\n",
    "        masking_X1[i, idx.item():idx.item()+p] = 1\n",
    "\n",
    "masking_X1 = torch.tensor(masking_X1, dtype=torch.float32)\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "run_optuna_study(pipeline.run_cross_val, Informer, model_type, suggestion_dict, model_params_keys, seed, X1, masking_X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "print_study_results(study)\n",
    "plot_best_model_results(\n",
    "    study.trials_dataframe(),\n",
    "    save_path=os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_losses.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.utils import plot_preds_vs_truevalues\n",
    "# from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "\n",
    "# epochs_train_losses, epochs_val_losses, all_predictions, all_true_values = get_preds_best_config(study, pipeline, CNNX1_X2Masking, model_type, model_params_keys, num_epochs =num_epochs, seed=seed, X1=X1, X2=masking_X1, y=y)\n",
    "\n",
    "# # Plot the train and validation losses for each fold\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharey=True)\n",
    "# for i in range(5):\n",
    "#     axes[i].plot(epochs_train_losses[i], label=\"Train Loss\")\n",
    "#     axes[i].plot(epochs_val_losses[i], label=\"Validation Loss\")\n",
    "#     axes[i].set_title(f\"Fold {i + 1}\")\n",
    "#     axes[i].set_xlabel(\"Epoch\")\n",
    "#     if i == 0:\n",
    "#         axes[i].set_ylabel(\"Loss\")\n",
    "#     axes[i].legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_losses.png\"))\n",
    "# plt.show()\n",
    "\n",
    "# # Plot the predictions vs true values for each fold\n",
    "# for fold in range(5):\n",
    "#     plot_preds_vs_truevalues(np.ravel(all_true_values[fold]), np.ravel(all_predictions[fold]), fold, save_path=os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_fold_{fold}_predictions.png\"))\n",
    "\n",
    "\n",
    "for fold in range(5):\n",
    "    img = mpimg.imread(os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_fold_{fold}_predictions.png\"))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axes for a cleaner display\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
