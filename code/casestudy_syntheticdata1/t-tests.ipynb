{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-24 13:40:34,915 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata1/variables=[0,2]\n",
      "2025-01-24 13:40:34,915 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata1/variables=[0,2]\n",
      "2025-01-24 13:40:34,915 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata1/variables=[0,2]\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata1/variables=[0,2]\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "from config import RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, MOTIF_INDEXES_PATH, K, N, P, NORMALIZE_FLAGS\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0    10    22 ... 99922 99956 99992]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(DATASET_PATH, delimiter=\",\").astype(int).reshape((K, N))\n",
    "motif_indexes = np.genfromtxt(MOTIF_INDEXES_PATH, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 15997 15998 15999] TEST: [16000 16001 16002 ... 19997 19998 19999]\n",
      "TRAIN: [20000 20001 20002 ... 35997 35998 35999] TEST: [36000 36001 36002 ... 39997 39998 39999]\n",
      "TRAIN: [40000 40001 40002 ... 55997 55998 55999] TEST: [56000 56001 56002 ... 59997 59998 59999]\n",
      "TRAIN: [60000 60001 60002 ... 75997 75998 75999] TEST: [76000 76001 76002 ... 79997 79998 79999]\n",
      "TRAIN: [80000 80001 80002 ... 95997 95998 95999] TEST: [96000 96001 96002 ... 99997 99998 99999]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAH5CAYAAAC28G5lAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqQklEQVR4nO3df3TV9X348dcF5JKGEKTKj8QgWHsISBULopR2wOosRanK1rN6tG1WwGOZKOOsE1datKXF9dfxdC7szFJ6urK6o6WjY9ipxeK6KExsLFV+6FoVAZv9kARmBUM+3z8s90sM4U0k5CbweJzzOcf7ue97P++Lb0KeuffzSS7LsiwAAABoV69iTwAAAKC7E04AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEvoUewLF0NLSErt3746ysrLI5XLFng4AAFAkWZbFvn37oqKiInr1av99pdMynHbv3h1VVVXFngYAANBN7Ny5M84555x27z8tw6msrCwi3vzDGTBgQJFnAwAAFEtTU1NUVVUVGqE9p2U4Hf543oABA4QTAACQPIXHxSEAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIKFPVx5s6tSpMW7cuLj77rvbHTNixIhYsGBBLFiwoMvmBQDA27N6+55iT4ET8ciP4+qbPxW5I3Z16TsrZWURTU1decS3rUN/LjU1NZHL5dpszz///MmaXxvf+c53jjqH119/vcvmAACAaOrprq6uiGtv/lT0jjej4PDWpfbti8jl0uO6gQ6/4zR9+vRYuXJlq31nn312p03oeAwYMCC2b9/eal+/fv26dA4AAKcz0dSzXV1d0b3O2cnlIrKs2LM4pg7/eeXz+Rg6dGirrXfv3hERsWHDhpg4cWLk8/kYNmxYLFq0KJqbm9t9roaGhpg5c2aUlJTEyJEjY9WqVcc1h1wu12YOAAB0DdHUwz3y40IEdKv3egYMKPYMjqnTznHatWtXzJgxI2pqauK73/1ubNu2LebOnRv9+vWLO+6446iPqampiZ07d8b69eujb9++ccstt0RDQ0PyWPv3749zzz03Dh06FOPGjYsvfvGLcfHFF7c7/sCBA3HgwIHC7aYe8jlKAADobG89p6nb2Lev2DM4pg6/47R27dro379/YfvoRz8aERG1tbVRVVUV99xzT1RXV8c111wTd955Z3z961+PlpaWNs+zY8eOePDBB+Nb3/pWTJo0KcaPHx8rVqyI3/72t8c8fnV1dXznO9+JH/3oR/H9738/+vXrF5MnT47nnnuu3ccsW7YsysvLC1tVVVVHXzYAAJwSumU09QAdfsdp2rRpsXz58sLt0tLSiIjYunVrTJo0KXJHnNw1efLk2L9/f7z88ssxfPjwVs+zdevW6NOnT0yYMKGwr7q6OgYOHHjM41922WVx2WWXtTrGe9/73vjrv/7r+OY3v3nUx9x+++2xcOHCwu2mpibxBADAaal7n0nUfXU4nEpLS+P8889vsz/LslbRdHhfRLTZn7qvI3r16hWXXHLJMd9xyufzkc/nT+g4AABwKlhzz7fj2ps/FRHd7N2nsrJiz+CYOu1iGmPGjIm6urpCEEVE1NXVRVlZWVRWVrYZP3r06Ghubo4nn3yysG/79u2xd+/eDh03y7Kor6+PYcOGve25AwBw/GaN8n1Xj3b59Dh8Ik23evepm1+HoNPCad68ebFz586YP39+bNu2LdasWRNLliyJhQsXRq9ebQ8zatSomD59esydOzc2btwYmzdvjjlz5kRJSckxj3PnnXfGv/7rv8avfvWrqK+vj9mzZ0d9fX3cdNNNnfVSAABIEE8925ptu6PtVQiKqJtfijyiE8OpsrIy1q1bF5s2bYqLLroobrrpppg9e3YsXry43cesXLkyqqqqYsqUKTFr1qy48cYbY/Dgwcc8zt69e+PGG2+M0aNHxxVXXBG7du2Kxx57LCZOnNhZLwUAgOMgnnq2Ndt2xw/v+XYcioiWI7YuVVbWI6IpIiKXZT1kpp2oqakpysvLo7GxMQZ08+vFAwAAJ8/xtkG3+oXBAAAA3ZFwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAk9Cn2BACA7mP19j3FngInYvv2uPrqaZE7YleX/5T8uecizj+/q48KJ12X/l2aOnVqLFiw4JhjRowYEXfffXeXzAcA+P9EU892dXVFXHv1tOgdb36Dd3jrcu9+d0QvH2ri1NOhVV1TUxO5XK7N9vzzz5+s+R3TfffdF7lcLq655pqiHB8AThWiqWe7urqie51/kWXiiVNOh1f09OnTY8+ePa22kSNHnoy5HdOLL74Yf/7nfx4f+MAHuvzYAHAqEU093PbthW/ocscc2MWyLKJIP1yHk6HD4ZTP52Po0KGttt69e0dExIYNG2LixImRz+dj2LBhsWjRomhubm73uRoaGmLmzJlRUlISI0eOjFWrVh3XHA4dOhTXX3993HnnnXHeeeclxx84cCCamppabQAAp4KrZ10euehm0XTYmDHFngF0mk57D3XXrl0xY8aMuOSSS+Lpp5+O5cuXx4oVK2Lp0qXtPqampiZeeOGFWL9+fTzwwANRW1sbDQ0NyWN94QtfiLPPPjtmz559XHNbtmxZlJeXF7aqqqrjfl0AAN1Z7tChYk+hfW+8UewZQKfp8FX11q5dG/379y/c/vCHPxz3339/1NbWRlVVVdxzzz2Ry+Wiuro6du/eHbfddlt8/vOfj15v+Zzrjh074sEHH4wnnngiLr300oiIWLFiRYwePfqYx//3f//3WLFiRdTX1x/3nG+//fZYuHBh4XZTU5N4AgBOCVnv3hHdNZ7OOKPYM4BO0+FwmjZtWixfvrxwu7S0NCIitm7dGpMmTYpc7v+/UTx58uTYv39/vPzyyzF8+PBWz7N169bo06dPTJgwobCvuro6Bg4c2O6x9+3bFzfccEPce++9cdZZZx33nPP5fOTz+eMeDwDQU6xZ/Uhce/W0iOiGH9d79tlizwA6TYfDqbS0NM4/yrX5syxrFU2H90VEm/2p+9rzn//5n/HCCy/EzJkzC/taWloiIqJPnz6xffv2eNe73nXczwcARMwaNcwFInqyUaOiJd48/yKLbhRPuZzf58QppdPOcRozZkzU1dUVgigioq6uLsrKyqKysrLN+NGjR0dzc3M8+eSThX3bt2+PvXv3tnuM6urq2LJlS9TX1xe2j3zkIzFt2rSor6/38TsAeJtmjRpW7ClwAtZs2x0txZ7EkXK5iJZuNSM4YZ0WTvPmzYudO3fG/PnzY9u2bbFmzZpYsmRJLFy4sM35TRERo0aNiunTp8fcuXNj48aNsXnz5pgzZ06UlJS0e4x+/frF2LFjW20DBw6MsrKyGDt2bPTt27ezXg4AnHbEU8+2Ztvu+OGaR+NQRLQcsXW5554TTZySOvxRvfZUVlbGunXr4jOf+UxcdNFFMWjQoJg9e3YsXry43cesXLky5syZE1OmTIkhQ4bE0qVL43Of+1xnTQkA6CDx1MONGvbm708COl0uy06/v11NTU1RXl4ejY2NMWDAgGJPBwAAKJLjbYNO+6geAADAqUo4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQ0KcrDzZ16tQYN25c3H333e2OGTFiRCxYsCAWLFjQZfMCOFWt3r6n2FPgRBw6FGddUBWTIyL3u11d/hPPtWsjrryyq48K0O106OtvTU1N5HK5Ntvzzz9/subXxurVq2PChAkxcODAKC0tjXHjxsXf//3fd9nxAXoK0dSzVTy0Lq6+oCp+LyJ6x5v/YBflYyJXXRWRy6XHAZziOvyO0/Tp02PlypWt9p199tmdNqGUQYMGxWc/+9morq6Ovn37xtq1a+NP/uRPYvDgwfGhD32oy+YB0J2Jpp6t4qF1cektc4o9jdZyuYgsK/YsAIqmwz+8yufzMXTo0FZb7969IyJiw4YNMXHixMjn8zFs2LBYtGhRNDc3t/tcDQ0NMXPmzCgpKYmRI0fGqlWrksefOnVqXHvttTF69Oh417veFbfeemtceOGF8bOf/ayjLwXglCSaerhDh+LC30VTt3uf51/+pdgzACiaTjvHadeuXTFjxoyoqamJ7373u7Ft27aYO3du9OvXL+64446jPqampiZ27twZ69evj759+8Ytt9wSDQ0Nx33MLMti/fr1sX379virv/qrdscdOHAgDhw4ULjd1NR03McAgK501pMb4x3FnkR7rrrKu07AaavD4bR27dro379/4faHP/zhuP/++6O2tjaqqqrinnvuiVwuF9XV1bF79+647bbb4vOf/3z06tX6za0dO3bEgw8+GE888URceumlERGxYsWKGD16dHIOjY2NUVlZGQcOHIjevXtHbW1t/MEf/EG745ctWxZ33nlnR18qAHS5fv/1m2JPAYCj6HA4TZs2LZYvX164XVpaGhERW7dujUmTJkXuiBNIJ0+eHPv374+XX345hg8f3up5tm7dGn369IkJEyYU9lVXV8fAgQOTcygrK4v6+vrYv39//OQnP4mFCxfGeeedF1OnTj3q+Ntvvz0WLlxYuN3U1BRVVVXH83IBoEu9fvaQYk8BgKPocDiVlpbG+eef32Z/lmWtounwvohosz91X0qvXr0Kcxg3blxs3bo1li1b1m445fP5yOfzHT4OAHS1/55wabwWESXRDc9xWru22DMAKJpOu7LpmDFjoq6urhBEERF1dXVRVlYWlZWVbcaPHj06mpub48knnyzs2759e+zdu7fDx86yrNU5TACns1mjhhV7CpyI3r3jF9/8VkREdLuzifw+J+A01mnhNG/evNi5c2fMnz8/tm3bFmvWrIklS5bEwoUL25zfFBExatSomD59esydOzc2btwYmzdvjjlz5kRJSckxj7Ns2bJ4+OGH41e/+lVs27YtvvGNb8R3v/vduOGGGzrrpQD0eOKpZ9t9xYzY+M1vRUuxJ3IkF4UATnOdFk6VlZWxbt262LRpU1x00UVx0003xezZs2Px4sXtPmblypVRVVUVU6ZMiVmzZsWNN94YgwcPPuZx/u///i/mzZsXF1xwQbzvfe+LBx54IL73ve/FnDnd7PddABSZeOrZdl8xI9Y8szMei4hDEdHyu63LrV0rmgAiIpdlp99Xw6ampigvL4/GxsYYMGBAsacDAAAUyfG2Qae94wQAAHCqEk4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgAThBAAAkCCcAAAAEoQTAABAgnACAABIEE4AAAAJwgkAACBBOAEAACQIJwAAgIQ+xZ4AcPxWb99T7ClwoiZcEFfvfzVyR+zq0p9g1dZGfPrTXXlEADgldOm/11OnTo0FCxYcc8yIESPi7rvv7pL5QE8imnq+q6sr4tr9r0bvePOL7+GtS82bF5HLpccBAK106N/smpqayOVybbbnn3/+ZM2vjXvvvTc+8IEPxJlnnhlnnnlmXH755bFp06YuOz4Ug2jq+a6uruhen40WTwDQIR3+d3z69OmxZ8+eVtvIkSNPxtyO6qc//Wlcd9118eijj8bjjz8ew4cPjyuuuCJ27drVZXOAriSaTgETLih8se1WubJ8ebFnAAA9RofDKZ/Px9ChQ1ttvXv3joiIDRs2xMSJEyOfz8ewYcNi0aJF0dzc3O5zNTQ0xMyZM6OkpCRGjhwZq1atSh5/1apVMW/evBg3blxUV1fHvffeGy0tLfGTn/yk3cccOHAgmpqaWm0AXeXwOU3dKpoi3vzYHgBwXDrtkyO7du2KGTNmxCWXXBJPP/10LF++PFasWBFLly5t9zE1NTXxwgsvxPr16+OBBx6I2traaGho6NBxX3vttXjjjTdi0KBB7Y5ZtmxZlJeXF7aqqqoOHQPgRHS7YAIAOqzD4bR27dro379/YfvoRz8aERG1tbVRVVUV99xzT1RXV8c111wTd955Z3z961+PlpaWNs+zY8eOePDBB+Nb3/pWTJo0KcaPHx8rVqyI3/72tx2az6JFi6KysjIuv/zydsfcfvvt0djYWNh27tzZsRcNcAKyYk8AADhhHb4c+bRp02L5EZ+LLy0tjYiIrVu3xqRJkyJ3xAnHkydPjv3798fLL78cw4cPb/U8W7dujT59+sSECRMK+6qrq2PgwIHHPZevfOUr8f3vfz9++tOfRr9+/dodl8/nI5/PH/fzAnSmNf3PjGv3vxoR3ezdp9raYs8AAHqMDodTaWlpnH/++W32Z1nWKpoO74uINvtT9x2Pr33ta/HlL385Hnnkkbjwwgvf1nNATzBr1DAXiOjpnnwmWn53Vb0sulE8+X1OAHDcOu0cpzFjxkRdXV0hiCIi6urqoqysLCorK9uMHz16dDQ3N8eTTz5Z2Ld9+/bYu3dv8lhf/epX44tf/GL8+Mc/bvWOFZyqZo0aVuwpcILWbNsdbT+0XESZDxACQEd0WjjNmzcvdu7cGfPnz49t27bFmjVrYsmSJbFw4cLo1avtYUaNGhXTp0+PuXPnxsaNG2Pz5s0xZ86cKCkpOeZxvvKVr8TixYvj29/+dowYMSJeeeWVeOWVV2L//v2d9VKgWxJPPd+abbvjh/3PjEMR0XLE1qVqa0UTALwNHf6oXnsqKytj3bp18ZnPfCYuuuiiGDRoUMyePTsWL17c7mNWrlwZc+bMiSlTpsSQIUNi6dKl8bnPfe6Yx6mtrY2DBw/GH/3RH7Xav2TJkrjjjjs646VAtyWeTgH7/rfYMwAA3oZclp1+P3psamqK8vLyaGxsjAEDBhR7OgAAQJEcbxt02kf1AAAATlXCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACAhD5debCpU6fGuHHj4u677253zIgRI2LBggWxYMGCLptXsazZvicOFXsSnJhpl8XVe16K3BG7uvSnEYsXR3zxi115RACA01KHvserqamJXC7XZnv++edP1vzaeOaZZ+IP//APY8SIEZHL5Y4ZYd3ZatHU411dXRHX7nkpesebf5EOb11q6dKIXC49DgCAE9Lh7/OmT58ee/bsabWNHDnyZMztqF577bU477zz4q677oqhQ4d22XE70+rte4o9BU7Q1dUV3etzruIJAOCk6vD3fvl8PoYOHdpq6927d0REbNiwISZOnBj5fD6GDRsWixYtiubm5nafq6GhIWbOnBklJSUxcuTIWLVqVfL4l1xySXz1q1+Nj33sY5HP5zs6/aJbI5p6vmmXFf7idKtc+dznij0DAIBTVqf90HzXrl0xY8aMuOSSS+Lpp5+O5cuXx4oVK2Lp0qXtPqampiZeeOGFWL9+fTzwwANRW1sbDQ0NnTWlggMHDkRTU1OrrVh8PK/nO3xOU7eKpog3P7YHAMBJ0eGLQ6xduzb69+9fuP3hD3847r///qitrY2qqqq45557IpfLRXV1dezevTtuu+22+PznPx+9erVutB07dsSDDz4YTzzxRFx66aUREbFixYoYPXr0Cb6ktpYtWxZ33nlnpz8vp6duF0wAAJx0HQ6nadOmxfLlywu3S0tLIyJi69atMWnSpMgdca7F5MmTY//+/fHyyy/H8OHDWz3P1q1bo0+fPjFhwoTCvurq6hg4cGBHp5R0++23x8KFCwu3m5qaoqqqqtOPw+khK/YEAADoch0Op9LS0jj//PPb7M+yrFU0Hd4XEW32p+7rbPl8vtucD9U7fFyvp1szbHhcu+eliOhm7z4tXlzsGQAAnLI67RynMWPGRF1dXSGIIiLq6uqirKwsKisr24wfPXp0NDc3x5NPPlnYt3379ti7d29nTalbunrUsGJPgRP16BPR8rv/7FbvPvl9TgAAJ02nhdO8efNi586dMX/+/Ni2bVusWbMmlixZEgsXLmxzflNExKhRo2L69Okxd+7c2LhxY2zevDnmzJkTJSUlxzzOwYMHo76+Purr6+PgwYOxa9euqK+v79LfJXWiZomnHm/Ntt2FeOoWsm6VcAAAp5xOC6fKyspYt25dbNq0KS666KK46aabYvbs2bH4GB8fWrlyZVRVVcWUKVNi1qxZceONN8bgwYOPeZzdu3fHxRdfHBdffHHs2bMnvva1r8XFF18cc+bM6ayX0iVmjRoWvYs9CU7Imm2744fDhsehiGg5YutSixeLJgCALpDLstPvu66mpqYoLy+PxsbGGDBgQLGnAwAAFMnxtkGnveMEAABwqhJOAAAACcIJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEEwAAQIJwAgAASBBOAAAACcIJAAAgQTgBAAAkCCcAAICEPsWeQDFkWRYREU1NTUWeCQAAUEyHm+BwI7TntAynffv2RUREVVVVkWcCAAB0B/v27Yvy8vJ2789lqbQ6BbW0tMTu3bujrKwscrlcUefS1NQUVVVVsXPnzhgwYEBR50LPYM3QUdYMHWXN0FHWDB3VndZMlmWxb9++qKioiF692j+T6bR8x6lXr15xzjnnFHsarQwYMKDoi4aexZqho6wZOsqaoaOsGTqqu6yZY73TdJiLQwAAACQIJwAAgAThVGT5fD6WLFkS+Xy+2FOhh7Bm6Chrho6yZugoa4aO6olr5rS8OAQAAEBHeMcJAAAgQTgBAAAkCCcAAIAE4QQAAJAgnAAAABKEUxHV1tbGyJEjo1+/fjF+/Pj4t3/7t2JPiZNg2bJlcckll0RZWVkMHjw4rrnmmti+fXurMVmWxR133BEVFRVRUlISU6dOjWeeeabVmAMHDsT8+fPjrLPOitLS0vjIRz4SL7/8cqsxr776anz84x+P8vLyKC8vj49//OOxd+/eVmNeeumlmDlzZpSWlsZZZ50Vt9xySxw8ePCkvHZO3LJlyyKXy8WCBQsK+6wX3mrXrl1xww03xDvf+c54xzveEePGjYvNmzcX7rdmOFJzc3MsXrw4Ro4cGSUlJXHeeefFF77whWhpaSmMsWZOb4899ljMnDkzKioqIpfLxT/90z+1ur+7rY8tW7bElClToqSkJCorK+MLX/hCnJQLh2cUxX333ZedccYZ2b333ps9++yz2a233pqVlpZmL774YrGnRif70Ic+lK1cuTL75S9/mdXX12dXXnllNnz48Gz//v2FMXfddVdWVlaW/eAHP8i2bNmS/fEf/3E2bNiwrKmpqTDmpptuyiorK7OHH344e+qpp7Jp06ZlF110Udbc3FwYM3369Gzs2LFZXV1dVldXl40dOza76qqrCvc3NzdnY8eOzaZNm5Y99dRT2cMPP5xVVFRkN998c9f8YdAhmzZtykaMGJFdeOGF2a233lrYb71wpP/93//Nzj333KympibbuHFj9utf/zp75JFHsueff74wxprhSEuXLs3e+c53ZmvXrs1+/etfZ/fff3/Wv3//7O677y6MsWZOb+vWrcs++9nPZj/4wQ+yiMh++MMftrq/O62PxsbGbMiQIdnHPvaxbMuWLdkPfvCDrKysLPva177W6X8uwqlIJk6cmN10002t9lVXV2eLFi0q0ozoKg0NDVlEZBs2bMiyLMtaWlqyoUOHZnfddVdhzOuvv56Vl5dnf/u3f5tlWZbt3bs3O+OMM7L77ruvMGbXrl1Zr169sh//+MdZlmXZs88+m0VE9sQTTxTGPP7441lEZNu2bcuy7M0vhL169cp27dpVGPP9738/y+fzWWNj48l70XTYvn37sne/+93Zww8/nE2ZMqUQTtYLb3Xbbbdl73//+9u935rhra688srsU5/6VKt9s2bNym644YYsy6wZWntrOHW39VFbW5uVl5dnr7/+emHMsmXLsoqKiqylpaUT/ySyzEf1iuDgwYOxefPmuOKKK1rtv+KKK6Kurq5Is6KrNDY2RkTEoEGDIiLi17/+dbzyyiut1kM+n48pU6YU1sPmzZvjjTfeaDWmoqIixo4dWxjz+OOPR3l5eVx66aWFMZdddlmUl5e3GjN27NioqKgojPnQhz4UBw4caPWxHorvT//0T+PKK6+Myy+/vNV+64W3+tGPfhQTJkyIj370ozF48OC4+OKL49577y3cb83wVu9///vjJz/5SezYsSMiIp5++un42c9+FjNmzIgIa4Zj627r4/HHH48pU6ZEPp9vNWb37t3xwgsvdOpr79Opz8Zx+e///u84dOhQDBkypNX+IUOGxCuvvFKkWdEVsiyLhQsXxvvf//4YO3ZsRETh//nR1sOLL75YGNO3b98488wz24w5/PhXXnklBg8e3OaYgwcPbjXmrcc588wzo2/fvtZeN3LffffFU089Ff/xH//R5j7rhbf61a9+FcuXL4+FCxfGX/7lX8amTZvilltuiXw+H5/4xCesGdq47bbborGxMaqrq6N3795x6NCh+NKXvhTXXXddRPg6w7F1t/XxyiuvxIgRI9oc5/B9I0eOfDsv86iEUxHlcrlWt7Msa7OPU8vNN98cv/jFL+JnP/tZm/veznp465ijjX87YyienTt3xq233hoPPfRQ9OvXr91x1guHtbS0xIQJE+LLX/5yRERcfPHF8cwzz8Ty5cvjE5/4RGGcNcNh//iP/xjf+9734h/+4R/iggsuiPr6+liwYEFUVFTEJz/5ycI4a4Zj6U7r42hzae+xJ8JH9YrgrLPOit69e7f5SUpDQ0ObqubUMX/+/PjRj34Ujz76aJxzzjmF/UOHDo2IOOZ6GDp0aBw8eDBeffXVY475zW9+0+a4//Vf/9VqzFuP8+qrr8Ybb7xh7XUTmzdvjoaGhhg/fnz06dMn+vTpExs2bIhvfvOb0adPn1Y/RTuS9XL6GjZsWIwZM6bVvtGjR8dLL70UEb7G0NZnPvOZWLRoUXzsYx+L97znPfHxj388/uzP/iyWLVsWEdYMx9bd1sfRxjQ0NERE23fFTpRwKoK+ffvG+PHj4+GHH261/+GHH473ve99RZoVJ0uWZXHzzTfH6tWrY/369W3eMh45cmQMHTq01Xo4ePBgbNiwobAexo8fH2eccUarMXv27Ilf/vKXhTGTJk2KxsbG2LRpU2HMxo0bo7GxsdWYX/7yl7Fnz57CmIceeijy+XyMHz++8188HfbBD34wtmzZEvX19YVtwoQJcf3110d9fX2cd9551gutTJ48uc2vONixY0ece+65EeFrDG299tpr0atX628Be/fuXbgcuTXDsXS39TFp0qR47LHHWl2i/KGHHoqKioo2H+E7YZ16qQmO2+HLka9YsSJ79tlnswULFmSlpaXZCy+8UOyp0ck+/elPZ+Xl5dlPf/rTbM+ePYXttddeK4y56667svLy8mz16tXZli1bsuuuu+6ol/U855xzskceeSR76qmnst///d8/6mU9L7zwwuzxxx/PHn/88ew973nPUS/r+cEPfjB76qmnskceeSQ755xzXPa1mzvyqnpZZr3Q2qZNm7I+ffpkX/rSl7LnnnsuW7VqVfaOd7wj+973vlcYY81wpE9+8pNZZWVl4XLkq1evzs4666zsL/7iLwpjrJnT2759+7Kf//zn2c9//vMsIrJvfOMb2c9//vPCr83pTutj79692ZAhQ7Lrrrsu27JlS7Z69epswIABLkd+qvmbv/mb7Nxzz8369u2bvfe97y1cnppTS0QcdVu5cmVhTEtLS7ZkyZJs6NChWT6fz37v934v27JlS6vn+e1vf5vdfPPN2aBBg7KSkpLsqquuyl566aVWY/7nf/4nu/7667OysrKsrKwsu/7667NXX3211ZgXX3wxu/LKK7OSkpJs0KBB2c0339zqEp50P28NJ+uFt/rnf/7nbOzYsVk+n8+qq6uzv/u7v2t1vzXDkZqamrJbb701Gz58eNavX7/svPPOyz772c9mBw4cKIyxZk5vjz766FG/d/nkJz+ZZVn3Wx+/+MUvsg984ANZPp/Phg4dmt1xxx2dfinyLMuyXJadjF+rCwAAcOpwjhMAAECCcAIAAEgQTgAAAAnCCQAAIEE4AQAAJAgnAACABOEEAACQIJwAAAAShBMAAECCcAIAAEgQTgAAAAn/Dzai1x8OmqLgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.timeseries_split import BlockingTimeSeriesSplit\n",
    "\n",
    "#create index  \n",
    "indexes = np.arange(len(data[0]))\n",
    "\n",
    "#split data\n",
    "tscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(indexes)):\n",
    "    # Plot train and test indices\n",
    "    ax.plot(train_index, np.zeros_like(train_index) + i, 'o', color='lightblue')\n",
    "    ax.plot(test_index, np.zeros_like(test_index) + i, 'o', color='red')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "\n",
    "ax.set_yticks(np.arange(5), [\"Fold {}\".format(i) for i in range(1, 6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_series shape: torch.Size([19979, 100, 3])\n",
      "X_mask shape: torch.Size([19979, 100])\n",
      "X_indices shape: torch.Size([19979, 6, 1])\n",
      "y shape: torch.Size([19979, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#X_series: past window, X_indices: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X_series, X_indices, y = create_dataset(data, lookback_period, step, forecast_period, motif_indexes)\n",
    "\n",
    "#X_series is (num_samples, lookback_period, num_features)\n",
    "X_mask = np.zeros((X_series.shape[0], X_series.shape[1])) \n",
    "\n",
    "for i, obs_motif_indexes in enumerate(X_indices):\n",
    "    for j, idx in enumerate(obs_motif_indexes):\n",
    "        idx = int(idx)\n",
    "        X_mask[i, idx:idx+P] = 1\n",
    "\n",
    "X_mask = torch.tensor(X_mask, dtype=torch.float32)\n",
    "\n",
    "# X_series, X2, and y are now PyTorch tensors\n",
    "print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, lookback_period)\n",
    "print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model FFNNSeries already exists\n",
      "Model LSTMSeries already exists\n",
      "Model CNNSeries already exists\n",
      "Best hyperparameters: {'learning_rate': 0.000987141505311331, 'kernel_size': 3, 'receptive_field': 50, 'dropout': 0.028517695536759712, 'batch_size': 16, 'block_channels_0': 16, 'block_channels_1': 16, 'block_channels_2': 16, 'block_channels_3': 16, 'block_channels_4': 32}\n",
      "Stopping early: Maximum training time exceeded.\n",
      "Early stopping at epoch 101, with best epoch being 99\n",
      "Stopping early: Maximum training time exceeded.\n",
      "Early stopping at epoch 109, with best epoch being 107\n",
      "Stopping early: Maximum training time exceeded.\n",
      "Early stopping at epoch 101, with best epoch being 93\n",
      "Stopping early: Maximum training time exceeded.\n",
      "Early stopping at epoch 107, with best epoch being 89\n",
      "Stopping early: Maximum training time exceeded.\n",
      "Early stopping at epoch 101, with best epoch being 86\n",
      "Validation Losses: [1.5804728269577026, 4.387530326843262, 3.327434539794922, 1.4110078811645508, 3.1234617233276367]\n",
      "Mean validation loss: 2.7659814596176147\n",
      "Test Losses: [2.5055525302886963, 4.930098056793213, 4.30208683013916, 3.896125078201294, 1.6976078748703003]\n",
      "Mean test loss: 3.4662940740585326\n",
      "Test MAE: [1.1154910326004028, 1.4481569528579712, 1.2558526992797852, 1.0166480541229248, 0.9282515645027161]\n",
      "Model TransformerSeries already exists\n"
     ]
    }
   ],
   "source": [
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TemporalConvNet\n",
    "from models.transformer_pytorch import TimeSeriesTransformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "from utils.utils import print_study_results, get_best_model_results, plot_best_model_results, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(fold_val_losses, val_losses):\n",
    "        raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    if model_type == \"Transformer\":\n",
    "        model = eval(\"TimeSeriesTransformer\")\n",
    "    elif model_type == \"TCN\":\n",
    "        model = eval(\"TemporalConvNet\")\n",
    "    else:\n",
    "        model = eval(model_type)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, model, model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    #if not np.allclose(fold_val_losses, val_losses, atol=1):\n",
    "    #    raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        normalize_flags = NORMALIZE_FLAGS\n",
    "        n_trials, num_epochs = (1, 1) if model_type == \"Baseline\" else (n_trials, num_epochs)\n",
    "\n",
    "        if model_type == \"Baseline\":\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "\n",
    "            X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "            normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "            for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                process_baseline_model(\n",
    "                    model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            if input_name == \"Series\":\n",
    "                X = {\"X_series\": X_series}\n",
    "            elif input_name == \"Series_Masking\":\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "            else:\n",
    "                X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "\n",
    "            process_non_baseline_model(\n",
    "                model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: FFNNSeries\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: TCNSeries\n",
      "Results file for TCNSeries not found. Skipping.\n",
      "Processing Model: TransformerSeries\n",
      "          model   input fold       mae       rmse\n",
      "0          FFNN  Series    1  9.389045  11.669245\n",
      "1          FFNN  Series    2  8.793365  10.960507\n",
      "2          FFNN  Series    3  9.180077  11.325398\n",
      "3          FFNN  Series    4  8.737524  11.029864\n",
      "4          FFNN  Series    5  8.585275  10.890684\n",
      "5          LSTM  Series    1  4.258052   7.083573\n",
      "6          LSTM  Series    2  4.590631   7.886975\n",
      "7          LSTM  Series    3  3.035272   6.043316\n",
      "8          LSTM  Series    4  3.031424   6.217641\n",
      "9          LSTM  Series    5  7.226361   9.748582\n",
      "10          CNN  Series    1  6.470577   8.659925\n",
      "11          CNN  Series    2  6.460783   8.527258\n",
      "12          CNN  Series    3  5.694703   7.675818\n",
      "13          CNN  Series    4  6.876115   9.207098\n",
      "14          CNN  Series    5  6.587561   8.773660\n",
      "15  Transformer  Series    1  1.789328   4.256087\n",
      "16  Transformer  Series    2  2.188045   3.820515\n",
      "17  Transformer  Series    3  1.468080   3.266317\n",
      "18  Transformer  Series    4  1.682931   3.875419\n",
      "19  Transformer  Series    5  1.621739   3.732234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61335/153205014.py:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\",\"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\"]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"fold\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Combine each model with each input\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        # Handle baseline-specific logic\n",
    "        if model_type == \"Baseline\":\n",
    "            n_trials, num_epochs = (1, 1)\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            # Process both BaselineAverage and BaselineLastDifference\n",
    "            baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "            for baseline_type in baseline_variants:\n",
    "                model_name = f\"{baseline_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": baseline_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"fold\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            n_trials = 100\n",
    "            num_epochs = 500\n",
    "\n",
    "            model_name = f\"{model_type}{input_name}\"\n",
    "            print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "            # Construct the results directory path\n",
    "            model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "            results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "            # Skip if results file doesn't exist\n",
    "            if not os.path.exists(results_file):\n",
    "                print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load results from CSV\n",
    "            results = pd.read_csv(results_file)\n",
    "            maes = results[\"test_mae\"].values\n",
    "            rmses = results[\"test_rmse\"].values\n",
    "\n",
    "            # Add results to the dataframe\n",
    "            for i in range(len(maes)):  # Assuming results have folds\n",
    "                results_df = pd.concat([\n",
    "                    results_df,\n",
    "                    pd.DataFrame([{\n",
    "                        \"model\": model_type,\n",
    "                        \"input\": input_name,\n",
    "                        \"fold\": i + 1,\n",
    "                        \"mae\": maes[i],\n",
    "                        \"rmse\": rmses[i]\n",
    "                    }])\n",
    "                ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input fold       mae       rmse\n",
      "0          BaselineAverage         Indexes  3.0  7.061335   9.466859\n",
      "1   BaselineLastDifference         Indexes  3.0  4.363204   7.537955\n",
      "2                      CNN         Indexes  3.0  0.345493   0.555321\n",
      "3                      CNN          Series  3.0  6.417948   8.568752\n",
      "4                      CNN  Series_Masking  3.0  0.701390   0.967899\n",
      "5                     FFNN         Indexes  3.0  0.549793   1.042796\n",
      "6                     FFNN          Series  3.0  8.937057  11.175140\n",
      "7                     FFNN  Series_Masking  3.0  1.012417   1.686616\n",
      "8                     LSTM         Indexes  3.0  0.148808   0.186667\n",
      "9                     LSTM          Series  3.0  4.428348   7.396018\n",
      "10                    LSTM  Series_Masking  3.0  1.099881   2.904646\n",
      "11             Transformer         Indexes  3.0  0.403696   0.533269\n",
      "12             Transformer          Series  3.0  1.750024   3.790114\n",
      "13             Transformer  Series_Masking  3.0  0.553271   0.790670\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61335/1915286810.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rmse\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Filter data for the selected input type including baseline models even if they don't have the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mdf_filtered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Baseline\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Get the unique models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_filtered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0;34mf\"\u001b[0m\u001b[0;34mThe truth value of a \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m is ambiguous. \u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "for input_type in inputs:\n",
    "    for metric in [\"mae\", \"rmse\"]:\n",
    "        # Filter data for the selected input type and always include baseline models\n",
    "        df_filtered = results_df[(results_df['input'] == input_type) | (results_df['model'].str.contains(\"Baseline\"))]\n",
    "\n",
    "        # Get the unique models\n",
    "        models = df_filtered['model'].unique()\n",
    "\n",
    "        # Initialize an empty matrix for p-values\n",
    "        pval_matrix = pd.DataFrame(np.nan, index=models, columns=models)\n",
    "\n",
    "        # Fill the matrix with p-values\n",
    "        for i, model1 in enumerate(models):\n",
    "            for j, model2 in enumerate(models):\n",
    "                if i < j:  # Avoid redundant comparisons (matrix is symmetric)\n",
    "                    data1 = df_filtered[df_filtered['model'] == model1].sort_values('fold')[metric]\n",
    "                    data2 = df_filtered[df_filtered['model'] == model2].sort_values('fold')[metric]\n",
    "                    \n",
    "                    # Perform a paired t-test\n",
    "                    if len(data1) == len(data2):  # Ensure the lengths match for paired t-test\n",
    "                        t_stat, p_value = ttest_rel(data1, data2, alternative='less')\n",
    "                        \n",
    "                        # Populate the matrix\n",
    "                        pval_matrix.loc[model1, model2] = p_value\n",
    "                        pval_matrix.loc[model2, model1] = 1 - p_value\n",
    "\n",
    "        print(\"P-Value Matrix:\", input_type, metric)\n",
    "        print(pval_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
