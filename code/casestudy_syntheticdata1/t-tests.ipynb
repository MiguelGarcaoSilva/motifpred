{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata1/variables=[0,2]\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata1/variables=[0,2]\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]\n",
      "Dataset path: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]/scenario1_n=100000_k=3_p=5_min_step=5_max_step=45_variables=[0,2].csv\n",
      "Motif indexes path: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]/motif_indexes_scenario1_n=100000_k=3_p=5_min_step=5_max_step=45.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Load YAML configuration\n",
    "config_path = \"config.yaml\"  # Ensure this is the correct path\n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# Convert base_dir to absolute\n",
    "BASE_DIR = Path(config[\"base_dir\"]).resolve()\n",
    "\n",
    "# Convert other paths to absolute using BASE_DIR\n",
    "RESULTS_DIR = BASE_DIR / config[\"results_dir\"]\n",
    "IMAGES_DIR = BASE_DIR / config[\"images_dir\"]\n",
    "DATA_DIR = BASE_DIR / config[\"data_dir\"]\n",
    "DATASET_PATH = BASE_DIR / config[\"dataset_path\"]\n",
    "MOTIF_INDEXES_PATH = BASE_DIR / config[\"motif_indexes_path\"]\n",
    "LOOKBACK_PERIOD = config.get(\"lookback_period\", None)\n",
    "STEP = config.get(\"step\", None)\n",
    "FORECAST_PERIOD = config.get(\"forecast_period\", None)\n",
    "\n",
    "# Extract additional parameters from YAML\n",
    "N = config[\"n\"]\n",
    "K = config[\"k\"]\n",
    "P = config[\"p\"]\n",
    "VARIABLES_PATTERN = config[\"variables_pattern\"]\n",
    "NORMALIZE_FLAGS = config[\"normalize_flags\"]\n",
    "\n",
    "# Print resolved paths for debugging\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Motif indexes path: {MOTIF_INDEXES_PATH}\")\n",
    "\n",
    "# Ensure results directory exists\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Handling different environments\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = Path(__file__).parent.resolve()\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = Path(os.getcwd()).resolve()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(str(base_dir / \"../\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0    10    22 ... 99922 99956 99992]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(DATASET_PATH, delimiter=\",\").astype(int).reshape((K, N))\n",
    "motif_indexes = np.genfromtxt(MOTIF_INDEXES_PATH, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_series shape: torch.Size([19979, 100, 3])\n",
      "X_mask shape: torch.Size([19979, 100])\n",
      "X_indices shape: torch.Size([19979, 6, 1])\n",
      "y shape: torch.Size([19979, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "#X_series: past window, X_indices: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, P)\n",
    "\n",
    "# X_series, X2, and y are now PyTorch tensors\n",
    "print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, lookback_period)\n",
    "print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Model FFNNIndexes already exists\n",
      "Model LSTMSeries already exists\n",
      "Model LSTMSeries_Masking already exists\n",
      "Model LSTMIndexes already exists\n",
      "Model CNNSeries already exists\n",
      "Model CNNSeries_Masking already exists\n",
      "Model CNNIndexes already exists\n",
      "Model TCNSeries already exists\n",
      "Model TCNSeries_Masking already exists\n",
      "Model TCNIndexes already exists\n",
      "Model TransformerSeries already exists\n",
      "Model TransformerSeries_Masking already exists\n",
      "Model TransformerIndexes already exists\n",
      "Model BaselineAverageIndexes already exists\n",
      "Model BaselineLastDifferenceIndexes already exists\n"
     ]
    }
   ],
   "source": [
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TCN\n",
    "from models.transformer_pytorch import Transformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "from utils.utils import print_study_results, get_best_model_results, plot_best_model_results, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(fold_val_losses, val_losses):\n",
    "        raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    #if not np.allclose(fold_val_losses, val_losses, atol=1):\n",
    "    #    raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        normalize_flags = NORMALIZE_FLAGS\n",
    "        n_trials, num_epochs = (1, 1) if model_type == \"Baseline\" else (n_trials, num_epochs)\n",
    "\n",
    "        if model_type == \"Baseline\":\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "\n",
    "            X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "            normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "            for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                process_baseline_model(\n",
    "                    model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            if input_name == \"Series\":\n",
    "                X = {\"X_series\": X_series}\n",
    "            elif input_name == \"Series_Masking\":\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "            else:\n",
    "                X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "\n",
    "            process_non_baseline_model(\n",
    "                model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "                     model    input fold       mae       rmse\n",
      "0                     FFNN   Series    1  9.389045  11.669245\n",
      "1                     FFNN   Series    2  8.793365  10.960507\n",
      "2                     FFNN   Series    3  9.180077  11.325398\n",
      "3                     FFNN   Series    4  8.737524  11.029864\n",
      "4                     FFNN   Series    5  8.585275  10.890684\n",
      "..                     ...      ...  ...       ...        ...\n",
      "80  BaselineLastDifference  Indexes    1  4.359199   7.539217\n",
      "81  BaselineLastDifference  Indexes    2  4.372966   7.543615\n",
      "82  BaselineLastDifference  Indexes    3  4.356696   7.533073\n",
      "83  BaselineLastDifference  Indexes    4  4.371715   7.540711\n",
      "84  BaselineLastDifference  Indexes    5  4.355444   7.533156\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_279420/2494069276.py:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"fold\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Combine each model with each input\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        # Handle baseline-specific logic\n",
    "        if model_type == \"Baseline\":\n",
    "            n_trials, num_epochs = (1, 1)\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            # Process both BaselineAverage and BaselineLastDifference\n",
    "            baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "            for baseline_type in baseline_variants:\n",
    "                model_name = f\"{baseline_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": baseline_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"fold\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            n_trials = 100\n",
    "            num_epochs = 500\n",
    "\n",
    "            model_name = f\"{model_type}{input_name}\"\n",
    "            print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "            # Construct the results directory path\n",
    "            model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "            results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "            # Skip if results file doesn't exist\n",
    "            if not os.path.exists(results_file):\n",
    "                print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load results from CSV\n",
    "            results = pd.read_csv(results_file)\n",
    "            maes = results[\"test_mae\"].values\n",
    "            rmses = results[\"test_rmse\"].values\n",
    "\n",
    "            # Add results to the dataframe\n",
    "            for i in range(len(maes)):  # Assuming results have folds\n",
    "                results_df = pd.concat([\n",
    "                    results_df,\n",
    "                    pd.DataFrame([{\n",
    "                        \"model\": model_type,\n",
    "                        \"input\": input_name,\n",
    "                        \"fold\": i + 1,\n",
    "                        \"mae\": maes[i],\n",
    "                        \"rmse\": rmses[i]\n",
    "                    }])\n",
    "                ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input fold       mae       rmse\n",
      "0          BaselineAverage         Indexes  3.0  7.061335   9.466859\n",
      "1   BaselineLastDifference         Indexes  3.0  4.363204   7.537955\n",
      "2                      CNN         Indexes  3.0  0.345493   0.555321\n",
      "3                      CNN          Series  3.0  6.417948   8.568752\n",
      "4                      CNN  Series_Masking  3.0  0.701390   0.967899\n",
      "5                     FFNN         Indexes  3.0  0.549793   1.042796\n",
      "6                     FFNN          Series  3.0  8.937057  11.175140\n",
      "7                     FFNN  Series_Masking  3.0  1.012417   1.686616\n",
      "8                     LSTM         Indexes  3.0  0.148808   0.186667\n",
      "9                     LSTM          Series  3.0  4.428348   7.396018\n",
      "10                    LSTM  Series_Masking  3.0  1.099881   2.904646\n",
      "11                     TCN         Indexes  3.0  1.084515   1.616984\n",
      "12                     TCN          Series  3.0  1.152880   1.830841\n",
      "13                     TCN  Series_Masking  3.0  0.477481   0.658084\n",
      "14             Transformer         Indexes  3.0  0.403696   0.533269\n",
      "15             Transformer          Series  3.0  1.750024   3.790114\n",
      "16             Transformer  Series_Masking  3.0  0.553271   0.790670\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_1</th>\n",
       "      <th>InputType_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>InputType_2</th>\n",
       "      <th>Metric</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series</td>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>mae</td>\n",
       "      <td>4.524174e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series</td>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>rmse</td>\n",
       "      <td>3.219293e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>TCN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>mae</td>\n",
       "      <td>3.540011e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>TCN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>rmse</td>\n",
       "      <td>3.328977e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>mae</td>\n",
       "      <td>3.140100e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>rmse</td>\n",
       "      <td>6.535836e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>mae</td>\n",
       "      <td>8.084342e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>rmse</td>\n",
       "      <td>2.631434e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Series</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>mae</td>\n",
       "      <td>4.928297e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNN</td>\n",
       "      <td>Series</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>rmse</td>\n",
       "      <td>4.813531e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model_1 InputType_1      Model_2     InputType_2 Metric       P-Value\n",
       "0         FFNN      Series         FFNN  Series_Masking    mae  4.524174e-07\n",
       "1         FFNN      Series         FFNN  Series_Masking   rmse  3.219293e-07\n",
       "2          TCN      Series          TCN  Series_Masking    mae  3.540011e-03\n",
       "3          TCN      Series          TCN  Series_Masking   rmse  3.328977e-03\n",
       "4  Transformer      Series  Transformer  Series_Masking    mae  3.140100e-02\n",
       "5  Transformer      Series  Transformer  Series_Masking   rmse  6.535836e-03\n",
       "6         LSTM      Series         LSTM  Series_Masking    mae  8.084342e-03\n",
       "7         LSTM      Series         LSTM  Series_Masking   rmse  2.631434e-03\n",
       "8          CNN      Series          CNN  Series_Masking    mae  4.928297e-06\n",
       "9          CNN      Series          CNN  Series_Masking   rmse  4.813531e-06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "models_1 = [\"FFNN\", \"TCN\", \"Transformer\", \"LSTM\", \"CNN\" ]\n",
    "input_types_1 = [\"Series\"]\n",
    "models_2 = [\"FFNN\", \"TCN\", \"Transformer\", \"LSTM\", \"CNN\" ]\n",
    "input_types_2 = [\"Series_Masking\"]\n",
    "\n",
    "# Filter data for the selected input types\n",
    "\n",
    "results = []\n",
    "for model1 in models_1:\n",
    "    for model2 in models_2:\n",
    "        for input_1 in input_types_1:\n",
    "            for input_2 in input_types_2:\n",
    "                for metric in [\"mae\", \"rmse\"]:\n",
    "\n",
    "                    data1 = results_df[(results_df['model'] == model1) & (results_df['input'] == input_1)].sort_values('fold')[metric]\n",
    "                    data2 = results_df[(results_df['model'] == model2) & (results_df['input'] == input_2)].sort_values('fold')[metric]\n",
    "\n",
    "                    # Perform a paired t-test if the lengths match\n",
    "                    if model1 != model2:\n",
    "                        continue\n",
    "                    if len(data1) == len(data2):\n",
    "                        t_stat, p_value = ttest_rel(data1, data2, alternative='greater')\n",
    "                        results.append({\n",
    "                            \"Model_1\": model1,\n",
    "                            \"InputType_1\": input_1,\n",
    "                            \"Model_2\": model2,\n",
    "                            \"InputType_2\": input_2,\n",
    "                            \"Metric\": metric,\n",
    "                            \"P-Value\": p_value\n",
    "                        })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "pval_results_df = pd.DataFrame(results)\n",
    "pval_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
