{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata1/variables=[0,2]\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata1/variables=[0,2]\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata1/variables=[0,2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "from config import RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, MOTIF_INDEXES_PATH, K, N, P, NORMALIZE_FLAGS\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0    10    22 ... 99922 99956 99992]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(DATASET_PATH, delimiter=\",\").astype(int).reshape((K, N))\n",
    "motif_indexes = np.genfromtxt(MOTIF_INDEXES_PATH, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.5035, 0.9978, 0.3884],\n",
      "        [0.6929, 0.1703, 0.1384],\n",
      "        [0.4759, 0.7481, 0.0361],\n",
      "        [0.5062, 0.8469, 0.2588],\n",
      "        [0.2707, 0.4115, 0.6839]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_series shape: torch.Size([19979, 100, 3])\n",
      "X_mask shape: torch.Size([19979, 100])\n",
      "X_indices shape: torch.Size([19979, 6, 1])\n",
      "y shape: torch.Size([19979, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#X_series: past window, X_indices: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X_series, X_indices, X_mask, y = create_dataset(data, lookback_period, step, forecast_period, motif_indexes, P)\n",
    "\n",
    "# X_series, X2, and y are now PyTorch tensors\n",
    "print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, lookback_period)\n",
    "print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Model FFNNIndexes already exists\n",
      "Model LSTMSeries already exists\n",
      "Model LSTMSeries_Masking already exists\n",
      "Model LSTMIndexes already exists\n",
      "Model CNNSeries already exists\n",
      "Model CNNSeries_Masking already exists\n",
      "Model CNNIndexes already exists\n",
      "Model TCNSeries already exists\n",
      "Model TCNSeries_Masking already exists\n",
      "Model TCNIndexes already exists\n",
      "Model TransformerSeries already exists\n",
      "Model TransformerSeries_Masking already exists\n",
      "Model TransformerIndexes already exists\n",
      "Model BaselineAverageIndexes already exists\n",
      "Model BaselineLastDifferenceIndexes already exists\n"
     ]
    }
   ],
   "source": [
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TCN\n",
    "from models.transformer_pytorch import Tramsformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "from utils.utils import print_study_results, get_best_model_results, plot_best_model_results, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(fold_val_losses, val_losses):\n",
    "        raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    #if not np.allclose(fold_val_losses, val_losses, atol=1):\n",
    "    #    raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        normalize_flags = NORMALIZE_FLAGS\n",
    "        n_trials, num_epochs = (1, 1) if model_type == \"Baseline\" else (n_trials, num_epochs)\n",
    "\n",
    "        if model_type == \"Baseline\":\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "\n",
    "            X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "            normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "            for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                process_baseline_model(\n",
    "                    model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            if input_name == \"Series\":\n",
    "                X = {\"X_series\": X_series}\n",
    "            elif input_name == \"Series_Masking\":\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "            else:\n",
    "                X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "\n",
    "            process_non_baseline_model(\n",
    "                model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "                     model    input fold       mae       rmse\n",
      "0                     FFNN   Series    1  9.389045  11.669245\n",
      "1                     FFNN   Series    2  8.793365  10.960507\n",
      "2                     FFNN   Series    3  9.180077  11.325398\n",
      "3                     FFNN   Series    4  8.737524  11.029864\n",
      "4                     FFNN   Series    5  8.585275  10.890684\n",
      "..                     ...      ...  ...       ...        ...\n",
      "80  BaselineLastDifference  Indexes    1  4.359199   7.539217\n",
      "81  BaselineLastDifference  Indexes    2  4.372966   7.543615\n",
      "82  BaselineLastDifference  Indexes    3  4.356696   7.533073\n",
      "83  BaselineLastDifference  Indexes    4  4.371715   7.540711\n",
      "84  BaselineLastDifference  Indexes    5  4.355444   7.533156\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_174099/2494069276.py:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"fold\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Combine each model with each input\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        # Handle baseline-specific logic\n",
    "        if model_type == \"Baseline\":\n",
    "            n_trials, num_epochs = (1, 1)\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            # Process both BaselineAverage and BaselineLastDifference\n",
    "            baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "            for baseline_type in baseline_variants:\n",
    "                model_name = f\"{baseline_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": baseline_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"fold\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            n_trials = 100\n",
    "            num_epochs = 500\n",
    "\n",
    "            model_name = f\"{model_type}{input_name}\"\n",
    "            print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "            # Construct the results directory path\n",
    "            model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "            results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "            # Skip if results file doesn't exist\n",
    "            if not os.path.exists(results_file):\n",
    "                print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load results from CSV\n",
    "            results = pd.read_csv(results_file)\n",
    "            maes = results[\"test_mae\"].values\n",
    "            rmses = results[\"test_rmse\"].values\n",
    "\n",
    "            # Add results to the dataframe\n",
    "            for i in range(len(maes)):  # Assuming results have folds\n",
    "                results_df = pd.concat([\n",
    "                    results_df,\n",
    "                    pd.DataFrame([{\n",
    "                        \"model\": model_type,\n",
    "                        \"input\": input_name,\n",
    "                        \"fold\": i + 1,\n",
    "                        \"mae\": maes[i],\n",
    "                        \"rmse\": rmses[i]\n",
    "                    }])\n",
    "                ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input fold       mae       rmse\n",
      "0          BaselineAverage         Indexes  3.0  7.061335   9.466859\n",
      "1   BaselineLastDifference         Indexes  3.0  4.363204   7.537955\n",
      "2                      CNN         Indexes  3.0  0.345493   0.555321\n",
      "3                      CNN          Series  3.0  6.417948   8.568752\n",
      "4                      CNN  Series_Masking  3.0  0.701390   0.967899\n",
      "5                     FFNN         Indexes  3.0  0.549793   1.042796\n",
      "6                     FFNN          Series  3.0  8.937057  11.175140\n",
      "7                     FFNN  Series_Masking  3.0  1.012417   1.686616\n",
      "8                     LSTM         Indexes  3.0  0.148808   0.186667\n",
      "9                     LSTM          Series  3.0  4.428348   7.396018\n",
      "10                    LSTM  Series_Masking  3.0  1.099881   2.904646\n",
      "11                     TCN         Indexes  3.0  1.084515   1.616984\n",
      "12                     TCN          Series  3.0  1.152880   1.830841\n",
      "13                     TCN  Series_Masking  3.0  0.477481   0.658084\n",
      "14             Transformer         Indexes  3.0  0.403696   0.533269\n",
      "15             Transformer          Series  3.0  1.750024   3.790114\n",
      "16             Transformer  Series_Masking  3.0  0.553271   0.790670\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value Matrix: Indexes mae\n",
      "                            FFNN      LSTM       CNN       TCN  Transformer  \\\n",
      "FFNN                         NaN  0.979128  0.842335  0.011395     0.787777   \n",
      "LSTM                    0.020872       NaN  0.050376  0.000005     0.009799   \n",
      "CNN                     0.157665  0.949624       NaN  0.001719     0.337012   \n",
      "TCN                     0.988605  0.999995  0.998281       NaN     0.999611   \n",
      "Transformer             0.212223  0.990201  0.662988  0.000389          NaN   \n",
      "BaselineAverage         0.999999  1.000000  1.000000  1.000000     1.000000   \n",
      "BaselineLastDifference  0.999994  1.000000  0.999999  1.000000     1.000000   \n",
      "\n",
      "                        BaselineAverage  BaselineLastDifference  \n",
      "FFNN                       7.607594e-07            6.494993e-06  \n",
      "LSTM                       6.118536e-10            3.862235e-09  \n",
      "CNN                        9.228712e-08            6.901462e-07  \n",
      "TCN                        1.844912e-08            2.000335e-07  \n",
      "Transformer                3.376358e-08            1.927926e-07  \n",
      "BaselineAverage                     NaN            1.000000e+00  \n",
      "BaselineLastDifference     9.448475e-11                     NaN  \n"
     ]
    }
   ],
   "source": [
    "input_type = \"Indexes\"\n",
    "metric = \"mae\"\n",
    "\n",
    "# Filter data for the selected input type and always include baseline models\n",
    "df_filtered = results_df[(results_df['input'] == input_type) | (results_df['model'].str.contains(\"Baseline\"))]\n",
    "\n",
    "# Get the unique models\n",
    "models = df_filtered['model'].unique()\n",
    "\n",
    "# Initialize an empty matrix for p-values\n",
    "pval_matrix = pd.DataFrame(np.nan, index=models, columns=models)\n",
    "\n",
    "# Fill the matrix with p-values\n",
    "for i, model1 in enumerate(models):\n",
    "    for j, model2 in enumerate(models):\n",
    "        if i < j:  # Avoid redundant comparisons (matrix is symmetric)\n",
    "            data1 = df_filtered[df_filtered['model'] == model1].sort_values('fold')[metric]\n",
    "            data2 = df_filtered[df_filtered['model'] == model2].sort_values('fold')[metric]\n",
    "            \n",
    "            # Perform a paired t-test\n",
    "            if len(data1) == len(data2):  # Ensure the lengths match for paired t-test\n",
    "                t_stat, p_value = ttest_rel(data1, data2, alternative='less')\n",
    "                \n",
    "                # Populate the matrix\n",
    "                pval_matrix.loc[model1, model2] = p_value\n",
    "                pval_matrix.loc[model2, model1] = 1 - p_value\n",
    "\n",
    "print(\"P-Value Matrix:\", input_type, metric)\n",
    "print(pval_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
