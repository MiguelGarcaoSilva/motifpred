{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/household\n",
      "Dataset path: /home/mgsilva/motifpred/data/household/data_5min_resampled_globalactive_reactive.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from pathlib import Path  \n",
    "from msig import Motif, NullModel\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# Load YAML configuration\n",
    "config_path = \"config.yaml\" \n",
    "with open(config_path, \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "BASE_DIR = Path(config[\"base_dir\"]).resolve()\n",
    "\n",
    "RESULTS_DIR = BASE_DIR / config[\"results_dir\"]\n",
    "IMAGES_DIR = BASE_DIR / config[\"images_dir\"]\n",
    "DATA_DIR = BASE_DIR / config[\"data_dir\"]\n",
    "DATASET_PATH = BASE_DIR / config[\"dataset_path\"]\n",
    "RESULTS_MOTIF_DIR = BASE_DIR / config[\"results_motif_dir\"]\n",
    "\n",
    "VARIABLES = config[\"variables\"]\n",
    "NORMALIZE_FLAGS = config[\"normalize_flags\"]\n",
    "STUMPY_EXCL_ZONE_DENOM = config[\"stumpy_excl_zone_denom\"]\n",
    "TOP_K_MP = config[\"top_k_mp\"]\n",
    "INCLUDE = config[\"include\"]\n",
    "NORMALIZE = config[\"normalize\"]\n",
    "SUBSEQUENCES_LENGTHS = config[\"subsequences_lengths\"]\n",
    "NTOP_MOTIFS = config[\"ntop_motifs\"]\n",
    "MOTIF_SIZE = config[\"motif_size\"]\n",
    "LOOKBACK_PERIOD = config[\"lookback_period\"]\n",
    "STEP = config[\"step\"]\n",
    "FORECAST_PERIOD = config[\"forecast_period\"]\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = Path(__file__).parent.resolve()\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = Path(os.getcwd()).resolve()\n",
    "\n",
    "sys.path.append(str(base_dir / \"../\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(os.path.join(RESULTS_DIR, f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"))\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=[\"#Matches\", \"ID\"], ascending=[False, True]).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2944, 1.3644, 1.4672, ..., 0.7808, 0.7676, 0.634 ],\n",
       "       [0.    , 0.0776, 0.2188, ..., 0.1644, 0.1492, 0.0608]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as \n",
    "data_df = pd.read_csv(DATASET_PATH, index_col=0).astype(float)\n",
    "data_df = data_df[VARIABLES]\n",
    "data = data_df.values.T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 6 with size 24 and 359 indexes\n",
      "Processing model FFNNSeries for motif 6\n",
      "Model FFNNSeries already exists for motif 6\n",
      "Processing model FFNNSeries_Masking for motif 6\n",
      "Model FFNNSeries_Masking already exists for motif 6\n",
      "Processing model FFNNIndexes for motif 6\n",
      "Model FFNNIndexes already exists for motif 6\n",
      "Processing model LSTMSeries for motif 6\n",
      "Model LSTMSeries already exists for motif 6\n",
      "Processing model LSTMSeries_Masking for motif 6\n",
      "Model LSTMSeries_Masking already exists for motif 6\n",
      "Processing model LSTMIndexes for motif 6\n",
      "Model LSTMIndexes already exists for motif 6\n",
      "Processing model CNNSeries for motif 6\n",
      "Model CNNSeries already exists for motif 6\n",
      "Processing model CNNSeries_Masking for motif 6\n",
      "Model CNNSeries_Masking already exists for motif 6\n",
      "Processing model CNNIndexes for motif 6\n",
      "Model CNNIndexes already exists for motif 6\n",
      "Processing model TCNSeries for motif 6\n",
      "Model TCNSeries already exists for motif 6\n",
      "Processing model TCNSeries_Masking for motif 6\n",
      "Model TCNSeries_Masking already exists for motif 6\n",
      "Processing model TCNIndexes for motif 6\n",
      "Model TCNIndexes already exists for motif 6\n",
      "Processing model TransformerSeries for motif 6\n",
      "Best hyperparameters: {'learning_rate': 7.595148737112702e-05, 'd_model': 512, 'n_heads': 4, 'e_layers': 2, 'dim_feedforward': 256, 'dropout': 0.07698080959320366, 'batch_size': 16}\n",
      "Early stopping at epoch 17, with best epoch being 6\n",
      "Test loss: 1431.59814453125\n",
      "Retrained test loss: 1230.326904296875\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Best model test loss does not match the one obtained from the study",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 126\u001b[0m\n\u001b[1;32m    118\u001b[0m model_params_map \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFFNN\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_sizes_list\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_sizes_list\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdim_feedforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    124\u001b[0m }\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00minput_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for motif \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 126\u001b[0m \u001b[43mprocess_non_baseline_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_flags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 73\u001b[0m, in \u001b[0;36mprocess_non_baseline_model\u001b[0;34m(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y, motif_id)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrained test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretrained_test_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model test loss does not match the one obtained from the study\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: [test_loss],\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_mae\u001b[39m\u001b[38;5;124m\"\u001b[39m: [test_mae],\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_rmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: [test_rmse]\n\u001b[1;32m     79\u001b[0m })\n\u001b[1;32m     80\u001b[0m results\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_results_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mException\u001b[0m: Best model test loss does not match the one obtained from the study"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import ast\n",
    "import pandas as pd\n",
    "from utils.utils import create_dataset, get_best_model_results_traindevtest, plot_best_model_results_traindevtest, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TCN\n",
    "from models.transformer_pytorch import Transformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "\n",
    "\n",
    "models = [ \"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists for motif {motif_id}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing model {model_name} for motif {motif_id}\")\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    _, _, _, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(test_loss, test_losses, atol=0.1):\n",
    "        print(f\"Test loss: {test_loss}\")\n",
    "        print(f\"Retrained test loss: {test_losses}\")\n",
    "        raise Exception(\"Best model test loss does not match the one obtained from the study\")\n",
    "\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y, motif_id):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists for motif {motif_id}\")\n",
    "        return\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse  = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    _, _, _, retrained_test_losses, retrained_test_mae, retrained_test_rmse, retrained_all_predictions, retrained_all_true_values = get_preds_best_config_train_val_test(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "    \n",
    "    if not np.allclose(test_loss, retrained_test_losses, atol=50):\n",
    "        print(f\"Test loss: {test_loss}\")\n",
    "        print(f\"Retrained test loss: {retrained_test_losses}\")\n",
    "        raise Exception(\"Best model test loss does not match the one obtained from the study\")\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"test_loss\": [test_loss],\n",
    "        \"test_mae\": [test_mae],\n",
    "        \"test_rmse\": [test_rmse]\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False)\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            normalize_flags = NORMALIZE_FLAGS\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "            \n",
    "            if model_type == \"Baseline\":\n",
    "                if input_name != \"Indexes\":\n",
    "                    continue\n",
    "\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "                normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "                for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                    process_baseline_model(model_class, input_name, X, normalize_flags, 1, 1, seed, pipeline, y, i+1)\n",
    "            else:\n",
    "                if input_name == \"Series\":\n",
    "                    X = {\"X_series\": X_series}\n",
    "                elif input_name == \"Series_Masking\":\n",
    "                    X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "                else:\n",
    "                    X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "                model_params_map = {\n",
    "                    \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                    \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                    \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                    \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                    \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "                }\n",
    "                print(f\"Processing model {model_type}{input_name} for motif {i+1}\")\n",
    "                process_non_baseline_model(\n",
    "                    model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y, i+1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing motif 6 with 359 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 18 with 358 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 2 with 298 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 8 with 279 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "Processing motif 7 with 268 indexes\n",
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "                     model           input motif        mae       rmse\n",
      "0                     FFNN          Series     1  25.591469  37.014912\n",
      "1                     FFNN  Series_Masking     1  26.125835  35.585533\n",
      "2                     FFNN         Indexes     1  28.169262  38.871849\n",
      "3                     LSTM          Series     1  26.270823  35.308262\n",
      "4                     LSTM  Series_Masking     1  26.325588  35.268147\n",
      "..                     ...             ...   ...        ...        ...\n",
      "65                     TCN          Series     1  32.467461  36.947479\n",
      "66                     TCN  Series_Masking     1  32.822128  50.910583\n",
      "67                     TCN         Indexes     1  27.996260  34.853374\n",
      "68         BaselineAverage         Indexes     1  28.105087  38.589703\n",
      "69  BaselineLastDifference         Indexes     1  35.602772  48.467937\n",
      "\n",
      "[70 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_280421/393695975.py:83: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "models = [ \"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\" \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"motif\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Loop through each motif\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    motif_id = i + 1\n",
    "    print(f\"Processing motif {motif_id} with {len(motif_indexes)} indexes\")\n",
    "    \n",
    "    for model_type in models:\n",
    "        for input_name in inputs:\n",
    "            # Handle baseline-specific logic\n",
    "            if model_type == \"Baseline\":\n",
    "                n_trials, num_epochs = (1, 1)\n",
    "                if input_name != \"Indexes\":\n",
    "                    continue\n",
    "                \n",
    "                # Process both BaselineAverage and BaselineLastDifference\n",
    "                baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "                for baseline_type in baseline_variants:\n",
    "                    model_name = f\"{baseline_type}{input_name}\"\n",
    "                    print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                    # Construct the results directory path\n",
    "                    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "                    results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                    # Skip if results file doesn't exist\n",
    "                    if not os.path.exists(results_file):\n",
    "                        print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    # Load results from CSV\n",
    "                    results = pd.read_csv(results_file)\n",
    "                    maes = results[\"test_mae\"].values\n",
    "                    rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                    # Add results to the dataframe\n",
    "                    for i in range(len(maes)):  # Assuming results have folds\n",
    "                        results_df = pd.concat([\n",
    "                            results_df,\n",
    "                            pd.DataFrame([{\n",
    "                                \"model\": baseline_type,\n",
    "                                \"input\": input_name,\n",
    "                                \"motif\": i + 1,\n",
    "                                \"mae\": maes[i],\n",
    "                                \"rmse\": rmses[i]\n",
    "                            }])\n",
    "                        ], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                n_trials = 100\n",
    "                num_epochs = 500\n",
    "\n",
    "                model_name = f\"{model_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{motif_id}\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": model_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"motif\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input motif        mae       rmse\n",
      "0          BaselineAverage         Indexes   1.0  37.434675  48.206358\n",
      "1   BaselineLastDifference         Indexes   1.0  40.447647  53.754295\n",
      "2                      CNN         Indexes   1.0  31.925813  42.335421\n",
      "3                      CNN          Series   1.0  32.803692  42.631120\n",
      "4                      CNN  Series_Masking   1.0  35.722453  45.665712\n",
      "5                     FFNN         Indexes   1.0  31.844345  42.039991\n",
      "6                     FFNN          Series   1.0  34.523452  44.126491\n",
      "7                     FFNN  Series_Masking   1.0  33.268448  45.107064\n",
      "8                     LSTM         Indexes   1.0  30.800459  40.969523\n",
      "9                     LSTM          Series   1.0  32.418578  41.870246\n",
      "10                    LSTM  Series_Masking   1.0  31.152064  40.939259\n",
      "11                     TCN         Indexes   1.0  31.660012  42.332847\n",
      "12                     TCN          Series   1.0  32.181380  41.624569\n",
      "13                     TCN  Series_Masking   1.0  32.557570  46.219292\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_1</th>\n",
       "      <th>InputType_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>InputType_2</th>\n",
       "      <th>Metric</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.155132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Series_Masking</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.236713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.107958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFNN</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>BaselineAverage</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.088931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_1     InputType_1          Model_2 InputType_2 Metric   P-Value\n",
       "0    FFNN  Series_Masking  BaselineAverage     Indexes    mae  0.155132\n",
       "1    FFNN  Series_Masking  BaselineAverage     Indexes   rmse  0.236713\n",
       "2    FFNN         Indexes  BaselineAverage     Indexes    mae  0.107958\n",
       "3    FFNN         Indexes  BaselineAverage     Indexes   rmse  0.088931"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "models_1 = [\"FFNN\" ]\n",
    "input_types_1 = [\"Series_Masking\",\"Indexes\"]\n",
    "models_2 = [\"BaselineAverage\" ]\n",
    "input_types_2 = [\"Indexes\"]\n",
    "\n",
    "# Filter data for the selected input types\n",
    "\n",
    "results = []\n",
    "for model1 in models_1:\n",
    "    for model2 in models_2:\n",
    "        for input_1 in input_types_1:\n",
    "            for input_2 in input_types_2:\n",
    "                for metric in [\"mae\", \"rmse\"]:\n",
    "\n",
    "                    data1 = results_df[(results_df['model'] == model1) & (results_df['input'] == input_1)].sort_values('motif')[metric]\n",
    "                    data2 = results_df[(results_df['model'] == model2) & (results_df['input'] == input_2)].sort_values('motif')[metric]\n",
    "\n",
    "                    if len(data1) == len(data2):\n",
    "                        t_stat, p_value = ttest_rel(data1, data2, alternative='less')\n",
    "                        results.append({\n",
    "                            \"Model_1\": model1,\n",
    "                            \"InputType_1\": input_1,\n",
    "                            \"Model_2\": model2,\n",
    "                            \"InputType_2\": input_2,\n",
    "                            \"Metric\": metric,\n",
    "                            \"P-Value\": p_value\n",
    "                        })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "pval_results_df = pd.DataFrame(results)\n",
    "pval_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
