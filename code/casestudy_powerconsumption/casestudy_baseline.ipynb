{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, VARIABLES, NORMALIZE_FLAGS, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS, NTOP_MOTIFS, MOTIF_SIZE\n",
    "from config import LOOKBACK_PERIOD, STEP, FORECAST_PERIOD\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=[\"#Matches\", \"ID\"], ascending=[False, True]).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3087, 0.0736, 0.4216],\n",
      "        [0.0691, 0.2332, 0.4047],\n",
      "        [0.2162, 0.9927, 0.4128],\n",
      "        [0.5938, 0.6128, 0.1519],\n",
      "        [0.0453, 0.5035, 0.9978]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2944, 1.3644, 1.4672, ..., 0.7808, 0.7676, 0.634 ],\n",
       "       [5.28  , 5.6   , 6.04  , ..., 3.2   , 3.16  , 2.64  ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as \n",
    "data_df = pd.read_csv(DATASET_PATH, index_col=0).astype(float)\n",
    "data_df = data_df[VARIABLES]\n",
    "labels = pd.read_csv(DATA_DIR  / f\"labels.csv\", index_col=0).astype(float)\n",
    "data = data_df.values.T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 9 with size 24 and 484 indexes \n",
      "X_series shape: torch.Size([2985, 576, 2])\n",
      "X_indices shape: torch.Size([2985, 25, 1])\n",
      "X_mask shape: torch.Size([2985, 576])\n",
      "y shape: torch.Size([2985, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979d3a77de6a46f393ba26859278b188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 488.404052734375, Test MAE: 16.858551025390625, Test RMSE: 22.099864959716797\n",
      "Evaluating motif 6 with size 24 and 357 indexes \n",
      "X_series shape: torch.Size([2974, 576, 2])\n",
      "X_indices shape: torch.Size([2974, 20, 1])\n",
      "X_mask shape: torch.Size([2974, 576])\n",
      "y shape: torch.Size([2974, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3489184f7ce4c1ea8878ddd97b7153b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1576.9000244140625, Test MAE: 28.369747161865234, Test RMSE: 39.710201263427734\n",
      "Evaluating motif 8 with size 24 and 302 indexes \n",
      "X_series shape: torch.Size([2977, 576, 2])\n",
      "X_indices shape: torch.Size([2977, 17, 1])\n",
      "X_mask shape: torch.Size([2977, 576])\n",
      "y shape: torch.Size([2977, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9133602d4b8641d898ac9c504365ffa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 2460.440673828125, Test MAE: 33.385379791259766, Test RMSE: 49.60282897949219\n",
      "Evaluating motif 11 with size 24 and 283 indexes \n",
      "X_series shape: torch.Size([2991, 576, 2])\n",
      "X_indices shape: torch.Size([2991, 19, 1])\n",
      "X_mask shape: torch.Size([2991, 576])\n",
      "y shape: torch.Size([2991, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72512e54b04dffb4403484a53c4d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1159.0826416015625, Test MAE: 27.461578369140625, Test RMSE: 34.04530334472656\n",
      "Evaluating motif 1 with size 24 and 271 indexes \n",
      "X_series shape: torch.Size([2984, 576, 2])\n",
      "X_indices shape: torch.Size([2984, 16, 1])\n",
      "X_mask shape: torch.Size([2984, 576])\n",
      "y shape: torch.Size([2984, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8eec8ff4bd445f5bef4d09809ede26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1126.423583984375, Test MAE: 25.66509246826172, Test RMSE: 33.562232971191406\n",
      "Aggregated Results Across Top 10 Motifs:\n",
      "Mean Test Loss: 1362.2501953125 ± 650.0146463927978\n",
      "Mean Test MAE: 26.348069763183595 ± 5.391998464603725\n",
      "Mean Test RMSE: 35.80408630371094 ± 8.962008034112415\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "\n",
    "test_losses_list, test_mae_list, test_rmse_list  = [], [], []\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 1\n",
    "    num_epochs = 1\n",
    "    model_name = \"BaselineAverage\" \n",
    "    model_type = \"Baseline\"\n",
    "    \n",
    "    suggestion_dict = {\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[4,8, 16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    model_params_keys = []\n",
    "    \n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "    \n",
    "    X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "    normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "    \n",
    "    run_optuna_study(pipeline.run_train_val_test, eval(model_name), model_type, suggestion_dict,  model_params_keys, seed, X , y, normalize_flags, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_name), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags)\n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 10 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 10 with size 24 and 484 indexes \n",
      "X_series shape: torch.Size([2985, 576, 2])\n",
      "X_indices shape: torch.Size([2985, 25, 1])\n",
      "X_mask shape: torch.Size([2985, 576])\n",
      "y shape: torch.Size([2985, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fa03a68e724fffa0342fc1a82731c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 913.5816650390625, Test MAE: 22.4451904296875, Test RMSE: 30.225513458251953\n",
      "Evaluating motif 7 with size 24 and 357 indexes \n",
      "X_series shape: torch.Size([2974, 576, 2])\n",
      "X_indices shape: torch.Size([2974, 20, 1])\n",
      "X_mask shape: torch.Size([2974, 576])\n",
      "y shape: torch.Size([2974, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37100cb8432d410da022beae41f8c641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1923.778076171875, Test MAE: 33.97982406616211, Test RMSE: 43.86089324951172\n",
      "Evaluating motif 9 with size 24 and 302 indexes \n",
      "X_series shape: torch.Size([2977, 576, 2])\n",
      "X_indices shape: torch.Size([2977, 17, 1])\n",
      "X_mask shape: torch.Size([2977, 576])\n",
      "y shape: torch.Size([2977, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5416b0cce24491b5b84e85492d1a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 3605.262451171875, Test MAE: 42.029151916503906, Test RMSE: 60.04383850097656\n",
      "Evaluating motif 12 with size 24 and 283 indexes \n",
      "X_series shape: torch.Size([2991, 576, 2])\n",
      "X_indices shape: torch.Size([2991, 19, 1])\n",
      "X_mask shape: torch.Size([2991, 576])\n",
      "y shape: torch.Size([2991, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e254663faa41f3aaa54c9ec893197e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1777.3907470703125, Test MAE: 34.515625, Test RMSE: 42.15911102294922\n",
      "Evaluating motif 2 with size 24 and 271 indexes \n",
      "X_series shape: torch.Size([2984, 576, 2])\n",
      "X_indices shape: torch.Size([2984, 16, 1])\n",
      "X_mask shape: torch.Size([2984, 576])\n",
      "y shape: torch.Size([2984, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9644d4c88617423eae92ddba86921733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'batch_size': 128}\n",
      "Best epoch: 0\n",
      "Test Loss: 1694.7069091796875, Test MAE: 31.060401916503906, Test RMSE: 41.16681671142578\n",
      "Aggregated Results Across Top 10 Motifs:\n",
      "Mean Test Loss: 1672.5970825195313 ± 835.4659438851766\n",
      "Mean Test MAE: 29.57705421447754 ± 6.703673191215174\n",
      "Mean Test RMSE: 39.647660446166995 ± 10.032949389280843\n"
     ]
    }
   ],
   "source": [
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 1\n",
    "    num_epochs = 1\n",
    "    model_name = \"BaselineLastDifference\" \n",
    "    model_type = \"Baseline\"\n",
    "    \n",
    "    suggestion_dict = {\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    model_params_keys = []\n",
    "    \n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "    \n",
    "    X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "    normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "    \n",
    "    run_optuna_study(pipeline.run_train_val_test, eval(model_name), model_type, suggestion_dict,  model_params_keys, seed, X , y, normalize_flags, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "    \n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "    \n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_name), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags)\n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 10 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
