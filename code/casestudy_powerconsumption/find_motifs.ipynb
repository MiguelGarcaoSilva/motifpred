{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 14:50:50,472 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "2025-01-29 14:50:50,472 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "2025-01-29 14:50:50,472 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, VARIABLES, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 77760)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(DATASET_PATH, index_col=0).astype(float)\n",
    "data_df = data_df[VARIABLES]\n",
    "labels = pd.read_csv(DATA_DIR  / f\"labels.csv\", index_col=0).astype(float)\n",
    "data = data_df.values.T\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 14:50:50,675 - INFO - init\n"
     ]
    }
   ],
   "source": [
    "# motif discovery\n",
    "import stumpy\n",
    "from stumpy import config\n",
    "\n",
    "config.STUMPY_EXCL_ZONE_DENOM = STUMPY_EXCL_ZONE_DENOM  \n",
    "\n",
    "for m in SUBSQUENCES_LENGTHS:\n",
    "    mp, mp_indices = stumpy.mstump(data, m, normalize=NORMALIZE)\n",
    "    np.save(\n",
    "        RESULTS_MOTIF_DIR / f\"normalized_{NORMALIZE}_top_{TOP_K_MP}_m_{m}_mp.npy\",\n",
    "        mp,\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    np.save(\n",
    "        RESULTS_MOTIF_DIR / f\"normalized_{NORMALIZE}_top_{TOP_K_MP}_m_{m}_mp_indices.npy\",\n",
    "        mp_indices,\n",
    "        allow_pickle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_summary_motifs(\n",
    "    motif_indices,\n",
    "    motif_distances,\n",
    "    motif_subspaces,\n",
    "    data,\n",
    "    k_distances,\n",
    "    m,\n",
    "    normalize,\n",
    "    max_allowed_dist,\n",
    "):\n",
    "    mp_stats_table = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"ID\",\n",
    "            \"k_distances\",\n",
    "            \"Features\",\n",
    "            \"m\",\n",
    "            \"#Matches\",\n",
    "            \"Indices\",\n",
    "            \"max(dists)\",\n",
    "            \"min(dists)\",\n",
    "            \"med(dists)\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    motif_index = 0\n",
    "\n",
    "    n_vars, n_time = data.shape\n",
    "\n",
    "    if normalize:\n",
    "        data = (data - np.mean(data, axis=1)[:, np.newaxis]) / np.std(data, axis=1)[\n",
    "            :, np.newaxis\n",
    "        ]\n",
    "\n",
    "\n",
    "    for motif_indice, match_indices in enumerate(motif_indices):\n",
    "        dimensions = motif_subspaces[motif_indice]\n",
    "\n",
    "        # remove filling values of -1 and Nans from motif_indices and match_distances\n",
    "        match_indices = match_indices[match_indices != -1]\n",
    "        match_distances = motif_distances[motif_indice]\n",
    "        match_distances = match_distances[~np.isnan(match_distances)]\n",
    "\n",
    "        # if is empty, skip\n",
    "        if len(match_indices) == 0:\n",
    "            continue\n",
    "\n",
    "        excl_zone = np.ceil(m / config.STUMPY_EXCL_ZONE_DENOM)\n",
    "\n",
    "        # remove trivial matches\n",
    "        non_trivial_matches = []\n",
    "        for indice in match_indices:\n",
    "            trivial = False\n",
    "            for indice_new in non_trivial_matches:\n",
    "                if abs(indice - indice_new) <= excl_zone:\n",
    "                    trivial = True\n",
    "                    break\n",
    "            if not trivial:\n",
    "                non_trivial_matches.append(indice)\n",
    "        match_indices = non_trivial_matches\n",
    "\n",
    "        max_possible_matches = int(np.floor((n_time - m) / excl_zone + 1))\n",
    "\n",
    "\n",
    "        max_dist = np.max(match_distances)\n",
    "        min_dist = np.min(match_distances[1:])\n",
    "\n",
    "        if k_distances is None:  # consider all matches\n",
    "            med_dist = np.median(match_distances[1:])\n",
    "        else:  # consider only the k closest matches\n",
    "            med_dist = np.median(match_distances[1 : k_distances + 1])\n",
    "\n",
    "        \n",
    "        # data features are now the ones in the dimensions\n",
    "        used_features = [f\"{dimension}\" for dimension in dimensions]\n",
    "\n",
    "        stats_df = {\n",
    "            \"ID\": str(motif_index),\n",
    "            \"k\": len(dimensions),\n",
    "            \"Features\": \",\".join(used_features),\n",
    "            \"m\": m,\n",
    "            \"#Matches\": len(match_indices) - 1,\n",
    "            \"Indices\": match_indices,\n",
    "            \"max(dists)\": np.around(max_dist, 3),\n",
    "            \"min(dists)\": np.around(min_dist, 3),\n",
    "            \"med(dists)\": np.around(med_dist, 3),\n",
    "        }\n",
    "\n",
    "        mp_stats_table = (\n",
    "            pd.DataFrame.from_records([stats_df])\n",
    "            if mp_stats_table.empty\n",
    "            else pd.concat(\n",
    "                [mp_stats_table, pd.DataFrame.from_records([stats_df])],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        motif_index += 1\n",
    "    return mp_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_distances = None\n",
    "min_neighbors = 2\n",
    "cutoff = np.inf\n",
    "max_matches = 99999\n",
    "max_distance = None\n",
    "max_motifs = 99999\n",
    "k = 1\n",
    "\n",
    "# Initialize mp_stats_table outside the loop to accumulate results\n",
    "mp_stats_table = pd.DataFrame()\n",
    "\n",
    "for m in SUBSQUENCES_LENGTHS:\n",
    "    mp = np.load(\n",
    "        RESULTS_MOTIF_DIR / f\"normalized_{NORMALIZE}_top_{TOP_K_MP}_m_{m}_mp.npy\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "    indices = np.load(\n",
    "        RESULTS_MOTIF_DIR / f\"normalized_{NORMALIZE}_top_{TOP_K_MP}_m_{m}_mp_indices.npy\",\n",
    "        allow_pickle=True,\n",
    "    )\n",
    "\n",
    "    motif_distances, motif_indices, motif_subspaces, motif_mdls = stumpy.mmotifs(\n",
    "        data,\n",
    "        mp,\n",
    "        indices,\n",
    "        min_neighbors=min_neighbors,\n",
    "        max_distance=max_distance,\n",
    "        cutoffs=cutoff,\n",
    "        max_matches=max_matches,\n",
    "        max_motifs=max_motifs,\n",
    "        k=k,\n",
    "        include=INCLUDE,\n",
    "        normalize=NORMALIZE,\n",
    "    )\n",
    "    if len(motif_indices[0]) == 0:\n",
    "        continue\n",
    "\n",
    "    # Create the table for the current iteration\n",
    "    table = table_summary_motifs(\n",
    "        motif_indices,\n",
    "        motif_distances,\n",
    "        motif_subspaces,\n",
    "        data,\n",
    "        k_distances,\n",
    "        m,\n",
    "        NORMALIZE,\n",
    "        max_distance,\n",
    "    )\n",
    "    # Append the current table to mp_stats_table\n",
    "    mp_stats_table = pd.concat([mp_stats_table, table], ignore_index=True)\n",
    "\n",
    "# Save the accumulated mp_stats_table to CSV\n",
    "mp_stats_table.to_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rrll}\n",
      "\\toprule\n",
      "m & #motifs & avg_n_matches & avg_n_features \\\\\n",
      "\\midrule\n",
      "60 & 21 & (458.71, 213.2) & (2.0, 0.0) \\\\\n",
      "180 & 14 & (163.5, 96.393) & (2.0, 0.0) \\\\\n",
      "360 & 13 & (80.92, 36.466) & (2.0, 0.0) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "\n",
    "motif_lengths = mp_stats_table[\"m\"].unique()\n",
    "motif_stats_table = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"m\",\n",
    "        \"#motifs\",\n",
    "        \"avg_n_matches\",\n",
    "        \"avg_n_features\"\n",
    "    ]\n",
    ")\n",
    "for m in motif_lengths:\n",
    "    table = mp_stats_table[mp_stats_table[\"m\"] == m]\n",
    "    if table.empty:\n",
    "        continue\n",
    "    n_motifs = table.shape[0]\n",
    "\n",
    "    avg_n_matches = (\n",
    "        round(table[\"#Matches\"].mean(), 2),\n",
    "        round(table[\"#Matches\"].std(), 3),\n",
    "    )\n",
    "\n",
    "    avg_n_features = (\n",
    "        round(table[\"k\"].mean(), 2),\n",
    "        round(table[\"k\"].std(), 3),\n",
    "    )\n",
    "\n",
    "    stats_df = {\n",
    "        \"m\": m,\n",
    "        \"#motifs\": n_motifs,\n",
    "        \"avg_n_matches\": avg_n_matches,\n",
    "        \"avg_n_features\": avg_n_features,\n",
    "    }\n",
    "\n",
    "    motif_stats_table = (\n",
    "        pd.DataFrame.from_records([stats_df])\n",
    "        if motif_stats_table.empty\n",
    "        else pd.concat(\n",
    "            [motif_stats_table, pd.DataFrame.from_records([stats_df])],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "print(motif_stats_table.to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## m:60 #########\n",
      "\\begin{tabular}{rrrlrrr}\n",
      "\\toprule\n",
      "ID & #Matches & k & Features & max(dists) & min(dists) & med(dists) \\\\\n",
      "\\midrule\n",
      "5 & 836 & 2 & 1,0 & 7.966 & 1.144 & 5.823 \\\\\n",
      "20 & 758 & 2 & 1,0 & 8.785 & 6.080 & 8.252 \\\\\n",
      "7 & 726 & 2 & 0,1 & 7.731 & 1.371 & 5.003 \\\\\n",
      "6 & 720 & 2 & 0,1 & 6.928 & 1.270 & 4.671 \\\\\n",
      "10 & 706 & 2 & 0,1 & 6.582 & 1.695 & 4.466 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "########## m:180 #########\n",
      "\\begin{tabular}{rrrlrrr}\n",
      "\\toprule\n",
      "ID & #Matches & k & Features & max(dists) & min(dists) & med(dists) \\\\\n",
      "\\midrule\n",
      "8 & 349 & 2 & 0,1 & 15.648 & 5.152 & 13.890 \\\\\n",
      "10 & 333 & 2 & 0,1 & 15.999 & 7.742 & 14.747 \\\\\n",
      "1 & 235 & 2 & 0,1 & 13.549 & 2.670 & 10.097 \\\\\n",
      "9 & 214 & 2 & 0,1 & 14.149 & 7.112 & 13.212 \\\\\n",
      "4 & 193 & 2 & 0,1 & 12.727 & 3.445 & 9.257 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "########## m:360 #########\n",
      "\\begin{tabular}{rrrlrrr}\n",
      "\\toprule\n",
      "ID & #Matches & k & Features & max(dists) & min(dists) & med(dists) \\\\\n",
      "\\midrule\n",
      "7 & 160 & 2 & 0,1 & 23.008 & 9.699 & 19.923 \\\\\n",
      "11 & 125 & 2 & 0,1 & 21.418 & 15.772 & 20.337 \\\\\n",
      "6 & 105 & 2 & 1,0 & 18.282 & 9.406 & 14.435 \\\\\n",
      "2 & 95 & 2 & 1,0 & 15.008 & 5.496 & 10.377 \\\\\n",
      "3 & 93 & 2 & 0,1 & 17.693 & 6.439 & 14.490 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "\n",
    "subsequence_lengths = mp_stats_table[\"m\"].unique()\n",
    "for m in subsequence_lengths:\n",
    "    print(\"########## m:{} #########\".format(m))\n",
    "    top_motifs = mp_stats_table[mp_stats_table[\"m\"] == m]\n",
    "    top_motifs = top_motifs.sort_values(by=\"#Matches\", ascending=False).head(5)\n",
    "    top_motifs = top_motifs[\n",
    "        [\n",
    "            \"ID\",\n",
    "            \"#Matches\",\n",
    "            \"k\",\n",
    "            \"Features\",\n",
    "            \"max(dists)\",\n",
    "            \"min(dists)\",\n",
    "            \"med(dists)\",\n",
    "        ]\n",
    "    ]\n",
    "    print(top_motifs.to_latex(index=False, float_format=\"%.3f\"))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif(ts_list, features, m, motif_indexes, motif_name):\n",
    "    # Generate the time range starting at 2008-09-01 00:00:00 with 77760 minutes\n",
    "    start_time = pd.Timestamp(\"2008-09-01 00:00:00\")\n",
    "    time_range = pd.date_range(start=start_time, periods=77760, freq=\"min\")\n",
    "\n",
    "    # Define 5 equally spaced indices for xticks on the right plots\n",
    "    xtick_indices = np.linspace(0, len(time_range) - 1, 5, dtype=int)\n",
    "    xtick_labels = [\n",
    "        time_range[idx].strftime(\"%d,%b \\n %H:%M:%S\") for idx in xtick_indices\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        ncols=2, nrows=len(ts_list), figsize=(10, 2 * len(ts_list)), squeeze=False\n",
    "    )\n",
    "\n",
    "    for i in range(len(ts_list)):\n",
    "        ts = ts_list[i]\n",
    "        # plot light grey on the right side\n",
    "        axes[i, 1].plot(ts, color=\"black\", linewidth=0.5, alpha=0.5)\n",
    "\n",
    "        # Set unique colors for motifs\n",
    "        colors = plt.cm.tab20(np.linspace(0, 1, len(motif_indexes)))\n",
    "        axes[i, 0].set_prop_cycle(\"color\", colors)\n",
    "        axes[i, 1].set_prop_cycle(\"color\", colors)\n",
    "\n",
    "        # Plot motifs on the left and highlight on the right\n",
    "        for index in motif_indexes:\n",
    "            subsequence_match = ts.iloc[index : index + m]\n",
    "            axes[i, 0].plot(subsequence_match.values)  # Ensure left plot is drawn\n",
    "            axes[i, 1].plot(subsequence_match, linewidth=2)\n",
    "\n",
    "        # Set y-axis labels for left plot\n",
    "        # Split long y-axis labels (e.g., those with 3 words) into multiple lines\n",
    "        words = features[i].split()\n",
    "        if len(words) == 3:\n",
    "            wrapped_label = (\n",
    "                f\"{' '.join(words[:-1])}\\n{words[-1]}\"  # Add \\n before the last word\n",
    "            )\n",
    "        else:\n",
    "            wrapped_label = features[i]  # No line break for 2 words or less\n",
    "\n",
    "        # Set y-axis labels for left plot\n",
    "        axes[i, 0].set_ylabel(wrapped_label, rotation=90, size=\"large\")\n",
    "        xticks = [0] + list(range(max(1, m // 5), m - 1, max(1, m // 5))) + [m - 1]\n",
    "        xticklabels = [\"i\"] + [f\"i+{t}\" for t in xticks[1:-1]] + [f\"i+{m-1}\"]\n",
    "\n",
    "        axes[i, 0].set_xticks(xticks)\n",
    "        axes[i, 0].set_xticklabels(xticklabels)\n",
    "        plt.setp(axes[i, 0].xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "        # Add custom xticks and labels to the right plots\n",
    "        axes[i, 1].set_xticks(xtick_indices)\n",
    "        axes[i, 1].set_xticklabels(xtick_labels, rotation=45)\n",
    "\n",
    "        # Only display x-axis on the last row of plots\n",
    "        if i != len(ts_list) - 1:\n",
    "            axes[i, 0].axes.get_xaxis().set_visible(False)\n",
    "            axes[i, 1].axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    # Set titles for the two columns\n",
    "    axes[0, 0].set_title(\"Raw Subsequences\")\n",
    "    axes[0, 1].set_title(\"Motif in TS\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "        images_dir + \"/m=\" + str(m) + \"_motif_\" + str(motif_name) + \".pdf\",\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load motif statistics table\u001b[39;00m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mresults_dir\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable_motifs_normalize=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnormalize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_min_neighbors=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_distance=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_distance\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cutoff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_matches=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_motifs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_motifs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m mp_stats_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Extract unique subsequence lengths\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# Load motif statistics table\n",
    "file_path = os.path.join(\n",
    "    results_dir,\n",
    "    f\"table_motifs_normalize={normalize}_min_neighbors={min_neighbors}_max_distance={max_distance}_cutoff={cutoff}_max_matches={max_matches}_max_motifs={max_motifs}.csv\",\n",
    ")\n",
    "mp_stats_table = pd.read_csv(file_path)\n",
    "\n",
    "# Extract unique subsequence lengths\n",
    "subsequence_lengths = mp_stats_table[\"m\"].unique()\n",
    "\n",
    "ts = data\n",
    "\n",
    "# Loop over each subsequence length\n",
    "for m in subsequence_lengths:\n",
    "    logging.info(f\"Motif length: {m}\")\n",
    "\n",
    "    # Filter motifs by current subsequence length\n",
    "    top_motifs = mp_stats_table[mp_stats_table[\"m\"] == m]\n",
    "    top_motifs = top_motifs.sort_values(by=\"Score Unified\", ascending=False).head(5)\n",
    "\n",
    "    # Loop over each top motif\n",
    "    for top_motif in top_motifs.to_dict(orient=\"records\"):\n",
    "        print(top_motif)\n",
    "\n",
    "        # Parse dimensions and indices\n",
    "        dimensions = sorted(map(int, top_motif[\"Features\"].split(\",\")))\n",
    "        indices = sorted(map(int, top_motif[\"Indices\"].strip(\"[]\").split(\",\")))\n",
    "\n",
    "        # Extract feature names\n",
    "        features = [df_data.columns[dimension] for dimension in dimensions]\n",
    "\n",
    "        # Add label feature to the list\n",
    "        ts_list = [df_data[feature].reset_index(drop=True) for feature in features]\n",
    "\n",
    "        # Generate motif name\n",
    "        motif_name = top_motif[\"ID\"]\n",
    "\n",
    "        # Create the figure and axes once, with 3 subplots for the submeters\n",
    "        fig, ax = plt.subplots(figsize=(10, 5), nrows=3, sharex=True)\n",
    "\n",
    "        # Loop over each index and plot the subsequences\n",
    "        for indice in indices:\n",
    "            subseq = labels.iloc[indice: indice + m]\n",
    "\n",
    "            # Plot subsequences for each submeter in the same 3 subplots\n",
    "            for i, feature in enumerate(labels.columns):\n",
    "                ax[i].plot(subseq[feature].values, alpha=0.7)  # Plot with transparency to differentiate subsequences\n",
    "                ax[i].set_ylabel(feature.replace(\"_\", \" \"))  # Format the y-axis label for better readability\n",
    "\n",
    "        # Set common x-axis labels and formatting\n",
    "        ax[-1].set_xlabel(\"Time Index\")  # Only set x-axis label on the bottom plot\n",
    "\n",
    "        # Adjust layout to prevent overlap\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Show the plot (or save it, depending on your requirements)\n",
    "        plt.show()\n",
    "\n",
    "        features = [feature.replace(\"_\", \" \") for feature in features]\n",
    "\n",
    "        # Plot and save the motif\n",
    "        plot_motif(ts_list, features, m, indices, motif_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
