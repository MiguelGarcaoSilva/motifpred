{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:39:09,585 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "2025-01-31 17:39:09,585 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "2025-01-31 17:39:09,585 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, VARIABLES, NORMALIZE_FLAGS, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS, NTOP_MOTIFS, MOTIF_SIZE\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=\"#Matches\", ascending=False).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3  , 1.282, 1.302, ..., 0.62 , 0.62 , 0.618],\n",
       "       [5.4  , 5.2  , 5.2  , ..., 2.6  , 2.6  , 2.6  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as \n",
    "data_df = pd.read_csv(DATASET_PATH, index_col=0).astype(float)\n",
    "data_df = data_df[VARIABLES]\n",
    "labels = pd.read_csv(DATA_DIR  / f\"labels.csv\", index_col=0).astype(float)\n",
    "data = data_df.values.T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_motif_in_ts(data, motif_indexes, MOTIF_SIZE):\n",
    "    data = np.asarray(data)  # Ensure data is a NumPy array\n",
    "    \n",
    "    if data.ndim == 1:  # Univariate case\n",
    "        data = data.reshape(1, -1)  # Reshape to (1, N) for uniformity\n",
    "    \n",
    "    num_variates = data.shape[0]\n",
    "    fig, axes = plt.subplots(num_variates, 2, figsize=(12, 5 * num_variates), gridspec_kw={'width_ratios': [1, 3]}, sharex=False)\n",
    "    \n",
    "    if num_variates == 1:\n",
    "        axes = [axes]  # Ensure axes is always iterable\n",
    "    \n",
    "    for i in range(num_variates):\n",
    "        # Plot the motif matches on the left\n",
    "        for idx in motif_indexes:\n",
    "            motif_pattern = data[i, idx:idx + MOTIF_SIZE]\n",
    "            axes[i][0].plot(motif_pattern, alpha=0.7)\n",
    "        axes[i][0].set_title(f\"Motif Pattern Variate {i+1}\")\n",
    "        axes[i][0].set_ylabel(\"Value\")\n",
    "        \n",
    "        # Plot the full time series on the right\n",
    "        axes[i][1].plot(data[i], label=f\"Variate {i+1}\")\n",
    "        for idx in motif_indexes:\n",
    "            axes[i][1].axvspan(idx, idx + MOTIF_SIZE, color='red', alpha=0.3, label=\"Motif\" if idx == motif_indexes[0] else \"\")\n",
    "        axes[i][1].legend()\n",
    "        axes[i][1].set_ylabel(\"Value\")\n",
    "        axes[i][1].set_title(f\"Variate {i+1}\")\n",
    "    \n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#plot_motif_in_ts(data, motif_indexes, MOTIF_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 30 with size 180 and 350 indexes \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_series shape: torch.Size([14634, 4320, 2])\n",
      "X_indices shape: torch.Size([14634, 26, 1])\n",
      "X_mask shape: torch.Size([14634, 4320])\n",
      "y shape: torch.Size([14634, 1])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80b101567794bef8ebbfce33b387c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 111, with best epoch being 66\n",
      "Early stopping at epoch 101, with best epoch being 3\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 17\n",
      "Early stopping at epoch 101, with best epoch being 9\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 16\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 2\n",
      "Early stopping at epoch 101, with best epoch being 14\n",
      "Early stopping at epoch 101, with best epoch being 14\n",
      "Early stopping at epoch 101, with best epoch being 14\n",
      "Early stopping at epoch 101, with best epoch being 3\n",
      "Early stopping at epoch 101, with best epoch being 4\n",
      "Early stopping at epoch 101, with best epoch being 12\n",
      "Early stopping at epoch 101, with best epoch being 6\n",
      "Early stopping at epoch 101, with best epoch being 52\n",
      "Early stopping at epoch 101, with best epoch being 4\n",
      "Early stopping at epoch 101, with best epoch being 28\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 12\n",
      "Early stopping at epoch 101, with best epoch being 25\n",
      "Early stopping at epoch 101, with best epoch being 25\n",
      "Early stopping at epoch 101, with best epoch being 9\n",
      "Early stopping at epoch 101, with best epoch being 17\n",
      "Early stopping at epoch 101, with best epoch being 6\n",
      "Early stopping at epoch 101, with best epoch being 2\n",
      "Early stopping at epoch 101, with best epoch being 1\n",
      "Early stopping at epoch 101, with best epoch being 58\n",
      "Early stopping at epoch 101, with best epoch being 28\n",
      "Early stopping at epoch 101, with best epoch being 25\n",
      "Early stopping at epoch 101, with best epoch being 34\n",
      "Early stopping at epoch 101, with best epoch being 27\n",
      "Early stopping at epoch 101, with best epoch being 10\n",
      "Early stopping at epoch 101, with best epoch being 63\n",
      "Early stopping at epoch 101, with best epoch being 2\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 0\n",
      "Early stopping at epoch 101, with best epoch being 2\n",
      "Early stopping at epoch 101, with best epoch being 6\n",
      "Early stopping at epoch 101, with best epoch being 27\n",
      "Early stopping at epoch 101, with best epoch being 27\n",
      "Early stopping at epoch 101, with best epoch being 22\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 5\n",
      "Early stopping at epoch 101, with best epoch being 7\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 11\n",
      "Early stopping at epoch 101, with best epoch being 7\n",
      "Early stopping at epoch 101, with best epoch being 7\n",
      "Early stopping at epoch 101, with best epoch being 7\n",
      "Early stopping at epoch 101, with best epoch being 11\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.ffnn_pytorch import FFNN\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "\n",
    "lookback_period = 60*24*3 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 60*24*2 #forward window size\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, lookback_period, step, forecast_period, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"FFNN\"\n",
    "    model_name = \"FFNNSeries_Masking\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3], \n",
    "            \"kwargs\": {\"log\": True} \n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[1, 2, 3, 4]] \n",
    "        },        \n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"hidden_sizes_list\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "    run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "        save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    )    \n",
    "    plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
