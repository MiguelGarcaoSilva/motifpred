{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 23:15:03,066 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "2025-02-07 23:15:03,067 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "2025-02-07 23:15:03,067 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/household\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/household\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/household\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import math\n",
    "import ast\n",
    "import logging\n",
    "from msig import Motif, NullModel\n",
    "from config import RESULTS_MOTIF_DIR, RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, VARIABLES, NORMALIZE_FLAGS, STUMPY_EXCL_ZONE_DENOM, TOP_K_MP, INCLUDE, NORMALIZE, SUBSQUENCES_LENGTHS, NTOP_MOTIFS, MOTIF_SIZE\n",
    "from config import LOOKBACK_PERIOD, STEP, FORECAST_PERIOD\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_stats_table = pd.read_csv(\n",
    "    RESULTS_DIR / f\"mp_stats_table_normalized_{NORMALIZE}_top_{TOP_K_MP}.csv\"\n",
    ")\n",
    "mp_stats_table = mp_stats_table[mp_stats_table[\"m\"] == MOTIF_SIZE]\n",
    "top_motifs = mp_stats_table.sort_values(by=[\"#Matches\", \"ID\"], ascending=[False, True]).head(NTOP_MOTIFS)\n",
    "top_motifs = top_motifs[[\"m\", \"Indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2944, 1.3644, 1.4672, ..., 0.7808, 0.7676, 0.634 ],\n",
       "       [0.    , 0.0776, 0.2188, ..., 0.1644, 0.1492, 0.0608]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data as \n",
    "data_df = pd.read_csv(DATASET_PATH, index_col=0).astype(float)\n",
    "data_df = data_df[VARIABLES]\n",
    "data = data_df.values.T\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259067/581482660.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_seq = (seq - np.mean(seq)) / np.std(seq)\n",
      "/tmp/ipykernel_259067/581482660.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_seq = (seq - np.mean(seq)) / np.std(seq)\n",
      "/tmp/ipykernel_259067/581482660.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_seq = (seq - np.mean(seq)) / np.std(seq)\n",
      "/tmp/ipykernel_259067/581482660.py:31: RuntimeWarning: invalid value encountered in divide\n",
      "  norm_seq = (seq - np.mean(seq)) / np.std(seq)\n"
     ]
    }
   ],
   "source": [
    "# Set global style for scientific plots\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",  # Use a serif font for better readability in papers\n",
    "    \"font.size\": 14,         # Increase font size for clarity\n",
    "    \"axes.titlesize\": 16,    # Larger title font size\n",
    "    \"axes.labelsize\": 14,    # Axis label size\n",
    "    \"xtick.labelsize\": 12,   # Tick size for x-axis\n",
    "    \"ytick.labelsize\": 12,   # Tick size for y-axis\n",
    "    \"legend.fontsize\": 12,   # Legend font size\n",
    "    \"figure.figsize\": (6, 4) # Standard paper figure size\n",
    "})\n",
    "\n",
    "num_vars = data.shape[0]  # Number of variables in the dataset\n",
    "\n",
    "for i, row in top_motifs.iterrows():\n",
    "    motif_indices = sorted(ast.literal_eval(row[\"Indices\"]))\n",
    "\n",
    "    # Create subplots for each variable\n",
    "    fig, axs = plt.subplots(num_vars, 2, figsize=(8, 3 * num_vars), dpi=300, gridspec_kw={'width_ratios': [1, 2]},  constrained_layout=True)\n",
    "\n",
    "    if num_vars == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)  # Ensure it remains iterable for a single-variable case\n",
    "\n",
    "    for var_idx in range(num_vars):\n",
    "        motif_subsequences = []\n",
    "\n",
    "        # Extract motif sequences for the current variable\n",
    "        for indice in motif_indices:\n",
    "            seq = data[var_idx, indice:indice + MOTIF_SIZE]\n",
    "            if len(seq) == MOTIF_SIZE:  # Ensure valid motif length\n",
    "                norm_seq = (seq - np.mean(seq)) / np.std(seq)\n",
    "                motif_subsequences.append(norm_seq)\n",
    "\n",
    "        if not motif_subsequences:\n",
    "            print(f\"Skipping motif {i} for variable {var_idx} due to empty subsequences.\")\n",
    "            continue\n",
    "\n",
    "        motif_subsequences = np.array(motif_subsequences)\n",
    "\n",
    "        # Plot normalized motif subsequences\n",
    "        axs[var_idx, 0].plot(motif_subsequences.T, color=\"black\", alpha=0.3, linewidth=1)\n",
    "        axs[var_idx, 0].set_title(f\"Normalized Subsequences\", fontsize=16)\n",
    "        axs[var_idx, 0].set_xlabel(\"Time\", fontsize=14)\n",
    "        axs[var_idx, 0].grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        # Plot original time series with motif locations\n",
    "        axs[var_idx, 1].plot(data[var_idx, : ], color=\"black\", alpha=0.7, linewidth=1.5)\n",
    "        for indice in motif_indices:\n",
    "            axs[var_idx, 1].axvline(x=indice, color=\"red\", linestyle=\"--\", linewidth=1.2, alpha=0.5, \n",
    "                                    label=\"Motif Occurrence\" if indice == motif_indices[0] else \"\")\n",
    "        axs[var_idx, 1].set_title(f\" Time Series ({VARIABLES[var_idx]})\", fontsize=16)\n",
    "        axs[var_idx, 1].set_xlabel(\"Time\", fontsize=14)\n",
    "        axs[var_idx, 1].grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        # Add legend only once\n",
    "        if len(motif_indices) > 0:\n",
    "            axs[var_idx, 1].legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "    # Save as high-quality PNG or PDF\n",
    "    plt.savefig(IMAGES_DIR / f\"top_motif_{i}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(IMAGES_DIR / f\"top_motif_{i}.pdf\", bbox_inches=\"tight\")  # Optional PDF for papers\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>Indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>[8371, 9127, 4929, 31, 4614, 4351, 10979, 5233...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>[2184, 2487, 2335, 11263, 15144, 2591, 7106, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>[9085, 15374, 14247, 15158, 13875, 1810, 1175,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>[7193, 7535, 603, 3812, 10530, 587, 7936, 6504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>[6921, 6647, 6474, 7243, 6366, 13436, 6935, 70...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     m                                            Indices\n",
       "5   24  [8371, 9127, 4929, 31, 4614, 4351, 10979, 5233...\n",
       "17  24  [2184, 2487, 2335, 11263, 15144, 2591, 7106, 9...\n",
       "1   24  [9085, 15374, 14247, 15158, 13875, 1810, 1175,...\n",
       "7   24  [7193, 7535, 603, 3812, 10530, 587, 7936, 6504...\n",
       "6   24  [6921, 6647, 6474, 7243, 6366, 13436, 6935, 70..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 6 with size 24 and 359 indexes \n",
      "X_series shape: torch.Size([2977, 576, 2])\n",
      "X_indices shape: torch.Size([2977, 22, 1])\n",
      "X_mask shape: torch.Size([2977, 576])\n",
      "y shape: torch.Size([2977, 1])\n",
      "Best epoch: 106\n",
      "Test Loss: 1321.105224609375, Test MAE: 25.78338050842285, Test RMSE: 36.34701156616211\n",
      "Evaluating motif 18 with size 24 and 358 indexes \n",
      "X_series shape: torch.Size([2974, 576, 2])\n",
      "X_indices shape: torch.Size([2974, 20, 1])\n",
      "X_mask shape: torch.Size([2974, 576])\n",
      "y shape: torch.Size([2974, 1])\n",
      "Best epoch: 12\n",
      "Test Loss: 1223.294677734375, Test MAE: 25.875572204589844, Test RMSE: 34.97562789916992\n",
      "Evaluating motif 2 with size 24 and 298 indexes \n",
      "X_series shape: torch.Size([2987, 576, 2])\n",
      "X_indices shape: torch.Size([2987, 17, 1])\n",
      "X_mask shape: torch.Size([2987, 576])\n",
      "y shape: torch.Size([2987, 1])\n",
      "Best epoch: 38\n",
      "Test Loss: 1124.681640625, Test MAE: 28.6058406829834, Test RMSE: 33.53627395629883\n",
      "Evaluating motif 8 with size 24 and 279 indexes \n",
      "X_series shape: torch.Size([2984, 576, 2])\n",
      "X_indices shape: torch.Size([2984, 22, 1])\n",
      "X_mask shape: torch.Size([2984, 576])\n",
      "y shape: torch.Size([2984, 1])\n",
      "Best epoch: 34\n",
      "Test Loss: 4397.87158203125, Test MAE: 48.174644470214844, Test RMSE: 66.31645202636719\n",
      "Evaluating motif 7 with size 24 and 268 indexes \n",
      "X_series shape: torch.Size([2887, 576, 2])\n",
      "X_indices shape: torch.Size([2887, 25, 1])\n",
      "X_mask shape: torch.Size([2887, 576])\n",
      "y shape: torch.Size([2887, 1])\n",
      "Best epoch: 0\n",
      "Test Loss: 1365.1163330078125, Test MAE: 32.46746063232422, Test RMSE: 36.947479248046875\n",
      "Aggregated Results Across Top 5 Motifs:\n",
      "Mean Test Loss: 1886.4138916015625 ± 1258.467947813401\n",
      "Mean Test MAE: 32.18137969970703 ± 8.358809022783516\n",
      "Mean Test RMSE: 41.624568939208984 ± 12.401982122865288\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.tcn_pytorch import TCN\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"TCN\"\n",
    "    model_name = \"TCNSeries\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"kernel_size\": { # ensure receptive field is at least as large as sequence length (lookback_period)\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[3, 5 ,7]]\n",
    "        },\n",
    "        \"receptive_field\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[250]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"kernel_size\", \"num_channels_list\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_series\": X_series}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 5 with size 24 and 359 indexes \n",
      "X_series shape: torch.Size([2977, 576, 2])\n",
      "X_indices shape: torch.Size([2977, 22, 1])\n",
      "X_mask shape: torch.Size([2977, 576])\n",
      "y shape: torch.Size([2977, 1])\n",
      "Best epoch: 14\n",
      "Test Loss: 1424.3375244140625, Test MAE: 25.935346603393555, Test RMSE: 37.740394592285156\n",
      "Evaluating motif 17 with size 24 and 358 indexes \n",
      "X_series shape: torch.Size([2974, 576, 2])\n",
      "X_indices shape: torch.Size([2974, 20, 1])\n",
      "X_mask shape: torch.Size([2974, 576])\n",
      "y shape: torch.Size([2974, 1])\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/mgsilva/motifpred/results/household/TCNSeries_Masking_100_trials_500_epochs_motif_18/study.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m X \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_series\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_series, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: X_mask}\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_results_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudy.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse \u001b[38;5;241m=\u001b[39m get_best_model_results_traindevtest(study)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/joblib/numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/mgsilva/motifpred/results/household/TCNSeries_Masking_100_trials_500_epochs_motif_18/study.pkl'"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.tcn_pytorch import TCN\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"TCN\"\n",
    "    model_name = \"TCNSeries_Masking\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"kernel_size\": { # ensure receptive field is at least as large as sequence length (lookback_period)\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[3, 5 ,7]]\n",
    "        },\n",
    "        \"receptive_field\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[250]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"kernel_size\", \"num_channels_list\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating motif 6 with size 24 and 359 indexes \n",
      "X_series shape: torch.Size([2977, 576, 2])\n",
      "X_indices shape: torch.Size([2977, 22, 1])\n",
      "X_mask shape: torch.Size([2977, 576])\n",
      "y shape: torch.Size([2977, 1])\n",
      "Best epoch: 95\n",
      "Test Loss: 1511.0205078125, Test MAE: 28.169261932373047, Test RMSE: 38.871849060058594\n",
      "Evaluating motif 18 with size 24 and 358 indexes \n",
      "X_series shape: torch.Size([2974, 576, 2])\n",
      "X_indices shape: torch.Size([2974, 20, 1])\n",
      "X_mask shape: torch.Size([2974, 576])\n",
      "y shape: torch.Size([2974, 1])\n",
      "Best epoch: 4\n",
      "Test Loss: 1360.932373046875, Test MAE: 26.92951011657715, Test RMSE: 36.89081573486328\n",
      "Evaluating motif 2 with size 24 and 298 indexes \n",
      "X_series shape: torch.Size([2987, 576, 2])\n",
      "X_indices shape: torch.Size([2987, 17, 1])\n",
      "X_mask shape: torch.Size([2987, 576])\n",
      "y shape: torch.Size([2987, 1])\n",
      "Best epoch: 129\n",
      "Test Loss: 1279.9879150390625, Test MAE: 29.307514190673828, Test RMSE: 35.776920318603516\n",
      "Evaluating motif 8 with size 24 and 279 indexes \n",
      "X_series shape: torch.Size([2984, 576, 2])\n",
      "X_indices shape: torch.Size([2984, 22, 1])\n",
      "X_mask shape: torch.Size([2984, 576])\n",
      "y shape: torch.Size([2984, 1])\n",
      "Best epoch: 2\n",
      "Test Loss: 3861.05810546875, Test MAE: 46.025272369384766, Test RMSE: 62.137413024902344\n",
      "Evaluating motif 7 with size 24 and 268 indexes \n",
      "X_series shape: torch.Size([2887, 576, 2])\n",
      "X_indices shape: torch.Size([2887, 25, 1])\n",
      "X_mask shape: torch.Size([2887, 576])\n",
      "y shape: torch.Size([2887, 1])\n",
      "Best epoch: 0\n",
      "Test Loss: 1333.9263916015625, Test MAE: 28.7901668548584, Test RMSE: 36.52295684814453\n",
      "Aggregated Results Across Top 5 Motifs:\n",
      "Mean Test Loss: 1869.38505859375 ± 998.7808355422422\n",
      "Mean Test MAE: 31.844345092773438 ± 7.134760728131552\n",
      "Mean Test RMSE: 42.039990997314455 ± 10.10070513877768\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "from utils.train_pipeline import run_optuna_study\n",
    "from utils.utils import get_best_model_results_traindevtest, plot_best_model_results_traindevtest\n",
    "from models.tcn_pytorch import TCN\n",
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config_train_val_test\n",
    "\n",
    "\n",
    "test_losses_list = []\n",
    "test_mae_list = []\n",
    "test_rmse_list = []\n",
    "\n",
    "# Loop through each of the top 10 motifs\n",
    "for i, top_motif in top_motifs.iterrows():\n",
    "    motif_indexes = sorted(ast.literal_eval(top_motif[\"Indices\"]))\n",
    "    \n",
    "    print(f\"Evaluating motif {i+1} with size {MOTIF_SIZE} and {len(motif_indexes)} indexes \")\n",
    "    \n",
    "    # Create dataset for the current motif\n",
    "    X_series, X_indices, X_mask, y = create_dataset(data, LOOKBACK_PERIOD, STEP, FORECAST_PERIOD, motif_indexes, MOTIF_SIZE)\n",
    "\n",
    "    # X_series, X2, and y are now PyTorch tensors\n",
    "    print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, LOOKBACK_PERIOD, num_features)\n",
    "    print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window, 1)\n",
    "    print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "    print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n",
    "    \n",
    "    # Define the model and run the Optuna study\n",
    "    n_trials = 100\n",
    "    num_epochs = 500\n",
    "    model_type = \"TCN\"\n",
    "    model_name = \"TCNIndices\"\n",
    "\n",
    "    suggestion_dict = {\n",
    "        \"learning_rate\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [1e-5, 1e-3],\n",
    "            \"kwargs\": {\"log\": True}\n",
    "        },\n",
    "        \"kernel_size\": { # ensure receptive field is at least as large as sequence length (lookback_period)\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[3, 5 ,7]]\n",
    "        },\n",
    "        \"receptive_field\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[25]]\n",
    "        },\n",
    "        \"dropout\": {\n",
    "            \"type\": \"float\",\n",
    "            \"args\": [0.0, 0.5]\n",
    "        },\n",
    "        \"batch_size\": {\n",
    "            \"type\": \"categorical\",\n",
    "            \"args\": [[16, 32, 64, 128]]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model_params_keys = [\"kernel_size\", \"num_channels_list\", \"dropout\"]\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}\")\n",
    "    os.makedirs(model_results_dir, exist_ok=True)  \n",
    "\n",
    "    X = {\"X_indices\": X_indices}\n",
    "    #run_optuna_study(pipeline.run_train_val_test, eval(model_type), model_type, suggestion_dict, model_params_keys, seed, X, y, NORMALIZE_FLAGS, model_results_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    train_losses, val_losses, best_epoch, test_loss, test_mae, test_rmse = get_best_model_results_traindevtest(study)\n",
    "\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}, Test RMSE: {test_rmse}\")\n",
    "\n",
    "    test_losses_list.append(test_loss)\n",
    "    test_mae_list.append(test_mae)\n",
    "    test_rmse_list.append(test_rmse)\n",
    "    \n",
    "    # Plot predictions vs true values\n",
    "    #epochs_train_losses, epochs_val_losses, val_losses, test_losses, test_mae, test_rmse, all_predictions, all_true_values = get_preds_best_config_train_val_test(study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=NORMALIZE_FLAGS)\n",
    "    #plot_best_model_results_traindevtest( study.trials_dataframe(),\n",
    "    #    save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_best_results.png\")\n",
    "    #)    \n",
    "    #plot_preds_vs_truevalues(np.ravel(all_true_values), np.ravel(all_predictions), fold=0, save_path=os.path.join(IMAGES_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_motif_{i+1}_fold_{0}_predictions.png\"))\n",
    "\n",
    "\n",
    "# Convert lists to numpy arrays for easier calculations\n",
    "test_losses_array = np.array(test_losses_list)\n",
    "test_mae_array = np.array(test_mae_list)\n",
    "test_rmse_array = np.array(test_rmse_list)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_test_loss = np.mean(test_losses_array)\n",
    "std_test_loss = np.std(test_losses_array)\n",
    "\n",
    "mean_test_mae = np.mean(test_mae_array)\n",
    "std_test_mae = np.std(test_mae_array)\n",
    "\n",
    "mean_test_rmse = np.mean(test_rmse_array)\n",
    "std_test_rmse = np.std(test_rmse_array)\n",
    "\n",
    "# Print aggregated results\n",
    "print(f\"Aggregated Results Across Top 5 Motifs:\")\n",
    "print(f\"Mean Test Loss: {mean_test_loss} ± {std_test_loss}\")\n",
    "print(f\"Mean Test MAE: {mean_test_mae} ± {std_test_mae}\")\n",
    "print(f\"Mean Test RMSE: {mean_test_rmse} ± {std_test_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
