{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "results_dir = '../results/variables=[0,2]'\n",
    "images_dir = '../images/variables=[0,2]'\n",
    "data_dir = '../data/syntheticdata/variables=[0,2]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The StatsForecast module could not be imported. To enable support for the StatsForecastAutoARIMA, StatsForecastAutoETS and Croston models, please consider installing it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from utils.train_pipeline import ModelTrainingPipeline\n",
    "\n",
    "seed = 1729\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "device = torch.device(\"cpu\")\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "#torch.cuda.set_per_process_memory_fraction(0.02, device=torch.device('cuda:0'))\n",
    "\n",
    "ModelTrainingPipeline.set_seed(seed)\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     5    12 ... 99948 99965 99984]\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "n = 100000 #number of data points\n",
    "k = 3 #number of variables\n",
    "p = 5 # pattern length\n",
    "variable_indexes = np.arange(k)\n",
    "variables_pattern = [0,2]\n",
    "\n",
    "dataset_path = os.path.join(data_dir, \"n={}_k={}_p={}_min_step={}_max_step={}_variables={}.csv\".format(n, k, p, 5, 45, variables_pattern))\n",
    "motif_indexes_path = os.path.join(data_dir, \"motif_indexes_n={}_k={}_p={}_min_step={}_max_step={}.csv\".format(n, k, p, 5, 45))\n",
    "data = np.genfromtxt(dataset_path, delimiter=\",\").astype(int).reshape((k, n))\n",
    "motif_indexes = np.genfromtxt(motif_indexes_path, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [    0     1     2 ... 15997 15998 15999] TEST: [16000 16001 16002 ... 19997 19998 19999]\n",
      "TRAIN: [20000 20001 20002 ... 35997 35998 35999] TEST: [36000 36001 36002 ... 39997 39998 39999]\n",
      "TRAIN: [40000 40001 40002 ... 55997 55998 55999] TEST: [56000 56001 56002 ... 59997 59998 59999]\n",
      "TRAIN: [60000 60001 60002 ... 75997 75998 75999] TEST: [76000 76001 76002 ... 79997 79998 79999]\n",
      "TRAIN: [80000 80001 80002 ... 95997 95998 95999] TEST: [96000 96001 96002 ... 99997 99998 99999]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.timeseries_split import BlockingTimeSeriesSplit\n",
    "\n",
    "#create index  \n",
    "indexes = np.arange(len(data[0]))\n",
    "\n",
    "#split data\n",
    "tscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(indexes)):\n",
    "    # Plot train and test indices\n",
    "    ax.plot(train_index, np.zeros_like(train_index) + i, 'o', color='lightblue')\n",
    "    ax.plot(test_index, np.zeros_like(test_index) + i, 'o', color='red')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "\n",
    "ax.set_yticks(np.arange(5), [\"Fold {}\".format(i) for i in range(1, 6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: torch.Size([19977, 100, 3])\n",
      "X2 shape: torch.Size([19977, 8])\n",
      "y shape: torch.Size([19977, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#x1: past window, x2: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X1, X2, y = create_dataset(data, variable_indexes, lookback_period, step, forecast_period, motif_indexes)\n",
    "\n",
    "# X1, X2, and y are now PyTorch tensors\n",
    "print(\"X1 shape:\", X1.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X2 shape:\", X2.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 15:34:45,037] A new study created in memory with name: no-name-1ff29acb-b92c-44b8-9a7c-a7fe8cfc1517\n",
      "[W 2024-12-07 15:35:36,220] Trial 0 failed with parameters: {'learning_rate': 2.6565450821928437e-05, 'kernel_size': 7, 'num_blocks': 5, 'dropout': 0.12704166510234777, 'batch_size': 16, 'block_channels_0': 256, 'block_channels_1': 64, 'block_channels_2': 64, 'block_channels_3': 128, 'block_channels_4': 128} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 58, in objective\n",
      "    trial_val_loss, _, _ = objective_func(trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparameters, model_params_keys)  # Pass hyperparameters\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 365, in run_cross_val\n",
      "    fold_val_loss, model, best_epoch, train_losses, validation_losses = self.train_model(\n",
      "                                                                        ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/mgsilva/motifpred/code/utils/train_pipeline.py\", line 246, in train_model\n",
      "    loss.backward()\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-07 15:35:36,221] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m early_stopper \u001b[38;5;241m=\u001b[39m EarlyStopper(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, min_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     44\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m ModelTrainingPipeline(device\u001b[38;5;241m=\u001b[39mdevice, early_stopper\u001b[38;5;241m=\u001b[39mearly_stopper)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mrun_optuna_study\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cross_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTCNModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuggestion_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m study \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(result_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstudy.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     50\u001b[0m print_study_results(study)\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:63\u001b[0m, in \u001b[0;36mrun_optuna_study\u001b[0;34m(objective_func, model_class, model_type, suggestion_dict, model_params_keys, seed, X1, X2, y, results_folder, n_trials, num_epochs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Let Optuna manage trials and pass them to the objective function\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(study, file_name)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Save and log the study results\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:58\u001b[0m, in \u001b[0;36mrun_optuna_study.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     55\u001b[0m     hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m block_channels\n\u001b[1;32m     57\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()  \u001b[38;5;66;03m# Define the criterion here\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m trial_val_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_params_keys\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass hyperparameters\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial_val_loss\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:365\u001b[0m, in \u001b[0;36mModelTrainingPipeline.run_cross_val\u001b[0;34m(self, trial, seed, results_folder, model_class, model_type, X1, y, X2, criterion, num_epochs, hyperparams, model_params_keys)\u001b[0m\n\u001b[1;32m    361\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class(input_channels\u001b[38;5;241m=\u001b[39mX1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_hyperparams, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, output_activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, causal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;66;03m# Train the model using the existing train_model method\u001b[39;00m\n\u001b[0;32m--> 365\u001b[0m fold_val_loss, model, best_epoch, train_losses, validation_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdual_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# Test evaluation for other models\u001b[39;00m\n\u001b[1;32m    371\u001b[0m fold_test_loss, test_fold_predictions, test_fold_true_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_test_set(\n\u001b[1;32m    372\u001b[0m     model, test_loader, criterion, dual_input\u001b[38;5;241m=\u001b[39m(X2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    373\u001b[0m )\n",
      "File \u001b[0;32m~/motifpred/code/utils/train_pipeline.py:246\u001b[0m, in \u001b[0;36mModelTrainingPipeline.train_model\u001b[0;34m(self, model, criterion, optimizer, train_loader, val_loader, num_epochs, dual_input)\u001b[0m\n\u001b[1;32m    244\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(predictions, batch_y)\n\u001b[1;32m    245\u001b[0m     epoch_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m--> 246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    249\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m epoch_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.tcn_pytorch import TCNModel\n",
    "from utils.train_pipeline import EarlyStopper, ModelTrainingPipeline, run_optuna_study\n",
    "from utils.utils import print_study_results, plot_best_model_results\n",
    "\n",
    "\n",
    "\n",
    "n_trials = 2\n",
    "num_epochs = 50\n",
    "model_type = \"TCN\"\n",
    "model_name = \"TCNModel\"\n",
    "\n",
    "suggestion_dict = {\n",
    "    \"learning_rate\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [1e-5, 1e-3],\n",
    "        \"kwargs\": {\"log\": True}\n",
    "    },\n",
    "    \"kernel_size\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[3, 5, 7]]\n",
    "    },\n",
    "    \"num_blocks\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[3, 5, 7]]\n",
    "    },\n",
    "    \"dropout\": {\n",
    "        \"type\": \"float\",\n",
    "        \"args\": [0.0, 0.5]\n",
    "    },\n",
    "    \"batch_size\": {\n",
    "        \"type\": \"categorical\",\n",
    "        \"args\": [[16, 32, 64, 128]]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_params_keys = [\"kernel_size\", \"num_channels\", \"dropout\"]\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "run_optuna_study(pipeline.run_cross_val, TCNModel, model_type, suggestion_dict, model_params_keys, seed, X1, None, y, result_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "print_study_results(study)\n",
    "plot_best_model_results(\n",
    "    study.trials_dataframe(),\n",
    "    save_path=os.path.join(images_dir, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs_losses.png\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "\n",
    "epochs_train_losses, epochs_val_losses, all_predictions, all_true_values = get_preds_best_config(study, pipeline, CNNX1, model_type, model_params_keys, num_epochs =num_epochs, seed=seed, X1=X1, X2=None, y=y)\n",
    "\n",
    "# Plot the train and validation losses for each fold\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharey=True)\n",
    "for i in range(5):\n",
    "    axes[i].plot(epochs_train_losses[i], label=\"Train Loss\")\n",
    "    axes[i].plot(epochs_val_losses[i], label=\"Validation Loss\")\n",
    "    axes[i].set_title(f\"Fold {i + 1}\")\n",
    "    axes[i].set_xlabel(\"Epoch\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Loss\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot the predictions vs true values for each fold\n",
    "for fold in range(5):\n",
    "    plot_preds_vs_truevalues(np.ravel(all_true_values[fold]), np.ravel(all_predictions[fold]), fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
