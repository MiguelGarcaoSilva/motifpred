{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgsilva/miniconda3/envs/torch_motifpredenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "seed = 1729\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_dataset(data, variable_indexes, lookback_period, step, forecast_period, motif_indexes):\n",
    "    X1, X2, y = [], [], []  # X1: data, X2: indexes of the motifs, y: distance to the next motif\n",
    "    \n",
    "    for idx in range(len(data[0]) - lookback_period - 1):\n",
    "        if idx % step != 0:\n",
    "            continue\n",
    "\n",
    "        window_end_idx = idx + lookback_period\n",
    "        forecast_period_end = window_end_idx + forecast_period\n",
    "\n",
    "        # If there are no more matches after the window, break\n",
    "        if not any([window_end_idx < motif_idx for motif_idx in motif_indexes]):\n",
    "            break\n",
    "\n",
    "        # Motif indexes in window, relative to the start of the window\n",
    "        motif_indexes_in_window = [motif_idx - idx for motif_idx in motif_indexes if idx <= motif_idx <= window_end_idx]\n",
    "        motif_indexes_in_forecast_period = [motif_idx for motif_idx in motif_indexes if window_end_idx < motif_idx <= forecast_period_end]\n",
    "\n",
    "        if motif_indexes_in_forecast_period:\n",
    "            next_match_in_forecast_period = motif_indexes_in_forecast_period[0]\n",
    "        else:\n",
    "            next_match_in_forecast_period = -1  # No match in the forecast period but exists in the future\n",
    "\n",
    "        # Get the data window and transpose to (lookback_period, num_features)\n",
    "        data_window = data[variable_indexes, idx:window_end_idx].T\n",
    "\n",
    "        # Calculate `y`\n",
    "        data_y = -1\n",
    "        if next_match_in_forecast_period != -1:\n",
    "            # Index of the next match relative to the end of the window\n",
    "            data_y = next_match_in_forecast_period - window_end_idx\n",
    "        \n",
    "        # Append to lists\n",
    "        X1.append(torch.tensor(data_window, dtype=torch.float32))  # Now with shape (lookback_period, num_features)\n",
    "        X2.append(torch.tensor(motif_indexes_in_window, dtype=torch.long)) \n",
    "        y.append(data_y) \n",
    "\n",
    "    # Pad X2 sequences to have the same length\n",
    "    X2_padded = pad_sequence(X2, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    # Convert lists to torch tensors\n",
    "    X1 = torch.stack(X1)  # Final shape: (num_samples, lookback_period, num_features)\n",
    "    y = torch.tensor(y, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return X1, X2_padded, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load data\n",
    "n = 100000\n",
    "k = 3\n",
    "variable_indexes = range(k)\n",
    "\n",
    "data_scenario3 = np.genfromtxt(\"../data/syntheticdata/scenario3_n={}_k={}_min_step={}_max_step={}.csv\".format(n, k, 5, 45), delimiter=\",\").astype(int).reshape((k, n))\n",
    "\n",
    "motif_indexes_scenario3 = np.genfromtxt(\"../data/syntheticdata/motif_indexes_scenario3_n={}_k={}_min_step={}_max_step={}.csv\".format(n, k, 5, 45), delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes_scenario3) #TODO: check this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from timeseries_split import BlockingTimeSeriesSplit\n",
    "\n",
    "#create index  \n",
    "indexes = np.arange(len(data_scenario3[0]))\n",
    "\n",
    "#split data\n",
    "tscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(indexes)):\n",
    "    # Plot train and test indices\n",
    "    ax.plot(train_index, np.zeros_like(train_index) + i, 'o', color='lightblue')\n",
    "    ax.plot(test_index, np.zeros_like(test_index) + i, 'o', color='red')\n",
    "\n",
    "ax.set_yticks(np.arange(5), [\"Fold {}\".format(i) for i in range(1, 6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: torch.Size([19977, 100, 3])\n",
      "X2 shape: torch.Size([19977, 8])\n",
      "y shape: torch.Size([19977, 1])\n"
     ]
    }
   ],
   "source": [
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#x1: past window + masking, x2: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X1, X2, y = create_dataset(data_scenario3, variable_indexes, lookback_period, step, forecast_period, motif_indexes_scenario3)\n",
    "\n",
    "# X1, X2, and y are now PyTorch tensors\n",
    "print(\"X1 shape:\", X1.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X2 shape:\", X2.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "from typing import Tuple, List\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def evaluate_metrics(predictions: torch.Tensor, targets: torch.Tensor) -> Tuple[float, float]:\n",
    "    mae = torch.mean(torch.abs(predictions - targets)).item()\n",
    "    rmse = torch.sqrt(torch.mean((predictions - targets) ** 2)).item()\n",
    "    return mae, rmse\n",
    "\n",
    "def train_validate_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=500) -> float:\n",
    "    early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_X1, batch_y in train_loader:\n",
    "            batch_X1, batch_y = batch_X1.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(model(batch_X1), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_X1, batch_y in val_loader:\n",
    "                batch_X1, batch_y = batch_X1.to(device), batch_y.to(device)\n",
    "                val_loss += criterion(model(batch_X1), batch_y).item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        # Early stopping\n",
    "        if epoch >= 100:\n",
    "            if early_stopper.early_stop(avg_val_loss):\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                break\n",
    "    return early_stopper.min_validation_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-07 17:32:44,345] A new study created in memory with name: no-name-ceb78800-4661-4a90-bdb4-ba905d7e768f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 144\n",
      "Early stopping at epoch 126\n",
      "Early stopping at epoch 289\n",
      "Early stopping at epoch 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-07 17:37:27,117] Trial 0 finished with value: 104.01853485107422 and parameters: {'learning_rate': 2.6565450821928437e-05, 'hidden_size': 256, 'num_layers': 3, 'batch_size': 64}. Best is trial 0 with value: 104.01853485107422.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 283\n",
      "Early stopping at epoch 125\n",
      "Early stopping at epoch 129\n",
      "Early stopping at epoch 208\n",
      "Early stopping at epoch 118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-07 17:40:32,265] Trial 1 finished with value: 59.19865188598633 and parameters: {'learning_rate': 0.00010461160323948997, 'hidden_size': 128, 'num_layers': 2, 'batch_size': 16}. Best is trial 1 with value: 59.19865188598633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 130\n",
      "Early stopping at epoch 272\n",
      "Early stopping at epoch 245\n",
      "Early stopping at epoch 272\n",
      "Early stopping at epoch 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-07 17:41:39,287] Trial 2 finished with value: 77.85519409179688 and parameters: {'learning_rate': 8.234629491061175e-05, 'hidden_size': 128, 'num_layers': 1, 'batch_size': 64}. Best is trial 1 with value: 59.19865188598633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 269\n",
      "Early stopping at epoch 451\n",
      "Early stopping at epoch 448\n"
     ]
    }
   ],
   "source": [
    "from models.lstm_pytorch import LSTMX1Input\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size = X1.shape[2]  # Number of features in X1\n",
    "output_size = 1   \n",
    "\n",
    "def objective_lstm_x1(trial) -> float:\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [16, 32, 64, 128, 256])\n",
    "    num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "\n",
    "    fold_results, test_mae_per_fold, test_rmse_per_fold = [], [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(BlockingTimeSeriesSplit(n_splits=5).split(X1)):\n",
    "        X1_train, X1_test = X1[train_idx], X1[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        val_index = int(0.8 * X1_train.shape[0])\n",
    "\n",
    "        X1_train, X1_val = X1_train[:val_index], X1_train[val_index:]\n",
    "        y_train, y_val = y_train[:val_index], y_train[val_index:]\n",
    "\n",
    "        # Fit the MinMaxScaler on the training data only and transform train, val, and test data\n",
    "        scaler_X1 = MinMaxScaler(feature_range=(0, 1))\n",
    "        X1_train = torch.tensor(scaler_X1.fit_transform(X1_train.view(-1, X1_train.shape[-1])), dtype=torch.float32).view(X1_train.shape)\n",
    "        X1_val = torch.tensor(scaler_X1.transform(X1_val.view(-1, X1_val.shape[-1])), dtype=torch.float32).view(X1_val.shape)\n",
    "        X1_test = torch.tensor(scaler_X1.transform(X1_test.view(-1, X1_test.shape[-1])), dtype=torch.float32).view(X1_test.shape)\n",
    "\n",
    "        train_loader = DataLoader(TensorDataset(X1_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(TensorDataset(X1_val, y_val), batch_size=len(X1_val), shuffle=False)\n",
    "        test_loader = DataLoader(TensorDataset(X1_test, y_test), batch_size=len(X1_test), shuffle=False)\n",
    "\n",
    "        model = LSTMX1Input(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size).to(device)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        fold_val_loss = train_validate_model(model, criterion, optimizer, train_loader, val_loader)\n",
    "        fold_results.append(fold_val_loss)\n",
    "\n",
    "        # Test evaluation\n",
    "        all_predictions, all_true_values = [], []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_X1, batch_y in test_loader:\n",
    "                batch_X1, batch_y = batch_X1.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_X1).squeeze()\n",
    "                all_predictions.append(outputs)\n",
    "                all_true_values.append(batch_y)\n",
    "\n",
    "        all_predictions = torch.cat(all_predictions)\n",
    "        all_true_values = torch.cat(all_true_values)\n",
    "        mae, rmse = evaluate_metrics(all_predictions, all_true_values)\n",
    "        test_mae_per_fold.append(mae)\n",
    "        test_rmse_per_fold.append(rmse)\n",
    "\n",
    "    mean_val_loss = np.mean(fold_results)\n",
    "    mean_test_mae, std_test_mae = np.mean(test_mae_per_fold), np.std(test_mae_per_fold)\n",
    "    mean_test_rmse, std_test_rmse = np.mean(test_rmse_per_fold), np.std(test_rmse_per_fold)\n",
    "\n",
    "    with open(\"results_LSTMX1Input.csv\", mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            \"trial_number\", \"learning_rate\", \"batch_size\", \"hidden_size\", \"num_layers\",\n",
    "            \"fold_1_val_loss\", \"fold_2_val_loss\", \"fold_3_val_loss\", \"fold_4_val_loss\", \"fold_5_val_loss\",\n",
    "            \"avg_validation_loss\", \"test_mae_mean\", \"test_mae_std\", \"test_rmse_mean\", \"test_rmse_std\"\n",
    "        ])\n",
    "        writer.writerow([\n",
    "            trial.number, learning_rate, batch_size, hidden_size, num_layers,\n",
    "            *fold_results, mean_val_loss, mean_test_mae, std_test_mae, mean_test_rmse, std_test_rmse\n",
    "        ])\n",
    "        file.flush()\n",
    "\n",
    "    return mean_val_loss\n",
    "\n",
    "\n",
    "def run_optuna_study(objective_func, file_name: str, n_trials: int = 100):\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "    study.optimize(objective_func, n_trials=n_trials)\n",
    "    joblib.dump(study, file_name)\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best cross-validated validation loss:\", study.best_value)\n",
    "\n",
    "\n",
    "# Run the study for LSTM with X1 input\n",
    "run_optuna_study(objective_lstm_x1, \"synthetic_data_LSTMX1Input.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1_X2BeforeLSTM\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "input_size = X1.shape[2]  # Number of features in X1\n",
    "output_size = 1           \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Open the CSV file to log Optuna results\n",
    "with open(\"optuna_tuning_results.csv\", mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write the header including columns for each fold's validation loss, average validation loss, test MAE, test RMSE, and their standard deviations\n",
    "    writer.writerow([\"trial_number\", \"learning_rate\", \"batch_size\", \"hidden_size\", \"num_layers\",\n",
    "                     \"fold_1_val_loss\", \"fold_2_val_loss\", \"fold_3_val_loss\", \"fold_4_val_loss\", \"fold_5_val_loss\",\n",
    "                     \"avg_validation_loss\", \"test_mae_mean\", \"test_mae_std\", \"test_rmse_mean\", \"test_rmse_std\"])\n",
    "\n",
    "    # Define the Optuna objective function\n",
    "    def objective(trial):\n",
    "        # Define hyperparameters to tune\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "        hidden_size = trial.suggest_categorical(\"hidden_size\", [16, 32, 64, 128, 256])\n",
    "        num_layers = trial.suggest_categorical(\"num_layers\", [1, 2, 3])\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "\n",
    "        # Placeholder for fold validation losses\n",
    "        fold_results = []\n",
    "        \n",
    "        # Placeholders for test MAE and RMSE for each fold\n",
    "        test_mae_per_fold, test_rmse_per_fold = [], []\n",
    "\n",
    "        # Cross-validation with BlockingTimeSeriesSplit\n",
    "        for fold, (train_idx, test_idx) in enumerate(BlockingTimeSeriesSplit(n_splits=5).split(X1)):\n",
    "            # Split train and test sets for each fold\n",
    "            X1_train, X1_test = X1[train_idx], X1[test_idx]\n",
    "            X2_train, X2_test = X2[train_idx], X2[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            # Split train into train and validation (80-20 split)\n",
    "            val_index = int(0.8 * X1_train.shape[0])\n",
    "            X1_train, X1_val = X1_train[:val_index], X1_train[val_index:]\n",
    "            X2_train, X2_val = X2_train[:val_index], X2_train[val_index:]\n",
    "            y_train, y_val = y_train[:val_index], y_train[val_index:]\n",
    "\n",
    "            # Fit the MinMaxScaler on the training data only and transform train, val, and test data\n",
    "            scaler_X1 = MinMaxScaler(feature_range=(0, 1))\n",
    "            X1_train = torch.tensor(scaler_X1.fit_transform(X1_train.view(-1, X1_train.shape[-1])), dtype=torch.float32).view(X1_train.shape)\n",
    "            X1_val = torch.tensor(scaler_X1.transform(X1_val.view(-1, X1_val.shape[-1])), dtype=torch.float32).view(X1_val.shape)\n",
    "            X1_test = torch.tensor(scaler_X1.transform(X1_test.view(-1, X1_test.shape[-1])), dtype=torch.float32).view(X1_test.shape)\n",
    "\n",
    "            # Create DataLoader for train, validation, and test sets\n",
    "            train_loader = DataLoader(TensorDataset(X1_train, X2_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(TensorDataset(X1_val, X2_val, y_val), batch_size= len(X1_val), shuffle=False)  # Use the whole validation set at once\n",
    "            test_loader = DataLoader(TensorDataset(X1_test, X2_test, y_test), batch_size= len(X1_test), shuffle=False) # Use the whole test set at once\n",
    "\n",
    "            # Initialize model, loss function, and optimizer\n",
    "            model = LSTMX1_X2BeforeLSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size).to(device)\n",
    "            early_stopper = EarlyStopper(patience=10, min_delta=1e-5)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            # Training loop for the fold\n",
    "            num_epochs = 500\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                for batch_X1, batch_X2, batch_y in train_loader:\n",
    "                    batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = model(batch_X1, batch_X2)\n",
    "                    loss = criterion(outputs, batch_y)\n",
    "\n",
    "                    # Backward pass and optimization\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Validation phase - evaluate on validation set after each epoch\n",
    "                model.eval()\n",
    "                val_loss = 0\n",
    "                with torch.no_grad():\n",
    "                    for batch_X1, batch_X2, batch_y in val_loader:\n",
    "                        batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "                        outputs = model(batch_X1, batch_X2)\n",
    "                        loss = criterion(outputs, batch_y)\n",
    "                        val_loss += loss.item()\n",
    "                avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "                # Early stopping check using EarlyStopper\n",
    "                if epoch >= 100:\n",
    "                    if early_stopper.early_stop(avg_val_loss):\n",
    "                        print(f\"Early stopping at epoch {epoch}\")\n",
    "                        break\n",
    "\n",
    "            # Append the best validation loss encountered during this fold\n",
    "            fold_results.append(early_stopper.min_validation_loss)\n",
    "\n",
    "        \n",
    "            # Evaluate on test set for the current fold\n",
    "            all_predictions, all_true_values  = [], []\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for batch_X1, batch_X2, batch_y in test_loader:\n",
    "                    batch_X1, batch_X2, batch_y = batch_X1.to(device), batch_X2.to(device), batch_y.to(device)\n",
    "\n",
    "                    # Predict and store results\n",
    "                    outputs = model(batch_X1, batch_X2).squeeze()\n",
    "                    all_predictions.append(outputs)\n",
    "                    all_true_values.append(batch_y)\n",
    "\n",
    "\n",
    "            # Compute MAE and RMSE for this fold and store them\n",
    "            all_predictions = torch.cat(all_predictions)\n",
    "            all_true_values = torch.cat(all_true_values)\n",
    "            test_mae_per_fold.append(torch.mean(torch.abs(all_predictions - all_true_values)).item())\n",
    "            test_rmse_per_fold.append(torch.sqrt(torch.mean((all_predictions - all_true_values) ** 2)).item())\n",
    "\n",
    "\n",
    "        # Calculate the mean and std of validation loss, test MAE, and test RMSE across folds\n",
    "        mean_val_loss = np.mean(fold_results)\n",
    "        mean_test_mae = np.mean(test_mae_per_fold)\n",
    "        std_test_mae = np.std(test_mae_per_fold)\n",
    "        mean_test_rmse = np.mean(test_rmse_per_fold)\n",
    "        std_test_rmse = np.std(test_rmse_per_fold)\n",
    "\n",
    "        # Log results for this trial\n",
    "        writer.writerow([trial.number, learning_rate, batch_size, hidden_size, num_layers] + \n",
    "                        fold_results + [mean_val_loss, mean_test_mae, std_test_mae, mean_test_rmse, std_test_rmse])\n",
    "        file.flush()  # Ensure each trial result is written immediately\n",
    "\n",
    "        # Return the mean validation loss across folds for Optuna to optimize\n",
    "        return mean_val_loss\n",
    "\n",
    "    # Run the Optuna study\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    joblib.dump(study, \"synthetic_data_LSTMX1_X2BeforeLSTM.pkl\")\n",
    "\n",
    "    # Print the best hyperparameters and validation loss\n",
    "    print(\"Best hyperparameters:\", study.best_params)\n",
    "    print(\"Best cross-validated validation loss:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
