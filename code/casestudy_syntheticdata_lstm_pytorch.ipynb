{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "results_dir = '../results'\n",
    "images_dir = '../images'\n",
    "data_dir = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from train_pipeline import ModelTrainingPipeline\n",
    "\n",
    "seed = 1729\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTrainingPipeline.set_seed(seed)\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def create_dataset(data, variable_indexes, lookback_period, step, forecast_period, motif_indexes):\n",
    "    X1, X2, y = [], [], []  # X1: data, X2: indexes of the motifs, y: distance to the next motif\n",
    "    \n",
    "    for idx in range(len(data[0]) - lookback_period - 1):\n",
    "        if idx % step != 0:\n",
    "            continue\n",
    "\n",
    "        window_end_idx = idx + lookback_period\n",
    "        forecast_period_end = window_end_idx + forecast_period\n",
    "\n",
    "        # If there are no more matches after the window, break\n",
    "        if not any([window_end_idx < motif_idx for motif_idx in motif_indexes]):\n",
    "            break\n",
    "\n",
    "        # Motif indexes in window, relative to the start of the window\n",
    "        motif_indexes_in_window = [motif_idx - idx for motif_idx in motif_indexes if idx <= motif_idx <= window_end_idx]\n",
    "        motif_indexes_in_forecast_period = [motif_idx for motif_idx in motif_indexes if window_end_idx < motif_idx <= forecast_period_end]\n",
    "\n",
    "        if motif_indexes_in_forecast_period:\n",
    "            next_match_in_forecast_period = motif_indexes_in_forecast_period[0]\n",
    "        else:\n",
    "            next_match_in_forecast_period = -1  # No match in the forecast period but exists in the future\n",
    "\n",
    "        # Get the data window and transpose to (lookback_period, num_features)\n",
    "        data_window = data[variable_indexes, idx:window_end_idx].T\n",
    "\n",
    "        # Calculate `y`\n",
    "        data_y = -1\n",
    "        if next_match_in_forecast_period != -1:\n",
    "            # Index of the next match relative to the end of the window\n",
    "            data_y = next_match_in_forecast_period - window_end_idx\n",
    "        \n",
    "        # Append to lists\n",
    "        X1.append(torch.tensor(data_window, dtype=torch.float32))  # Now with shape (lookback_period, num_features)\n",
    "        X2.append(torch.tensor(motif_indexes_in_window, dtype=torch.long)) \n",
    "        y.append(data_y) \n",
    "\n",
    "    # Pad X2 sequences to have the same length\n",
    "    X2_padded = pad_sequence(X2, batch_first=True, padding_value=-1) # Final shape: (num_samples, max_num_motifs)\n",
    "    \n",
    "    # Convert lists to torch tensors\n",
    "    X1 = torch.stack(X1)  # Final shape: (num_samples, lookback_period, num_features)\n",
    "    y = torch.tensor(y, dtype=torch.float32).unsqueeze(1) \n",
    "\n",
    "    return X1, X2_padded, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \n",
    "n = 100000 #number of data points\n",
    "k = 3 #number of variables\n",
    "p = 5 # pattern length\n",
    "variable_indexes = range(k)\n",
    "\n",
    "dataset_path = os.path.join(data_dir, \"syntheticdata/n={}_k={}_p={}_min_step={}_max_step={}.csv\".format(n, k, p, 5, 45))\n",
    "motif_indexes_path = os.path.join(data_dir, \"syntheticdata/motif_indexes_n={}_k={}_p={}_min_step={}_max_step={}.csv\".format(n, k, p, 5, 45))\n",
    "data = np.genfromtxt(dataset_path, delimiter=\",\").astype(int).reshape((k, n))\n",
    "motif_indexes = np.genfromtxt(motif_indexes_path, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_split import BlockingTimeSeriesSplit\n",
    "\n",
    "#create index  \n",
    "indexes = np.arange(len(data[0]))\n",
    "\n",
    "#split data\n",
    "tscv = BlockingTimeSeriesSplit(n_splits=5)\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(indexes)):\n",
    "    # Plot train and test indices\n",
    "    ax.plot(train_index, np.zeros_like(train_index) + i, 'o', color='lightblue')\n",
    "    ax.plot(test_index, np.zeros_like(test_index) + i, 'o', color='red')\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    \n",
    "\n",
    "ax.set_yticks(np.arange(5), [\"Fold {}\".format(i) for i in range(1, 6)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#x1: past window, x2: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X1, X2, y = create_dataset(data, variable_indexes, lookback_period, step, forecast_period, motif_indexes)\n",
    "\n",
    "# X1, X2, and y are now PyTorch tensors\n",
    "print(\"X1 shape:\", X1.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X2 shape:\", X2.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_study(objective_func, model_class, seed, X1, y, results_folder: str, n_trials: int = 100, num_epochs=500, X2=None):\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "    file_name = os.path.join(results_folder, \"study.pkl\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        criterion = torch.nn.MSELoss()  # Define the criterion here\n",
    "        trial_val_loss, _, _ = objective_func(trial, seed, results_folder, model_class, X1, y, X2, criterion, num_epochs)  # Pass criterion\n",
    "\n",
    "        return trial_val_loss\n",
    "\n",
    "    # Let Optuna manage trials and pass them to the objective function\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    joblib.dump(study, file_name)\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_df.to_csv(os.path.join(results_folder, \"study_results.csv\"), index=False)\n",
    "\n",
    "    print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1Input\n",
    "from train_pipeline import EarlyStopper, ModelTrainingPipeline\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1Input_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)  \n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1Input, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"]) \n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "def plot_best_model_results(study_df):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharey=True)\n",
    "\n",
    "    best_fold_train_losses = []\n",
    "    best_fold_val_losses = []\n",
    "\n",
    "    for i in range(5):\n",
    "        # Extract losses for the best trial for the current fold\n",
    "        best_fold_train_losses.append(study_df[f\"user_attrs_fold_{i + 1}_train_losses\"].iloc[study_df[\"value\"].idxmin()])\n",
    "        best_fold_val_losses.append(study_df[f\"user_attrs_fold_{i + 1}_validation_losses\"].iloc[study_df[\"value\"].idxmin()])\n",
    "\n",
    "        # Plot train and validation losses in the current subplot\n",
    "        axes[i].plot(best_fold_train_losses[i], label=\"Train Loss\")\n",
    "        axes[i].plot(best_fold_val_losses[i], label=\"Validation Loss\")\n",
    "\n",
    "        # Customize the subplot\n",
    "        axes[i].set_title(f\"Fold {i + 1}\")\n",
    "        axes[i].set_xlabel(\"Epoch\")\n",
    "        if i == 0:  # Only set ylabel for the first subplot\n",
    "            axes[i].set_ylabel(\"Loss\")\n",
    "        axes[i].legend()\n",
    "\n",
    "    # Adjust layout and display the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_best_model_results(study_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100))\n",
    "ModelTrainingPipeline.set_seed(seed)\n",
    "\n",
    "# Retrieve the best configuration from the Optuna study\n",
    "best_config = study.best_params\n",
    "print(\"Best hyperparameters:\", best_config)\n",
    "\n",
    "# Initialize lists to store results\n",
    "epochs_train_losses = []\n",
    "epochs_val_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "all_predictions = []\n",
    "all_true_values = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(BlockingTimeSeriesSplit(n_splits=5).split(X1)):\n",
    "    pipeline.early_stopper.reset() \n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    train_val_split_idx = int(0.8 * len(train_idx))\n",
    "    train_idx, val_index = train_idx[:train_val_split_idx], train_idx[train_val_split_idx:]\n",
    "    X1_train, X1_val, X1_test = X1[train_idx], X1[val_index], X1[test_idx]\n",
    "    y_train, y_val, y_test = y[train_idx], y[val_index], y[test_idx]\n",
    "    X1_train_scaled, X1_val_scaled, X1_test_scaled = pipeline.scale_data(X1_train, X1_val, X1_test)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader, val_loader, test_loader = pipeline.prepare_dataloaders(\n",
    "        X1_train_scaled, X1_val_scaled, X1_test_scaled, y_train, y_val, y_test,\n",
    "        best_config[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = LSTMX1Input(\n",
    "        input_size=X1.shape[2],\n",
    "        hidden_size=best_config[\"hidden_size\"],\n",
    "        num_layers=best_config[\"num_layers\"],\n",
    "        output_size=1\n",
    "    ).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    fold_val_loss, model, best_epochs, train_losses, validation_losses = pipeline.train_model(\n",
    "        model,\n",
    "        criterion=torch.nn.MSELoss(),\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=best_config[\"learning_rate\"]),\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=500,\n",
    "        dual_input=False  # Single input configuration\n",
    "    )\n",
    "\n",
    "    # Store training and validation losses\n",
    "    epochs_train_losses.append(train_losses)\n",
    "    epochs_val_losses.append(validation_losses)\n",
    "    val_losses.append(fold_val_loss)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, fold_predictions, fold_true_values = pipeline.evaluate_test_set(\n",
    "        model, test_loader, criterion=torch.nn.MSELoss(), dual_input=False\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    all_predictions.append(fold_predictions.cpu().numpy())\n",
    "    all_true_values.append(fold_true_values.cpu().numpy())\n",
    "\n",
    "# Output validation and test losses\n",
    "print(\"Validation Losses:\", val_losses)\n",
    "print(\"Mean validation loss:\", np.mean(val_losses))\n",
    "print(\"Test Losses:\", test_losses)\n",
    "print(\"Mean test loss:\", np.mean(test_losses))\n",
    "\n",
    "# Plot the train and validation losses for each fold\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharey=True)\n",
    "for i in range(5):\n",
    "    axes[i].plot(epochs_train_losses[i], label=\"Train Loss\")\n",
    "    axes[i].plot(epochs_val_losses[i], label=\"Validation Loss\")\n",
    "    axes[i].set_title(f\"Fold {i + 1}\")\n",
    "    axes[i].set_xlabel(\"Epoch\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Loss\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Example for one fold (extend to all folds if needed)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=np.ravel(all_true_values[0]), mode='markers', name='True Values'))\n",
    "fig.add_trace(go.Scatter(y=np.ravel(all_predictions[0]), mode='markers', name='Predictions'))\n",
    "fig.update_layout(\n",
    "    title=\"Interactive Plot for Fold 1\",\n",
    "    xaxis_title=\"Sample\",\n",
    "    yaxis_title=\"Value\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1_X2BeforeLSTM\n",
    "from train_pipeline import EarlyStopper, ModelTrainingPipeline\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1_X2BeforeLSTM_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)  \n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1Input, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs, X2=X2)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"]) \n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "plot_best_model_results(study_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the pipeline\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100))\n",
    "ModelTrainingPipeline.set_seed(seed)\n",
    "\n",
    "# Retrieve the best configuration from the Optuna study\n",
    "best_config = study.best_params\n",
    "print(\"Best hyperparameters:\", best_config)\n",
    "\n",
    "# Initialize lists to store results\n",
    "epochs_train_losses = []\n",
    "epochs_val_losses = []\n",
    "val_losses = []\n",
    "test_losses = []\n",
    "all_predictions = []\n",
    "all_true_values = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(BlockingTimeSeriesSplit(n_splits=5).split(X1)):\n",
    "    pipeline.early_stopper.reset() \n",
    "\n",
    "    # Split data into train, validation, and test sets\n",
    "    train_val_split_idx = int(0.8 * len(train_idx))\n",
    "    train_idx, val_index = train_idx[:train_val_split_idx], train_idx[train_val_split_idx:]\n",
    "    X1_train, X1_val, X1_test = X1[train_idx], X1[val_index], X1[test_idx]\n",
    "    y_train, y_val, y_test = y[train_idx], y[val_index], y[test_idx]\n",
    "    X1_train_scaled, X1_val_scaled, X1_test_scaled = pipeline.scale_data(X1_train, X1_val, X1_test)\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader, val_loader, test_loader = pipeline.prepare_dataloaders(\n",
    "        X1_train_scaled, X1_val_scaled, X1_test_scaled, y_train, y_val, y_test,\n",
    "        best_config[\"batch_size\"], X2_train=X2[train_idx], X2_val=X2[val_index], X2_test=X2[test_idx]\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    model = LSTMX1_X2BeforeLSTM(\n",
    "        input_size=X1.shape[2],\n",
    "        hidden_size=best_config[\"hidden_size\"],\n",
    "        num_layers=best_config[\"num_layers\"],\n",
    "        output_size=1,\n",
    "        auxiliary_input_dim=X2.shape[1]\n",
    "    ).to(device)\n",
    "\n",
    "    # Train the model\n",
    "    fold_val_loss, model, best_epochs, train_losses, validation_losses = pipeline.train_model(\n",
    "        model,\n",
    "        criterion=torch.nn.MSELoss(),\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=best_config[\"learning_rate\"]),\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=500,\n",
    "        dual_input=True  # Single input configuration\n",
    "    )\n",
    "\n",
    "    # Store training and validation losses\n",
    "    epochs_train_losses.append(train_losses)\n",
    "    epochs_val_losses.append(validation_losses)\n",
    "    val_losses.append(fold_val_loss)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, fold_predictions, fold_true_values = pipeline.evaluate_test_set(\n",
    "        model, test_loader, criterion=torch.nn.MSELoss(), dual_input=True\n",
    "    )\n",
    "    test_losses.append(test_loss)\n",
    "    all_predictions.append(fold_predictions.cpu().numpy())\n",
    "    all_true_values.append(fold_true_values.cpu().numpy())\n",
    "\n",
    "# Output validation and test losses\n",
    "print(\"Validation Losses:\", val_losses)\n",
    "print(\"Mean validation loss:\", np.mean(val_losses))\n",
    "print(\"Test Losses:\", test_losses)\n",
    "print(\"Mean test loss:\", np.mean(test_losses))\n",
    "\n",
    "# Plot the train and validation losses for each fold\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(20, 5), sharey=True)\n",
    "for i in range(5):\n",
    "    axes[i].plot(epochs_train_losses[i], label=\"Train Loss\")\n",
    "    axes[i].plot(epochs_val_losses[i], label=\"Validation Loss\")\n",
    "    axes[i].set_title(f\"Fold {i + 1}\")\n",
    "    axes[i].set_xlabel(\"Epoch\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Loss\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1_X2AfterLSTM\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1_X2AfterLSTM_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1_X2AfterLSTM, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs, X2=X2)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"])\n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "plot_best_model_results(study_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1_X2AfterLSTM\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1_X2AfterLSTM_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1_X2AfterLSTM, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs, X2=X2)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"])\n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "\n",
    "plot_best_model_results(study_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1_X2Masking\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "#X1 shape is (num_samples, lookback_period)\n",
    "masking_X1 = np.zeros((X1.shape[0], X1.shape[1])) \n",
    "\n",
    "for i, obs_motif_indexes in enumerate(X2):\n",
    "    for j, idx in enumerate(obs_motif_indexes):\n",
    "        masking_X1[i, idx.item():idx.item()+p] = 1\n",
    "\n",
    "masking_X1 = torch.tensor(masking_X1, dtype=torch.float32)\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1_X2Masking_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1_X2Masking, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs, X2=masking_X1)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"])\n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "\n",
    "plot_best_model_results(study_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.lstm_pytorch import LSTMX1Attention\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "result_dir = os.path.join(results_dir, f\"LSTMX1Attention_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "os.makedirs(result_dir, exist_ok=True)  \n",
    "\n",
    "early_stopper = EarlyStopper(patience=10, min_delta=1e-5, min_epochs=100)\n",
    "pipeline = ModelTrainingPipeline(device=device, early_stopper=early_stopper)\n",
    "\n",
    "#run_optuna_study(pipeline.run_cross_val, LSTMX1Attention, seed, X1, y, result_dir, n_trials=n_trials, num_epochs=num_epochs)\n",
    "\n",
    "study = joblib.load(os.path.join(result_dir, \"study.pkl\"))\n",
    "study_df = study.trials_dataframe()\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Validation Losses\", study.best_trial.user_attrs[\"fold_val_losses\"])\n",
    "print(\"Mean validation loss:\", study.best_trial.user_attrs[\"mean_val_loss\"])\n",
    "print(\"Test Losses\", study.best_trial.user_attrs[\"test_losses\"])\n",
    "print(\"Mean test loss:\", study.best_trial.user_attrs[\"mean_test_loss\"])\n",
    "print(\"Mean test MAE:\", study.best_trial.user_attrs[\"mean_test_mae\"])\n",
    "print(\"Mean test RMSE:\", study.best_trial.user_attrs[\"mean_test_rmse\"])\n",
    "\n",
    "plot_best_model_results(study_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
