{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-05 11:31:56,942 - INFO - Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata2/variables=[0,2]\n",
      "2025-02-05 11:31:56,942 - INFO - Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata2/variables=[0,2]\n",
      "2025-02-05 11:31:56,942 - INFO - Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata2/variables=[0,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved in: /home/mgsilva/motifpred/results/syntheticdata2/variables=[0,2]\n",
      "Images will be saved in: /home/mgsilva/motifpred/images/syntheticdata2/variables=[0,2]\n",
      "Data will be accessed from: /home/mgsilva/motifpred/data/syntheticdata2/variables=[0,2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "from config import RESULTS_DIR, IMAGES_DIR, DATA_DIR, DATASET_PATH, MOTIF_INDEXES_PATH, K, N, P, NORMALIZE_FLAGS\n",
    "\n",
    "print(f\"Results will be saved in: {RESULTS_DIR}\")\n",
    "print(f\"Images will be saved in: {IMAGES_DIR}\")\n",
    "print(f\"Data will be accessed from: {DATA_DIR}\")\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "if '__file__' in globals():\n",
    "    # For standalone scripts\n",
    "    base_dir = os.path.dirname(__file__)\n",
    "else:\n",
    "    # For Jupyter or interactive environments\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of `utils` to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(base_dir, \"../\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   30    63    90 ... 99871 99921 99960]\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(DATASET_PATH, delimiter=\",\").astype(int).reshape((K, N))\n",
    "motif_indexes = np.genfromtxt(MOTIF_INDEXES_PATH, delimiter=\",\").astype(int)\n",
    "\n",
    "print(motif_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691],\n",
      "        [0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938],\n",
      "        [0.6128, 0.1519, 0.0453]])\n"
     ]
    }
   ],
   "source": [
    "# Import shared setup\n",
    "from utils.setup import seed, device, early_stopper, pipeline, test_tensor\n",
    "\n",
    "# Example usage\n",
    "print(f\"Device: {device}\")\n",
    "test_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_series shape: torch.Size([19972, 100, 3])\n",
      "X_mask shape: torch.Size([19972, 100])\n",
      "X_indices shape: torch.Size([19972, 4, 1])\n",
      "y shape: torch.Size([19972, 1])\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import create_dataset\n",
    "\n",
    "lookback_period = 100 #window size\n",
    "step = 5 #step size for the sliding window\n",
    "forecast_period = 50 #forward window size\n",
    "\n",
    "#X_series: past window, X_indices: indexes of the motif in the window,  y: next relative index of the motif\n",
    "X_series, X_indices, X_mask, y = create_dataset(data, lookback_period, step, forecast_period, motif_indexes, P)\n",
    "\n",
    "# X_series, X2, and y are now PyTorch tensors\n",
    "print(\"X_series shape:\", X_series.shape)  # Expected shape: (num_samples, lookback_period, num_features)\n",
    "print(\"X_mask shape:\", X_mask.shape)  # Expected shape: (num_samples, lookback_period)\n",
    "print(\"X_indices shape:\", X_indices.shape)  # Expected shape: (num_samples, max_motif_length_in_window)\n",
    "print(\"y shape:\", y.shape)    # Expected shape: (num_samples, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model FFNNSeries already exists\n",
      "Model FFNNSeries_Masking already exists\n",
      "Model FFNNIndexes already exists\n",
      "Model LSTMSeries already exists\n",
      "Model LSTMSeries_Masking already exists\n",
      "Model LSTMIndexes already exists\n",
      "Model CNNSeries already exists\n",
      "Model CNNSeries_Masking already exists\n",
      "Model CNNIndexes already exists\n",
      "Model TCNSeries already exists\n",
      "Model TCNSeries_Masking already exists\n",
      "Model TCNIndexes already exists\n",
      "Model TransformerSeries already exists\n",
      "Model TransformerSeries_Masking already exists\n",
      "Model TransformerIndexes already exists\n",
      "Model BaselineAverageIndexes already exists\n",
      "Model BaselineLastDifferenceIndexes already exists\n"
     ]
    }
   ],
   "source": [
    "from models.ffnn_pytorch import FFNN\n",
    "from models.lstm_pytorch import LSTM\n",
    "from models.cnn_pytorch import CNN\n",
    "from models.tcn_pytorch import TCN\n",
    "from models.transformer_pytorch import Transformer\n",
    "from models.baseline_pytorch import BaselineAverage, BaselineLastDifference\n",
    "from utils.utils import print_study_results, get_best_model_results, plot_best_model_results, plot_preds_vs_truevalues\n",
    "from utils.train_pipeline import get_preds_best_config\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "n_trials = 100\n",
    "num_epochs = 500\n",
    "\n",
    "\n",
    "def process_baseline_model(model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y):\n",
    "    \"\"\"Process baseline models.\"\"\"\n",
    "    model_name = f\"{model_class.__name__}{input_name}\"\n",
    "    dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, model_class, \"Baseline\", [], num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    if not np.allclose(fold_val_losses, val_losses):\n",
    "        raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "def process_non_baseline_model(model_type, model_params_keys, input_name, X, normalize_flags, num_epochs, seed, pipeline, y):\n",
    "    \"\"\"Process non-baseline models.\"\"\"\n",
    "    model_name = f\"{model_type}{input_name}\"\n",
    "    model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "\n",
    "    if os.path.exists(os.path.join(model_results_dir, \"best_model_results.csv\")):\n",
    "        print(f\"Model {model_name} already exists\")\n",
    "        return\n",
    "\n",
    "    study = joblib.load(os.path.join(model_results_dir, \"study.pkl\"))\n",
    "    fold_val_losses, fold_test_losses = get_best_model_results(study)\n",
    "\n",
    "    (epochs_train_losses, epochs_val_losses, val_losses, test_losses,\n",
    "     test_mae_per_fold, test_rmse_per_fold, all_predictions, all_true_values) = get_preds_best_config(\n",
    "        study, pipeline, eval(model_type), model_type, model_params_keys, num_epochs=num_epochs, seed=seed, X=X, y=y, normalize_flags=normalize_flags\n",
    "    )\n",
    "\n",
    "    #if not np.allclose(fold_val_losses, val_losses, atol=1):\n",
    "    #    raise Exception(\"Best model val losses are not close to val losses\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results = pd.DataFrame({\n",
    "        \"fold\": np.arange(1, 6),\n",
    "        \"val_loss\": fold_val_losses,\n",
    "        \"test_loss\": fold_test_losses,\n",
    "        \"test_mae\": test_mae_per_fold,\n",
    "        \"test_rmse\": test_rmse_per_fold\n",
    "    })\n",
    "    results.to_csv(os.path.join(model_results_dir, \"best_model_results.csv\"), index=False, mode='w')\n",
    "\n",
    "\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        normalize_flags = NORMALIZE_FLAGS\n",
    "        n_trials, num_epochs = (1, 1) if model_type == \"Baseline\" else (n_trials, num_epochs)\n",
    "\n",
    "        if model_type == \"Baseline\":\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "\n",
    "            X = {\"X_series\": X_series, \"X_mask\": X_mask, \"X_indices\": X_indices}\n",
    "            normalize_flags = {\"X_series\": True, \"X_mask\": False, \"X_indices\": False}\n",
    "\n",
    "            for model_class in [BaselineAverage, BaselineLastDifference]:\n",
    "                process_baseline_model(\n",
    "                    model_class, input_name, X, normalize_flags, n_trials, num_epochs, pipeline, seed, y\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            if input_name == \"Series\":\n",
    "                X = {\"X_series\": X_series}\n",
    "            elif input_name == \"Series_Masking\":\n",
    "                X = {\"X_series\": X_series, \"X_mask\": X_mask}\n",
    "            else:\n",
    "                X = {\"X_indices\": X_indices}\n",
    "\n",
    "\n",
    "            model_params_map = {\n",
    "                \"FFNN\": [\"hidden_sizes_list\"],\n",
    "                \"LSTM\": [\"hidden_sizes_list\"],\n",
    "                \"CNN\": [\"kernel_size\", \"num_filters_list\", \"pool_size\"],\n",
    "                \"TCN\": [\"kernel_size\", \"num_channels_list\", \"dropout\"],\n",
    "                \"Transformer\": [\"d_model\", \"n_heads\", \"e_layers\", \"dim_feedforward\", \"dropout\"]\n",
    "            }\n",
    "\n",
    "            process_non_baseline_model(\n",
    "                model_type, model_params_map[model_type], input_name, X, normalize_flags, num_epochs, seed, pipeline, y\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Model: FFNNSeries\n",
      "Processing Model: FFNNSeries_Masking\n",
      "Processing Model: FFNNIndexes\n",
      "Processing Model: LSTMSeries\n",
      "Processing Model: LSTMSeries_Masking\n",
      "Processing Model: LSTMIndexes\n",
      "Processing Model: CNNSeries\n",
      "Processing Model: CNNSeries_Masking\n",
      "Processing Model: CNNIndexes\n",
      "Processing Model: TCNSeries\n",
      "Processing Model: TCNSeries_Masking\n",
      "Processing Model: TCNIndexes\n",
      "Processing Model: TransformerSeries\n",
      "Processing Model: TransformerSeries_Masking\n",
      "Processing Model: TransformerIndexes\n",
      "Processing Model: BaselineAverageIndexes\n",
      "Processing Model: BaselineLastDifferenceIndexes\n",
      "                     model    input fold       mae       rmse\n",
      "0                     FFNN   Series    1  7.445557  10.795273\n",
      "1                     FFNN   Series    2  7.257272  10.210246\n",
      "2                     FFNN   Series    3  7.204072   9.981597\n",
      "3                     FFNN   Series    4  6.720878   9.787326\n",
      "4                     FFNN   Series    5  7.240952  10.807480\n",
      "..                     ...      ...  ...       ...        ...\n",
      "80  BaselineLastDifference  Indexes    1  7.513142   9.600858\n",
      "81  BaselineLastDifference  Indexes    2  8.222778  10.112509\n",
      "82  BaselineLastDifference  Indexes    3  8.165207  10.228308\n",
      "83  BaselineLastDifference  Indexes    4  7.719650   9.797959\n",
      "84  BaselineLastDifference  Indexes    5  7.932415   9.967030\n",
      "\n",
      "[85 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214285/2494069276.py:76: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "models = [\"FFNN\", \"LSTM\", \"CNN\", \"TCN\", \"Transformer\", \"Baseline\"]\n",
    "inputs = [\"Series\", \"Series_Masking\", \"Indexes\"]\n",
    "\n",
    "results_df = pd.DataFrame(columns=[\"model\", \"input\", \"fold\", \"mae\", \"rmse\"])\n",
    "\n",
    "# Combine each model with each input\n",
    "for model_type in models:\n",
    "    for input_name in inputs:\n",
    "        # Handle baseline-specific logic\n",
    "        if model_type == \"Baseline\":\n",
    "            n_trials, num_epochs = (1, 1)\n",
    "            if input_name != \"Indexes\":\n",
    "                continue\n",
    "            \n",
    "            # Process both BaselineAverage and BaselineLastDifference\n",
    "            baseline_variants = [\"BaselineAverage\", \"BaselineLastDifference\"]\n",
    "            for baseline_type in baseline_variants:\n",
    "                model_name = f\"{baseline_type}{input_name}\"\n",
    "                print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "                # Construct the results directory path\n",
    "                model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "                results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "                # Skip if results file doesn't exist\n",
    "                if not os.path.exists(results_file):\n",
    "                    print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Load results from CSV\n",
    "                results = pd.read_csv(results_file)\n",
    "                maes = results[\"test_mae\"].values\n",
    "                rmses = results[\"test_rmse\"].values\n",
    "\n",
    "                # Add results to the dataframe\n",
    "                for i in range(len(maes)):  # Assuming results have folds\n",
    "                    results_df = pd.concat([\n",
    "                        results_df,\n",
    "                        pd.DataFrame([{\n",
    "                            \"model\": baseline_type,\n",
    "                            \"input\": input_name,\n",
    "                            \"fold\": i + 1,\n",
    "                            \"mae\": maes[i],\n",
    "                            \"rmse\": rmses[i]\n",
    "                        }])\n",
    "                    ], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            n_trials = 100\n",
    "            num_epochs = 500\n",
    "\n",
    "            model_name = f\"{model_type}{input_name}\"\n",
    "            print(f\"Processing Model: {model_name}\")\n",
    "\n",
    "            # Construct the results directory path\n",
    "            model_results_dir = os.path.join(RESULTS_DIR, f\"{model_name}_{n_trials}_trials_{num_epochs}_epochs\")\n",
    "            results_file = os.path.join(model_results_dir, \"best_model_results.csv\")\n",
    "\n",
    "            # Skip if results file doesn't exist\n",
    "            if not os.path.exists(results_file):\n",
    "                print(f\"Results file for {model_name} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load results from CSV\n",
    "            results = pd.read_csv(results_file)\n",
    "            maes = results[\"test_mae\"].values\n",
    "            rmses = results[\"test_rmse\"].values\n",
    "\n",
    "            # Add results to the dataframe\n",
    "            for i in range(len(maes)):  # Assuming results have folds\n",
    "                results_df = pd.concat([\n",
    "                    results_df,\n",
    "                    pd.DataFrame([{\n",
    "                        \"model\": model_type,\n",
    "                        \"input\": input_name,\n",
    "                        \"fold\": i + 1,\n",
    "                        \"mae\": maes[i],\n",
    "                        \"rmse\": rmses[i]\n",
    "                    }])\n",
    "                ], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model           input fold       mae       rmse\n",
      "0          BaselineAverage         Indexes  3.0  7.128035   8.855437\n",
      "1   BaselineLastDifference         Indexes  3.0  7.910638   9.941333\n",
      "2                      CNN         Indexes  3.0  5.837890   7.056558\n",
      "3                      CNN          Series  3.0  6.271344   8.281592\n",
      "4                      CNN  Series_Masking  3.0  5.526430   7.428830\n",
      "5                     FFNN         Indexes  3.0  5.837307   6.978092\n",
      "6                     FFNN          Series  3.0  7.173746  10.316384\n",
      "7                     FFNN  Series_Masking  3.0  6.291727   8.902604\n",
      "8                     LSTM         Indexes  3.0  5.779784   6.920686\n",
      "9                     LSTM          Series  3.0  4.894149   7.319938\n",
      "10                    LSTM  Series_Masking  3.0  4.975712   7.499099\n",
      "11                     TCN         Indexes  3.0  5.783748   6.889995\n",
      "12                     TCN          Series  3.0  4.795416   7.131516\n",
      "13                     TCN  Series_Masking  3.0  4.871335   7.066913\n",
      "14             Transformer         Indexes  3.0  5.785303   6.896652\n",
      "15             Transformer          Series  3.0  5.032853   7.743369\n",
      "16             Transformer  Series_Masking  3.0  4.959506   7.727468\n"
     ]
    }
   ],
   "source": [
    "#average fold results for each model and input\n",
    "avg_results_df = results_df.groupby([\"model\", \"input\"]).mean().reset_index()\n",
    "print(avg_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_1</th>\n",
       "      <th>InputType_1</th>\n",
       "      <th>Model_2</th>\n",
       "      <th>InputType_2</th>\n",
       "      <th>Metric</th>\n",
       "      <th>P-Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.944167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCN</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.772097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>mae</td>\n",
       "      <td>0.003804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>Series</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>Indexes</td>\n",
       "      <td>rmse</td>\n",
       "      <td>0.983178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model_1 InputType_1 Model_2 InputType_2 Metric   P-Value\n",
       "0         LSTM      Series    LSTM     Indexes    mae  0.000291\n",
       "1         LSTM      Series    LSTM     Indexes   rmse  0.944167\n",
       "2          TCN      Series    LSTM     Indexes    mae  0.000684\n",
       "3          TCN      Series    LSTM     Indexes   rmse  0.772097\n",
       "4  Transformer      Series    LSTM     Indexes    mae  0.003804\n",
       "5  Transformer      Series    LSTM     Indexes   rmse  0.983178"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "models_1 = [\"LSTM\", \"TCN\", \"Transformer\"]\n",
    "input_types_1 = [\"Series\"]\n",
    "models_2 = [\"LSTM\" ]\n",
    "input_types_2 = [\"Indexes\"]\n",
    "\n",
    "# Filter data for the selected input types\n",
    "\n",
    "results = []\n",
    "for model1 in models_1:\n",
    "    for model2 in models_2:\n",
    "        for input_1 in input_types_1:\n",
    "            for input_2 in input_types_2:\n",
    "                for metric in [\"mae\", \"rmse\"]:\n",
    "\n",
    "                    data1 = results_df[(results_df['model'] == model1) & (results_df['input'] == input_1)].sort_values('fold')[metric]\n",
    "                    data2 = results_df[(results_df['model'] == model2) & (results_df['input'] == input_2)].sort_values('fold')[metric]\n",
    "\n",
    "                    # Perform a paired t-test if the lengths match\n",
    "                    if len(data1) == len(data2):\n",
    "                        t_stat, p_value = ttest_rel(data1, data2, alternative='less')\n",
    "                        results.append({\n",
    "                            \"Model_1\": model1,\n",
    "                            \"InputType_1\": input_1,\n",
    "                            \"Model_2\": model2,\n",
    "                            \"InputType_2\": input_2,\n",
    "                            \"Metric\": metric,\n",
    "                            \"P-Value\": p_value\n",
    "                        })\n",
    "\n",
    "# Convert results to DataFrame and display\n",
    "pval_results_df = pd.DataFrame(results)\n",
    "pval_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
