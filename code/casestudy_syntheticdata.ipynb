{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "keras.utils.set_random_seed(812)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.005,\n",
       " 0.015,\n",
       " 0.02,\n",
       " 0.03,\n",
       " 0.035,\n",
       " 0.045,\n",
       " 0.05,\n",
       " 0.06,\n",
       " 0.065,\n",
       " 0.075,\n",
       " 0.08,\n",
       " 0.09,\n",
       " 0.095,\n",
       " 0.105,\n",
       " 0.11,\n",
       " 0.12,\n",
       " 0.125,\n",
       " 0.135,\n",
       " 0.14,\n",
       " 0.15,\n",
       " 0.155,\n",
       " 0.165,\n",
       " 0.17,\n",
       " 0.18,\n",
       " 0.185,\n",
       " 0.195,\n",
       " 0.2,\n",
       " 0.21,\n",
       " 0.215,\n",
       " 0.225,\n",
       " 0.23,\n",
       " 0.24,\n",
       " 0.245,\n",
       " 0.255,\n",
       " 0.26,\n",
       " 0.27,\n",
       " 0.275,\n",
       " 0.285,\n",
       " 0.29,\n",
       " 0.3,\n",
       " 0.305,\n",
       " 0.315,\n",
       " 0.32,\n",
       " 0.33,\n",
       " 0.335,\n",
       " 0.345,\n",
       " 0.35,\n",
       " 0.36,\n",
       " 0.365,\n",
       " 0.375,\n",
       " 0.38,\n",
       " 0.39,\n",
       " 0.395,\n",
       " 0.405,\n",
       " 0.41,\n",
       " 0.42,\n",
       " 0.425,\n",
       " 0.435,\n",
       " 0.44,\n",
       " 0.45,\n",
       " 0.455,\n",
       " 0.465,\n",
       " 0.47,\n",
       " 0.48,\n",
       " 0.485,\n",
       " 0.495,\n",
       " 0.5,\n",
       " 0.51,\n",
       " 0.515,\n",
       " 0.525,\n",
       " 0.53,\n",
       " 0.54,\n",
       " 0.545,\n",
       " 0.555,\n",
       " 0.56,\n",
       " 0.57,\n",
       " 0.575,\n",
       " 0.585,\n",
       " 0.59,\n",
       " 0.6,\n",
       " 0.605,\n",
       " 0.615,\n",
       " 0.62,\n",
       " 0.63,\n",
       " 0.635,\n",
       " 0.645,\n",
       " 0.65,\n",
       " 0.66,\n",
       " 0.665,\n",
       " 0.675,\n",
       " 0.68,\n",
       " 0.69,\n",
       " 0.695,\n",
       " 0.705,\n",
       " 0.71,\n",
       " 0.72,\n",
       " 0.725,\n",
       " 0.735,\n",
       " 0.74,\n",
       " 0.75]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_indexes = []\n",
    "n = 1000\n",
    "p = 5\n",
    "k = 100\n",
    "\n",
    "start = 0\n",
    "while len(motif_indexes) < k:\n",
    "    if len(motif_indexes) % 2 == 0:\n",
    "        start += p\n",
    "    else:\n",
    "        start += 2 * p\n",
    "    motif_indexes.append(start)\n",
    "\n",
    "motif_indexes = sorted(motif_indexes)\n",
    "#normalize the data\n",
    "motif_indexes = [idx / n for idx in motif_indexes]\n",
    "motif_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(data, look_back=1):\n",
    "    X, y = list(), list()\n",
    "    for idx in range(len(data)- look_back -1):\n",
    "        data_x, data_y = data[idx:idx+look_back], data[idx+look_back]\n",
    "        X.append(data_x)\n",
    "        y.append(data_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.005 0.015 0.02  0.03  0.035 0.045 0.05  0.06  0.065 0.075] 0.08\n",
      "[0.015 0.02  0.03  0.035 0.045 0.05  0.06  0.065 0.075 0.08 ] 0.09\n",
      "[0.02  0.03  0.035 0.045 0.05  0.06  0.065 0.075 0.08  0.09 ] 0.095\n",
      "[0.03  0.035 0.045 0.05  0.06  0.065 0.075 0.08  0.09  0.095] 0.105\n",
      "[0.035 0.045 0.05  0.06  0.065 0.075 0.08  0.09  0.095 0.105] 0.11\n",
      "[0.045 0.05  0.06  0.065 0.075 0.08  0.09  0.095 0.105 0.11 ] 0.12\n",
      "[0.05  0.06  0.065 0.075 0.08  0.09  0.095 0.105 0.11  0.12 ] 0.125\n",
      "[0.06  0.065 0.075 0.08  0.09  0.095 0.105 0.11  0.12  0.125] 0.135\n",
      "[0.065 0.075 0.08  0.09  0.095 0.105 0.11  0.12  0.125 0.135] 0.14\n",
      "[0.075 0.08  0.09  0.095 0.105 0.11  0.12  0.125 0.135 0.14 ] 0.15\n",
      "[0.08  0.09  0.095 0.105 0.11  0.12  0.125 0.135 0.14  0.15 ] 0.155\n",
      "[0.09  0.095 0.105 0.11  0.12  0.125 0.135 0.14  0.15  0.155] 0.165\n",
      "[0.095 0.105 0.11  0.12  0.125 0.135 0.14  0.15  0.155 0.165] 0.17\n",
      "[0.105 0.11  0.12  0.125 0.135 0.14  0.15  0.155 0.165 0.17 ] 0.18\n",
      "[0.11  0.12  0.125 0.135 0.14  0.15  0.155 0.165 0.17  0.18 ] 0.185\n",
      "[0.12  0.125 0.135 0.14  0.15  0.155 0.165 0.17  0.18  0.185] 0.195\n",
      "[0.125 0.135 0.14  0.15  0.155 0.165 0.17  0.18  0.185 0.195] 0.2\n",
      "[0.135 0.14  0.15  0.155 0.165 0.17  0.18  0.185 0.195 0.2  ] 0.21\n",
      "[0.14  0.15  0.155 0.165 0.17  0.18  0.185 0.195 0.2   0.21 ] 0.215\n",
      "[0.15  0.155 0.165 0.17  0.18  0.185 0.195 0.2   0.21  0.215] 0.225\n",
      "[0.155 0.165 0.17  0.18  0.185 0.195 0.2   0.21  0.215 0.225] 0.23\n",
      "[0.165 0.17  0.18  0.185 0.195 0.2   0.21  0.215 0.225 0.23 ] 0.24\n",
      "[0.17  0.18  0.185 0.195 0.2   0.21  0.215 0.225 0.23  0.24 ] 0.245\n",
      "[0.18  0.185 0.195 0.2   0.21  0.215 0.225 0.23  0.24  0.245] 0.255\n",
      "[0.185 0.195 0.2   0.21  0.215 0.225 0.23  0.24  0.245 0.255] 0.26\n",
      "[0.195 0.2   0.21  0.215 0.225 0.23  0.24  0.245 0.255 0.26 ] 0.27\n",
      "[0.2   0.21  0.215 0.225 0.23  0.24  0.245 0.255 0.26  0.27 ] 0.275\n",
      "[0.21  0.215 0.225 0.23  0.24  0.245 0.255 0.26  0.27  0.275] 0.285\n",
      "[0.215 0.225 0.23  0.24  0.245 0.255 0.26  0.27  0.275 0.285] 0.29\n",
      "[0.225 0.23  0.24  0.245 0.255 0.26  0.27  0.275 0.285 0.29 ] 0.3\n",
      "[0.23  0.24  0.245 0.255 0.26  0.27  0.275 0.285 0.29  0.3  ] 0.305\n",
      "[0.24  0.245 0.255 0.26  0.27  0.275 0.285 0.29  0.3   0.305] 0.315\n",
      "[0.245 0.255 0.26  0.27  0.275 0.285 0.29  0.3   0.305 0.315] 0.32\n",
      "[0.255 0.26  0.27  0.275 0.285 0.29  0.3   0.305 0.315 0.32 ] 0.33\n",
      "[0.26  0.27  0.275 0.285 0.29  0.3   0.305 0.315 0.32  0.33 ] 0.335\n",
      "[0.27  0.275 0.285 0.29  0.3   0.305 0.315 0.32  0.33  0.335] 0.345\n",
      "[0.275 0.285 0.29  0.3   0.305 0.315 0.32  0.33  0.335 0.345] 0.35\n",
      "[0.285 0.29  0.3   0.305 0.315 0.32  0.33  0.335 0.345 0.35 ] 0.36\n",
      "[0.29  0.3   0.305 0.315 0.32  0.33  0.335 0.345 0.35  0.36 ] 0.365\n",
      "[0.3   0.305 0.315 0.32  0.33  0.335 0.345 0.35  0.36  0.365] 0.375\n",
      "[0.305 0.315 0.32  0.33  0.335 0.345 0.35  0.36  0.365 0.375] 0.38\n",
      "[0.315 0.32  0.33  0.335 0.345 0.35  0.36  0.365 0.375 0.38 ] 0.39\n",
      "[0.32  0.33  0.335 0.345 0.35  0.36  0.365 0.375 0.38  0.39 ] 0.395\n",
      "[0.33  0.335 0.345 0.35  0.36  0.365 0.375 0.38  0.39  0.395] 0.405\n",
      "[0.335 0.345 0.35  0.36  0.365 0.375 0.38  0.39  0.395 0.405] 0.41\n",
      "[0.345 0.35  0.36  0.365 0.375 0.38  0.39  0.395 0.405 0.41 ] 0.42\n",
      "[0.35  0.36  0.365 0.375 0.38  0.39  0.395 0.405 0.41  0.42 ] 0.425\n",
      "[0.36  0.365 0.375 0.38  0.39  0.395 0.405 0.41  0.42  0.425] 0.435\n",
      "[0.365 0.375 0.38  0.39  0.395 0.405 0.41  0.42  0.425 0.435] 0.44\n",
      "[0.375 0.38  0.39  0.395 0.405 0.41  0.42  0.425 0.435 0.44 ] 0.45\n",
      "[0.38  0.39  0.395 0.405 0.41  0.42  0.425 0.435 0.44  0.45 ] 0.455\n",
      "[0.39  0.395 0.405 0.41  0.42  0.425 0.435 0.44  0.45  0.455] 0.465\n",
      "[0.395 0.405 0.41  0.42  0.425 0.435 0.44  0.45  0.455 0.465] 0.47\n",
      "[0.405 0.41  0.42  0.425 0.435 0.44  0.45  0.455 0.465 0.47 ] 0.48\n",
      "[0.41  0.42  0.425 0.435 0.44  0.45  0.455 0.465 0.47  0.48 ] 0.485\n",
      "[0.42  0.425 0.435 0.44  0.45  0.455 0.465 0.47  0.48  0.485] 0.495\n",
      "[0.425 0.435 0.44  0.45  0.455 0.465 0.47  0.48  0.485 0.495] 0.5\n",
      "[0.435 0.44  0.45  0.455 0.465 0.47  0.48  0.485 0.495 0.5  ] 0.51\n",
      "[0.44  0.45  0.455 0.465 0.47  0.48  0.485 0.495 0.5   0.51 ] 0.515\n",
      "[0.45  0.455 0.465 0.47  0.48  0.485 0.495 0.5   0.51  0.515] 0.525\n",
      "[0.455 0.465 0.47  0.48  0.485 0.495 0.5   0.51  0.515 0.525] 0.53\n",
      "[0.465 0.47  0.48  0.485 0.495 0.5   0.51  0.515 0.525 0.53 ] 0.54\n",
      "[0.47  0.48  0.485 0.495 0.5   0.51  0.515 0.525 0.53  0.54 ] 0.545\n",
      "[0.48  0.485 0.495 0.5   0.51  0.515 0.525 0.53  0.54  0.545] 0.555\n",
      "[0.485 0.495 0.5   0.51  0.515 0.525 0.53  0.54  0.545 0.555] 0.56\n",
      "[0.495 0.5   0.51  0.515 0.525 0.53  0.54  0.545 0.555 0.56 ] 0.57\n",
      "[0.5   0.51  0.515 0.525 0.53  0.54  0.545 0.555 0.56  0.57 ] 0.575\n",
      "[0.51  0.515 0.525 0.53  0.54  0.545 0.555 0.56  0.57  0.575] 0.585\n",
      "[0.515 0.525 0.53  0.54  0.545 0.555 0.56  0.57  0.575 0.585] 0.59\n",
      "[0.525 0.53  0.54  0.545 0.555 0.56  0.57  0.575 0.585 0.59 ] 0.6\n",
      "[0.53  0.54  0.545 0.555 0.56  0.57  0.575 0.585 0.59  0.6  ] 0.605\n",
      "[0.54  0.545 0.555 0.56  0.57  0.575 0.585 0.59  0.6   0.605] 0.615\n",
      "[0.545 0.555 0.56  0.57  0.575 0.585 0.59  0.6   0.605 0.615] 0.62\n",
      "[0.555 0.56  0.57  0.575 0.585 0.59  0.6   0.605 0.615 0.62 ] 0.63\n",
      "[0.56  0.57  0.575 0.585 0.59  0.6   0.605 0.615 0.62  0.63 ] 0.635\n",
      "[0.57  0.575 0.585 0.59  0.6   0.605 0.615 0.62  0.63  0.635] 0.645\n",
      "[0.575 0.585 0.59  0.6   0.605 0.615 0.62  0.63  0.635 0.645] 0.65\n",
      "[0.585 0.59  0.6   0.605 0.615 0.62  0.63  0.635 0.645 0.65 ] 0.66\n",
      "[0.59  0.6   0.605 0.615 0.62  0.63  0.635 0.645 0.65  0.66 ] 0.665\n",
      "[0.6   0.605 0.615 0.62  0.63  0.635 0.645 0.65  0.66  0.665] 0.675\n",
      "[0.605 0.615 0.62  0.63  0.635 0.645 0.65  0.66  0.665 0.675] 0.68\n",
      "[0.615 0.62  0.63  0.635 0.645 0.65  0.66  0.665 0.675 0.68 ] 0.69\n",
      "[0.62  0.63  0.635 0.645 0.65  0.66  0.665 0.675 0.68  0.69 ] 0.695\n",
      "[0.63  0.635 0.645 0.65  0.66  0.665 0.675 0.68  0.69  0.695] 0.705\n",
      "[0.635 0.645 0.65  0.66  0.665 0.675 0.68  0.69  0.695 0.705] 0.71\n",
      "[0.645 0.65  0.66  0.665 0.675 0.68  0.69  0.695 0.705 0.71 ] 0.72\n",
      "[0.65  0.66  0.665 0.675 0.68  0.69  0.695 0.705 0.71  0.72 ] 0.725\n",
      "[0.66  0.665 0.675 0.68  0.69  0.695 0.705 0.71  0.72  0.725] 0.735\n",
      "[0.665 0.675 0.68  0.69  0.695 0.705 0.71  0.72  0.725 0.735] 0.74\n"
     ]
    }
   ],
   "source": [
    "X, y = split_sequence(motif_indexes, look_back=10)\n",
    "for i in range(len(X)):\n",
    " print(X[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72 , 0.725, 0.735])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pad sequences putting zeros at the beginning\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = pad_sequences(X,  maxlen=3, padding='pre', truncating='pre', value=-1, dtype=float)\n",
    "X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 3, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train are the first 80% of the X\n",
    "X_train = X[:int(0.8*len(X))]\n",
    "X_test = X[int(0.8*len(X)):]\n",
    "y_train = y[:int(0.8*len(y))]\n",
    "y_test = y[int(0.8*len(y)):]\n",
    "\n",
    "#reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],  X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],  X_test.shape[1], 1))\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train lstm\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "from keras import Input\n",
    "\n",
    "def create_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Masking(mask_value=-1))\n",
    "    hp_units = hp.Int('units', min_value=2, max_value=12, step=1)\n",
    "    model.add(LSTM(units=hp_units, activation='relu', return_sequences=False))\n",
    "    model.add(Dense(1))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01,0.001])\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=hp_learning_rate), metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./lstm_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "tuner= kt.RandomSearch(\n",
    "        create_model,\n",
    "        objective='mae',\n",
    "        max_trials=50,\n",
    "        executions_per_trial=3,\n",
    "        project_name='lstm_tuning'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x=X_train,\n",
    "        y=y_train,\n",
    "        epochs=300,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test,y_test)\n",
    "        #callbacks=[EarlyStopping('val_loss', patience=5)]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgsilva/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491</span> (1.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m491\u001b[0m (1.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">491</span> (1.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m491\u001b[0m (1.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./lstm_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"mae\", direction=\"min\")\n",
      "\n",
      "Trial 14 summary\n",
      "Hyperparameters:\n",
      "units: 10\n",
      "learning_rate: 0.01\n",
      "Score: 0.001632041724709173\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 12\n",
      "learning_rate: 0.01\n",
      "Score: 0.001633973908610642\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "units: 8\n",
      "learning_rate: 0.01\n",
      "Score: 0.0016635231052835782\n",
      "\n",
      "Trial 11 summary\n",
      "Hyperparameters:\n",
      "units: 9\n",
      "learning_rate: 0.01\n",
      "Score: 0.0017100654852886994\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 6\n",
      "learning_rate: 0.01\n",
      "Score: 0.0017128710945447285\n",
      "\n",
      "Trial 18 summary\n",
      "Hyperparameters:\n",
      "units: 3\n",
      "learning_rate: 0.01\n",
      "Score: 0.0017240438998366396\n",
      "\n",
      "Trial 17 summary\n",
      "Hyperparameters:\n",
      "units: 11\n",
      "learning_rate: 0.01\n",
      "Score: 0.0017750317929312587\n",
      "\n",
      "Trial 13 summary\n",
      "Hyperparameters:\n",
      "units: 7\n",
      "learning_rate: 0.01\n",
      "Score: 0.001775855237307648\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 10\n",
      "learning_rate: 0.001\n",
      "Score: 0.002961325847233335\n",
      "\n",
      "Trial 20 summary\n",
      "Hyperparameters:\n",
      "units: 9\n",
      "learning_rate: 0.001\n",
      "Score: 0.005279509428267677\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "MSE: 9.545381926041184e-06\n",
      "MAE: 0.0025556050406561983\n",
      "R2: 0.9936628169785618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f58df482a00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(y_pred, label='Predicted')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create synthetic time series random uniform integers\n",
    "n = 1000\n",
    "time = np.arange(0, n, 1)\n",
    "data = np.random.randint(0, 6, n)\n",
    "\n",
    "#select random timewindows of length 5 without overlapping\n",
    "motif_indexes = []\n",
    "k = 100\n",
    "motif_pattern = [1,3,5,3,1]\n",
    "p = len(motif_pattern)\n",
    "available_starts = list(range(n - p))\n",
    "\n",
    "start = 0\n",
    "for i in range(k):\n",
    "    if not available_starts:\n",
    "        break\n",
    "    start = np.random.choice(available_starts)\n",
    "    motif_indexes.append(start)\n",
    "    available_starts = [idx for idx in available_starts if not idx in range(start - p, start + p)]\n",
    "\n",
    "motif_indexes = sorted(motif_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 3, 5, 3, 1, 4, 1, 1, 3, 5, 3, 1, 5, 3, 1, 3, 5, 3, 1, 0, 4,\n",
       "       1, 4, 3, 4, 1, 3, 5, 3, 1, 5, 2, 2, 2, 3, 1, 3, 5, 3, 1, 4, 0, 0,\n",
       "       5, 5, 2, 4, 0, 4, 1, 3, 5, 3, 1, 0, 1, 1, 3, 5, 3, 1, 2, 2, 4, 5,\n",
       "       0, 1, 3, 3, 5, 3, 1, 1, 1, 3, 5, 3, 1, 3, 4, 1, 4, 0, 1, 3, 5, 3,\n",
       "       1, 4, 3, 4, 0, 2, 1, 3, 0, 3, 5, 1, 3, 5, 2, 3, 3, 1, 5, 1, 2, 3,\n",
       "       2, 3, 2, 3, 0, 4, 0, 1, 3, 5, 3, 1, 0, 2, 1, 3, 5, 3, 1, 2, 2, 2,\n",
       "       1, 1, 3, 5, 3, 1, 4, 1, 3, 5, 3, 1, 1, 0, 1, 1, 3, 5, 3, 1, 5, 3,\n",
       "       1, 3, 5, 3, 1, 5, 5, 5, 1, 3, 5, 3, 1, 1, 3, 5, 3, 1, 3, 5, 1, 3,\n",
       "       5, 3, 1, 2, 1, 3, 5, 3, 1, 1, 1, 1, 3, 5, 3, 1, 1, 0, 4, 2, 1, 3,\n",
       "       5, 3, 1, 3, 5, 4, 3, 2, 0, 1, 3, 5, 3, 1, 5, 4, 2, 2, 3, 1, 3, 5,\n",
       "       3, 1, 4, 0, 5, 5, 3, 1, 0, 1, 3, 5, 3, 1, 4, 0, 1, 3, 5, 3, 1, 1,\n",
       "       3, 5, 3, 1, 5, 5, 1, 3, 5, 3, 1, 3, 1, 5, 2, 4, 1, 3, 5, 3, 1, 4,\n",
       "       0, 3, 2, 1, 5, 2, 2, 3, 1, 3, 5, 3, 1, 1, 3, 5, 3, 1, 4, 2, 3, 3,\n",
       "       3, 3, 1, 1, 3, 5, 3, 1, 5, 5, 0, 3, 2, 1, 3, 5, 3, 1, 4, 4, 1, 1,\n",
       "       1, 3, 5, 3, 1, 5, 4, 4, 3, 2, 1, 3, 5, 3, 1, 0, 2, 0, 2, 1, 3, 5,\n",
       "       3, 1, 2, 4, 0, 1, 3, 5, 3, 1, 3, 0, 4, 3, 0, 3, 0, 0, 2, 0, 1, 3,\n",
       "       5, 3, 1, 1, 3, 5, 3, 1, 4, 4, 4, 1, 3, 5, 3, 1, 4, 2, 3, 2, 1, 3,\n",
       "       3, 0, 1, 3, 5, 3, 1, 1, 4, 1, 1, 4, 5, 5, 0, 2, 1, 3, 5, 3, 1, 3,\n",
       "       4, 1, 5, 3, 0, 2, 2, 5, 1, 3, 5, 3, 1, 1, 3, 5, 3, 1, 1, 1, 1, 4,\n",
       "       1, 3, 5, 3, 1, 0, 2, 2, 3, 0, 1, 2, 3, 2, 3, 2, 1, 3, 5, 3, 1, 0,\n",
       "       1, 3, 5, 3, 1, 4, 1, 2, 0, 0, 5, 3, 1, 2, 5, 0, 3, 1, 4, 2, 5, 5,\n",
       "       1, 2, 0, 5, 2, 1, 3, 5, 3, 1, 1, 0, 4, 1, 3, 5, 3, 1, 5, 1, 2, 5,\n",
       "       1, 1, 3, 5, 3, 1, 4, 3, 0, 1, 3, 5, 3, 1, 2, 2, 5, 2, 1, 0, 4, 5,\n",
       "       3, 5, 2, 5, 5, 3, 2, 4, 1, 3, 5, 3, 1, 1, 4, 5, 0, 1, 3, 5, 3, 1,\n",
       "       5, 1, 2, 3, 1, 4, 1, 3, 5, 3, 1, 0, 1, 3, 5, 3, 1, 2, 3, 0, 1, 1,\n",
       "       3, 1, 3, 5, 3, 1, 1, 1, 1, 1, 0, 1, 3, 5, 3, 1, 4, 1, 3, 5, 3, 1,\n",
       "       2, 4, 5, 2, 1, 1, 3, 5, 3, 1, 4, 5, 1, 3, 5, 3, 1, 4, 1, 5, 5, 2,\n",
       "       3, 4, 2, 2, 1, 3, 1, 3, 1, 3, 5, 3, 1, 1, 4, 1, 5, 0, 3, 4, 4, 5,\n",
       "       4, 1, 3, 5, 3, 1, 3, 1, 0, 3, 1, 3, 5, 3, 1, 5, 5, 2, 1, 4, 4, 4,\n",
       "       2, 3, 3, 1, 3, 5, 3, 1, 5, 4, 5, 1, 2, 0, 0, 3, 1, 3, 5, 3, 1, 3,\n",
       "       2, 1, 3, 5, 3, 1, 4, 3, 3, 5, 5, 3, 1, 3, 5, 3, 1, 0, 3, 1, 3, 5,\n",
       "       3, 1, 3, 3, 3, 1, 3, 5, 3, 1, 1, 3, 5, 3, 1, 3, 1, 3, 5, 3, 1, 0,\n",
       "       2, 1, 0, 4, 5, 1, 3, 5, 3, 1, 0, 0, 4, 5, 5, 4, 1, 1, 3, 5, 3, 1,\n",
       "       3, 4, 1, 2, 1, 4, 1, 3, 4, 4, 5, 1, 2, 3, 0, 4, 1, 4, 0, 0, 3, 5,\n",
       "       1, 1, 0, 5, 1, 3, 5, 3, 1, 5, 1, 3, 5, 3, 1, 4, 4, 4, 1, 1, 3, 5,\n",
       "       3, 1, 4, 0, 1, 5, 1, 3, 5, 3, 1, 0, 3, 1, 1, 0, 4, 3, 1, 3, 5, 3,\n",
       "       1, 0, 1, 3, 5, 3, 1, 3, 2, 0, 5, 3, 5, 1, 3, 5, 3, 1, 1, 3, 5, 3,\n",
       "       1, 4, 5, 1, 4, 5, 1, 3, 5, 3, 1, 1, 0, 5, 1, 1, 3, 5, 3, 1, 4, 1,\n",
       "       3, 5, 3, 1, 4, 4, 5, 5, 1, 2, 1, 3, 5, 3, 1, 0, 3, 4, 1, 3, 5, 3,\n",
       "       1, 1, 3, 5, 3, 1, 0, 0, 2, 1, 3, 5, 3, 1, 1, 2, 1, 1, 3, 5, 3, 1,\n",
       "       4, 3, 1, 2, 0, 2, 1, 3, 5, 3, 1, 4, 5, 0, 0, 3, 3, 5, 5, 1, 1, 3,\n",
       "       5, 3, 1, 1, 1, 3, 5, 3, 1, 1, 5, 1, 3, 5, 3, 1, 0, 0, 0, 0, 2, 4,\n",
       "       4, 4, 1, 3, 5, 3, 1, 2, 0, 0, 4, 3, 1, 3, 5, 3, 1, 3, 5, 3, 1, 3,\n",
       "       5, 3, 1, 0, 3, 4, 2, 2, 3, 0, 1, 1, 3, 5, 3, 1, 2, 1, 3, 5, 3, 1,\n",
       "       5, 1, 2, 4, 3, 1, 3, 5, 3, 1, 4, 1, 1, 1, 3, 5, 3, 1, 1, 3, 5, 3,\n",
       "       1, 5, 0, 4, 0, 0, 4, 0, 2, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the values of the time series in the selected timewindows to the motif pattern\n",
    "for idx in motif_indexes:\n",
    "    data[idx:idx+p] = motif_pattern\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def create_dataset(data, look_back, motif_indexes):\n",
    "    X1, X2, y1, y = list(), list(), list(), list()\n",
    "    for idx in range(len(data)- look_back -1):\n",
    "        next_motif_idx = [motif_idx for motif_idx in motif_indexes if motif_idx > idx + look_back]\n",
    "        dist_to_next_motif = next_motif_idx[0] - idx if next_motif_idx else -1\n",
    "        data_x1 = data[idx:idx+look_back]\n",
    "        data_x2 = [motif_idx for motif_idx in motif_indexes if motif_idx <= idx+look_back]\n",
    "        data_y1 = data[idx+look_back]\n",
    "        data_y = dist_to_next_motif\n",
    "        X1.append(data_x1)\n",
    "        X2.append(data_x2)\n",
    "        y1.append(data_y1)\n",
    "        y.append(data_y)\n",
    "\n",
    "    X2 = pad_sequences(X2, padding='post', value=-1, dtype=int)\n",
    "    return np.array(X1), np.array(X2), np.array(y1), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1 3 5 3 1 4 1 1 3 5 3 1 5 3 1 3 5 3 1 0 4 1 4 3 4 1 3 5 3 1 5 2 2 2 3 1\n",
      " 3 5 3 1 4 0 0 5 5 2 4 0 4] [ 1  8 15 26 36 50 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1] 1 57\n"
     ]
    }
   ],
   "source": [
    "look_back = 50\n",
    "X1, X2, y1, y  = create_dataset(data, look_back=look_back, motif_indexes=motif_indexes)\n",
    "print(X1[0], X2[0], y1[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(949, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759, 50, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train are the first 80% of the X\n",
    "X1_train = X1[:int(0.8*len(X1))]\n",
    "X2_train = X2[:int(0.8*len(X2))]\n",
    "X1_test = X1[int(0.8*len(X1)):]\n",
    "X2_test = X2[int(0.8*len(X2)):]\n",
    "y1_train = y1[:int(0.8*len(y1))]\n",
    "y_train = y[:int(0.8*len(y))]\n",
    "y1_test = y1[int(0.8*len(y1)):]\n",
    "y_test = y[int(0.8*len(y)):]\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X1_train, X2_train, y1_train = shuffle(X1_train, X2_train, y1_train)\n",
    "X1_test, X2_test, y1_test = shuffle(X1_test, X2_test, y1_test)\n",
    "\n",
    "#reshape input to be [samples, time steps, features]\n",
    "X1_train = np.reshape(X1_train, (X1_train.shape[0],  X1_train.shape[1], 1))\n",
    "X1_test = np.reshape(X1_test, (X1_test.shape[0],  X1_test.shape[1], 1))\n",
    "\n",
    "X1_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.01              |0.01              |learning_rate\n",
      "\n",
      "Epoch 1/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 4.3578 - mae: 1.6750\n",
      "Epoch 2/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4975 - mae: 1.3516\n",
      "Epoch 3/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4885 - mae: 1.3673\n",
      "Epoch 4/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4620 - mae: 1.3664\n",
      "Epoch 5/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4166 - mae: 1.3280\n",
      "Epoch 6/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.4134 - mae: 1.3460\n",
      "Epoch 7/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.5372 - mae: 1.3419\n",
      "Epoch 8/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3689 - mae: 1.3116\n",
      "Epoch 9/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 2.3331 - mae: 1.3073\n",
      "Epoch 10/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 2.2883 - mae: 1.2669\n",
      "Epoch 11/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3036 - mae: 1.2823\n",
      "Epoch 12/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3797 - mae: 1.2885\n",
      "Epoch 13/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.2842 - mae: 1.2573\n",
      "Epoch 14/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 2.3163 - mae: 1.2492\n",
      "Epoch 15/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.4149 - mae: 1.2940\n",
      "Epoch 16/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2598 - mae: 1.2244\n",
      "Epoch 17/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2433 - mae: 1.2197\n",
      "Epoch 18/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1895 - mae: 1.2169\n",
      "Epoch 19/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1397 - mae: 1.1879\n",
      "Epoch 20/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2027 - mae: 1.2044\n",
      "Epoch 21/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2102 - mae: 1.2203\n",
      "Epoch 22/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1564 - mae: 1.1678\n",
      "Epoch 23/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0789 - mae: 1.1565\n",
      "Epoch 24/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0133 - mae: 1.1443\n",
      "Epoch 25/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0856 - mae: 1.1706\n",
      "Epoch 26/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0409 - mae: 1.1364\n",
      "Epoch 27/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.1102 - mae: 1.1820\n",
      "Epoch 28/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.2339 - mae: 1.2025\n",
      "Epoch 29/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0340 - mae: 1.1302\n",
      "Epoch 30/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0429 - mae: 1.1689\n",
      "Epoch 31/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.9134 - mae: 1.0870\n",
      "Epoch 32/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0275 - mae: 1.1277\n",
      "Epoch 33/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.9398 - mae: 1.1211\n",
      "Epoch 34/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 2.0326 - mae: 1.1411\n",
      "Epoch 35/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.8352 - mae: 1.0567\n",
      "Epoch 36/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7815 - mae: 1.0577\n",
      "Epoch 37/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.8377 - mae: 1.0607\n",
      "Epoch 38/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.8643 - mae: 1.0690\n",
      "Epoch 39/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7353 - mae: 1.0431\n",
      "Epoch 40/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.8688 - mae: 1.0779\n",
      "Epoch 41/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6876 - mae: 1.0120\n",
      "Epoch 42/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7275 - mae: 1.0398\n",
      "Epoch 43/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7564 - mae: 1.0636\n",
      "Epoch 44/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7393 - mae: 1.0202\n",
      "Epoch 45/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.7998 - mae: 1.0701\n",
      "Epoch 46/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6502 - mae: 0.9956\n",
      "Epoch 47/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6522 - mae: 0.9980\n",
      "Epoch 48/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6808 - mae: 0.9958\n",
      "Epoch 49/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.5468 - mae: 0.9630\n",
      "Epoch 50/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.5516 - mae: 0.9428\n",
      "Epoch 51/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.5867 - mae: 0.9915\n",
      "Epoch 52/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.4648 - mae: 0.9117\n",
      "Epoch 53/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 1.6116 - mae: 1.0054\n",
      "Epoch 54/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4871 - mae: 0.9305\n",
      "Epoch 55/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4810 - mae: 0.9230\n",
      "Epoch 56/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.5720 - mae: 0.9734\n",
      "Epoch 57/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4347 - mae: 0.9255\n",
      "Epoch 58/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.3638 - mae: 0.9068\n",
      "Epoch 59/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4309 - mae: 0.9043\n",
      "Epoch 60/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3666 - mae: 0.8988\n",
      "Epoch 61/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4050 - mae: 0.9053\n",
      "Epoch 62/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.3810 - mae: 0.8843\n",
      "Epoch 63/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1864 - mae: 0.8249\n",
      "Epoch 64/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.3813 - mae: 0.9355\n",
      "Epoch 65/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4332 - mae: 0.9092\n",
      "Epoch 66/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2421 - mae: 0.8417\n",
      "Epoch 67/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.2490 - mae: 0.8566\n",
      "Epoch 68/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1584 - mae: 0.8226\n",
      "Epoch 69/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0669 - mae: 0.7817\n",
      "Epoch 70/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1953 - mae: 0.8193\n",
      "Epoch 71/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0660 - mae: 0.7884\n",
      "Epoch 72/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1934 - mae: 0.8357\n",
      "Epoch 73/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1500 - mae: 0.8077\n",
      "Epoch 74/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1009 - mae: 0.8071\n",
      "Epoch 75/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9656 - mae: 0.7549\n",
      "Epoch 76/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0277 - mae: 0.7523\n",
      "Epoch 77/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0319 - mae: 0.7501\n",
      "Epoch 78/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.0426 - mae: 0.7765\n",
      "Epoch 79/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0178 - mae: 0.7506\n",
      "Epoch 80/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0588 - mae: 0.7919\n",
      "Epoch 81/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9991 - mae: 0.7596\n",
      "Epoch 82/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9643 - mae: 0.7447\n",
      "Epoch 83/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9225 - mae: 0.7332\n",
      "Epoch 84/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9012 - mae: 0.7230\n",
      "Epoch 85/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8540 - mae: 0.7037\n",
      "Epoch 86/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9143 - mae: 0.7233\n",
      "Epoch 87/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9103 - mae: 0.7275\n",
      "Epoch 88/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8976 - mae: 0.7250\n",
      "Epoch 89/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8068 - mae: 0.6730\n",
      "Epoch 90/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8200 - mae: 0.6701\n",
      "Epoch 91/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9200 - mae: 0.7322\n",
      "Epoch 92/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7675 - mae: 0.6661\n",
      "Epoch 93/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8101 - mae: 0.6721\n",
      "Epoch 94/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.3247 - mae: 0.8975\n",
      "Epoch 95/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.9712 - mae: 0.7447\n",
      "Epoch 96/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.8083 - mae: 0.6790\n",
      "Epoch 97/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8613 - mae: 0.7064\n",
      "Epoch 98/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7586 - mae: 0.6577\n",
      "Epoch 99/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.8230 - mae: 0.6817\n",
      "Epoch 100/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6898 - mae: 0.6176\n",
      "Epoch 101/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6486 - mae: 0.6045\n",
      "Epoch 102/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6595 - mae: 0.6060\n",
      "Epoch 103/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6685 - mae: 0.6098\n",
      "Epoch 104/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7192 - mae: 0.6315\n",
      "Epoch 105/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6565 - mae: 0.6110\n",
      "Epoch 106/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.6130 - mae: 0.5850\n",
      "Epoch 107/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4762 - mae: 0.5105\n",
      "Epoch 108/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5519 - mae: 0.5498\n",
      "Epoch 109/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5868 - mae: 0.5579\n",
      "Epoch 110/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4983 - mae: 0.5291\n",
      "Epoch 111/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5426 - mae: 0.5385\n",
      "Epoch 112/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5393 - mae: 0.5442\n",
      "Epoch 113/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6391 - mae: 0.5682\n",
      "Epoch 114/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5653 - mae: 0.5625\n",
      "Epoch 115/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5500 - mae: 0.5565\n",
      "Epoch 116/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4566 - mae: 0.4940\n",
      "Epoch 117/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4669 - mae: 0.5044\n",
      "Epoch 118/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.4496 - mae: 0.4870\n",
      "Epoch 119/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2021 - mae: 1.1116\n",
      "Epoch 120/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2944 - mae: 1.1842\n",
      "Epoch 121/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8415 - mae: 1.0677\n",
      "Epoch 122/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8704 - mae: 1.0967\n",
      "Epoch 123/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.6321 - mae: 0.9984\n",
      "Epoch 124/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5040 - mae: 0.9364\n",
      "Epoch 125/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3913 - mae: 0.9191\n",
      "Epoch 126/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5050 - mae: 0.9407\n",
      "Epoch 127/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.4781 - mae: 0.9394\n",
      "Epoch 128/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4163 - mae: 0.8823\n",
      "Epoch 129/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2397 - mae: 0.8431\n",
      "Epoch 130/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.2343 - mae: 0.8379\n",
      "Epoch 131/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3263 - mae: 0.8759\n",
      "Epoch 132/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3776 - mae: 0.9230\n",
      "Epoch 133/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 1.1745 - mae: 0.7853\n",
      "Epoch 134/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2063 - mae: 0.8361\n",
      "Epoch 135/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1126 - mae: 0.7737\n",
      "Epoch 136/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2586 - mae: 0.8517\n",
      "Epoch 137/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1117 - mae: 0.7852\n",
      "Epoch 138/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0909 - mae: 0.7683\n",
      "Epoch 139/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1358 - mae: 0.8006\n",
      "Epoch 140/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1191 - mae: 0.7762\n",
      "Epoch 141/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0082 - mae: 0.7519\n",
      "Epoch 142/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0994 - mae: 0.7773\n",
      "Epoch 143/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1203 - mae: 0.7834\n",
      "Epoch 144/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0936 - mae: 0.7531\n",
      "Epoch 145/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9508 - mae: 0.7111\n",
      "Epoch 146/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0631 - mae: 0.7512\n",
      "Epoch 147/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9642 - mae: 0.7302\n",
      "Epoch 148/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9054 - mae: 0.7056\n",
      "Epoch 149/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8745 - mae: 0.6918\n",
      "Epoch 150/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.9095 - mae: 0.7024\n",
      "Epoch 151/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8890 - mae: 0.6907\n",
      "Epoch 152/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.7977 - mae: 0.6698\n",
      "Epoch 153/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.9065 - mae: 0.7082\n",
      "Epoch 154/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8526 - mae: 0.6900\n",
      "Epoch 155/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8263 - mae: 0.6780\n",
      "Epoch 156/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.8649 - mae: 0.6959\n",
      "Epoch 157/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7564 - mae: 0.6512\n",
      "Epoch 158/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7075 - mae: 0.6186\n",
      "Epoch 159/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7640 - mae: 0.6482\n",
      "Epoch 160/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7919 - mae: 0.6619\n",
      "Epoch 161/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7103 - mae: 0.6466\n",
      "Epoch 162/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6803 - mae: 0.6164\n",
      "Epoch 163/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6756 - mae: 0.6056\n",
      "Epoch 164/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6627 - mae: 0.6030\n",
      "Epoch 165/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.7353 - mae: 0.6319\n",
      "Epoch 166/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6056 - mae: 0.6015\n",
      "Epoch 167/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.5748 - mae: 0.5628\n",
      "Epoch 168/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6353 - mae: 0.5798\n",
      "Epoch 169/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5342 - mae: 0.5464\n",
      "Epoch 170/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4890 - mae: 0.5036\n",
      "Epoch 171/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4626 - mae: 0.4933\n",
      "Epoch 172/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5191 - mae: 0.5399\n",
      "Epoch 173/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4935 - mae: 0.5149\n",
      "Epoch 174/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4691 - mae: 0.5097\n",
      "Epoch 175/500\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5810 - mae: 0.5748\n",
      "Epoch 176/500\n",
      "\u001b[1m22/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5740 - mae: 0.5547"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 21\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m     13\u001b[0m tuner\u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[1;32m     14\u001b[0m         create_model_embeddinglstm,\n\u001b[1;32m     15\u001b[0m         objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m         project_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddinglstm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m         )\n\u001b[0;32m---> 21\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX1_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my1_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/trainer.py:254\u001b[0m, in \u001b[0;36mTorchTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 254\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/trainer.py:117\u001b[0m, in \u001b[0;36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m data \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/trainer.py:44\u001b[0m, in \u001b[0;36mTorchTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Compute predictions\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_has_training_arg:\n\u001b[0;32m---> 44\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/layer.py:27\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/models/sequential.py:209\u001b[0m, in \u001b[0;36mSequential.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_functional:\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_functional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# Fallback: Just apply the layer sequence.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# This typically happens if `inputs` is a nested struct.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# During each iteration, `inputs` are the inputs to `layer`, and\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# `outputs` are the outputs of `layer` applied to `inputs`. At the\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;66;03m# end of each iteration `inputs` is set to `outputs` to prepare for\u001b[39;00m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# the next layer.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/models/functional.py:202\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m             x\u001b[38;5;241m.\u001b[39m_keras_mask \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m--> 202\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/ops/function.py:155\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[0;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[1;32m    153\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/models/functional.py:592\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    590\u001b[0m ):\n\u001b[1;32m    591\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/layer.py:846\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 846\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[1;32m    850\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/layer.py:27\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/ops/operation.py:48\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[1;32m     44\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[1;32m     45\u001b[0m         call_fn,\n\u001b[1;32m     46\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     47\u001b[0m     )\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/rnn/lstm.py:560\u001b[0m, in \u001b[0;36mLSTM.call\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequences, initial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_state\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:406\u001b[0m, in \u001b[0;36mRNN.call\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# Prepopulate the dropout state so that the inner_loop is stateless\u001b[39;00m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# this is particularly important for JAX backend.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_config_dropout_masks(\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell, sequences[:, \u001b[38;5;241m0\u001b[39m, :], initial_state\n\u001b[1;32m    404\u001b[0m )\n\u001b[0;32m--> 406\u001b[0m last_output, outputs, states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m last_output \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(last_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n\u001b[1;32m    413\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/rnn/lstm.py:555\u001b[0m, in \u001b[0;36mLSTM.inner_loop\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cudnn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cudnn=True was specified, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut cuDNN is not supported for this layer configuration \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    552\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith this backend. Pass use_cudnn=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to fallback \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto a non-cuDNN implementation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m     )\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:346\u001b[0m, in \u001b[0;36mRNN.inner_loop\u001b[0;34m(self, sequences, initial_state, mask, training)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mis_nested(initial_state):\n\u001b[1;32m    344\u001b[0m     initial_state \u001b[38;5;241m=\u001b[39m [initial_state]\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgo_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_all_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/rnn.py:347\u001b[0m, in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m new_states \u001b[38;5;241m=\u001b[39m states\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m time \u001b[38;5;241m<\u001b[39m time_steps_t \u001b[38;5;129;01mand\u001b[39;00m it \u001b[38;5;241m<\u001b[39m max_iterations:\n\u001b[0;32m--> 347\u001b[0m     final_outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ta_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     time, output_ta_t \u001b[38;5;241m=\u001b[39m final_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    349\u001b[0m     new_states \u001b[38;5;241m=\u001b[39m final_outputs[\u001b[38;5;241m2\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/backend/torch/rnn.py:328\u001b[0m, in \u001b[0;36mrnn.<locals>._step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m    326\u001b[0m current_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ta[time] \u001b[38;5;28;01mfor\u001b[39;00m ta \u001b[38;5;129;01min\u001b[39;00m input_ta)\n\u001b[1;32m    327\u001b[0m current_input \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpack_sequence_as(inputs, current_input)\n\u001b[0;32m--> 328\u001b[0m output, new_states \u001b[38;5;241m=\u001b[39m \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m flat_new_state \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(new_states)\n\u001b[1;32m    333\u001b[0m flat_output \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mflatten(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/rnn/rnn.py:338\u001b[0m, in \u001b[0;36mRNN.inner_loop.<locals>.step\u001b[0;34m(inputs, states)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(inputs, states):\n\u001b[0;32m--> 338\u001b[0m     output, new_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcell_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mis_nested(new_states):\n\u001b[1;32m    340\u001b[0m         new_states \u001b[38;5;241m=\u001b[39m [new_states]\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/layer.py:743\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# Used to avoid expensive `tree` operations in the most common case.\u001b[39;00m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    738\u001b[0m     kwargs\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mstandardize_dtype(args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dtype\n\u001b[1;32m    742\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input_args:\n\u001b[0;32m--> 743\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(maybe_convert, kwargs)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m##########################################################\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# 2. Enforce that only tensors can be passed positionally.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/tree/tree_api.py:148\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.tree.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructures):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Maps `func` through given structures.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m        A new structure with the same layout as the given ones.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/tree/optree_impl.py:79\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     78\u001b[0m     assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnone_is_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/optree/ops.py:594\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    592\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    593\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/layers/layer.py:732\u001b[0m, in \u001b[0;36mLayer.__call__.<locals>.maybe_convert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_convert\u001b[39m(x):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautocast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dtype\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/dtype_policies/dtype_policy.py:143\u001b[0m, in \u001b[0;36mDTypePolicy.convert_input\u001b[0;34m(self, x, autocast, dtype)\u001b[0m\n\u001b[1;32m    138\u001b[0m dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mstandardize_dtype(dtype)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_tensor(x):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    141\u001b[0m         autocast\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mis_float_dtype(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m \u001b[38;5;241m!=\u001b[39m dtype\n\u001b[1;32m    144\u001b[0m     ):\n\u001b[1;32m    145\u001b[0m         x \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mcast(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_model_embeddinglstm(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units=50, activation='tanh', return_sequences=False))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[0.01,0.001])\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=hp_learning_rate), metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "import keras_tuner as kt\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "tuner= kt.RandomSearch(\n",
    "        create_model_embeddinglstm,\n",
    "        objective='mae',\n",
    "        max_trials=10,\n",
    "        executions_per_trial=3,\n",
    "        project_name = 'embeddinglstm'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x=X1_train,\n",
    "        y=y1_train,\n",
    "        epochs=500,\n",
    "        batch_size=32\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgsilva/miniconda3/envs/motifpredenv/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.005253280321710496\n",
      "MAE: 0.05478046589413994\n",
      "R2: 0.9979532719276796\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_train = best_model.predict(X_train)\n",
    "mse = mean_squared_error(y, y_train)\n",
    "mae = mean_absolute_error(y, y_train)\n",
    "r2 = r2_score(y, y_train)\n",
    "\n",
    "print(f'MSE: {mse}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "plt.plot(y, label='True')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motifpredenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
